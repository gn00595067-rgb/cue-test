import streamlit as st
import pandas as pd
import math
import io
import os
import shutil
import tempfile
import subprocess
import re
import requests
import base64
from datetime import timedelta, datetime, date
from copy import copy
import openpyxl
from openpyxl.utils import column_index_from_string
from openpyxl.cell.cell import MergedCell
from openpyxl.styles import Alignment, Font, Border, Side
from openpyxl.formula.translate import Translator

# =========================================================
# 0. åŸºç¤å·¥å…·
# =========================================================
def parse_count_to_int(x):
    if x is None: return 0
    if isinstance(x, (int, float)): return int(x)
    s = str(x)
    m = re.findall(r"[\d,]+", s)
    if not m: return 0
    return int(m[0].replace(",", ""))

def safe_filename(name: str) -> str:
    return re.sub(r'[\\/*?:"<>|]', "_", name).strip()

def html_escape(s):
    if s is None: return ""
    return str(s).replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;").replace("'", "&#39;")

# =========================================================
# 1. é é¢è¨­å®š & è‡ªå‹•è¼‰å…¥
# =========================================================
st.set_page_config(layout="wide", page_title="Cue Sheet Pro v74.1")

GOOGLE_DRIVE_FILE_ID = "11R1SA_hpFD5O_MGmYeh4BdtcUhK2bPta"
DEFAULT_FILENAME = "1209-Cueè¡¨ç›¸é—œè³‡æ–™.xlsx"

@st.cache_resource(ttl=600)
def load_default_template():
    status_msg = []
    if GOOGLE_DRIVE_FILE_ID:
        url = f"https://drive.google.com/uc?export=download&id={GOOGLE_DRIVE_FILE_ID}"
        try:
            r = requests.get(url, timeout=20, allow_redirects=True)
            if r.status_code == 200 and b"<!DOCTYPE html>" not in r.content[:500]:
                return r.content, "é›²ç«¯ç¡¬ç¢Ÿ (Google Drive)", status_msg
        except Exception as e:
            status_msg.append(f"âŒ é€£ç·šéŒ¯èª¤: {e}")

    if os.path.exists(DEFAULT_FILENAME):
        try:
            with open(DEFAULT_FILENAME, "rb") as f:
                return f.read(), "ç³»çµ±ä¸»æ©Ÿ (Local)", status_msg
        except: pass
    return None, None, status_msg

# =========================================================
# 2. PDF ç­–ç•¥ (å„ªå…ˆ LibreOfficeï¼Œå‚™æ´ WeasyPrint)
# =========================================================
def find_soffice_path():
    soffice = shutil.which("soffice") or shutil.which("libreoffice")
    if soffice: return soffice
    if os.name == "nt":
        candidates = [
            r"C:\Program Files\LibreOffice\program\soffice.exe",
            r"C:\Program Files (x86)\LibreOffice\program\soffice.exe",
        ]
        for p in candidates:
            if os.path.exists(p): return p
    return None

def xlsx_bytes_to_pdf_bytes(xlsx_bytes: bytes):
    soffice = find_soffice_path()
    if not soffice: 
        return None, "Fail", "ç„¡å¯ç”¨çš„ LibreOffice å¼•æ“"

    try:
        with tempfile.TemporaryDirectory() as tmp:
            xlsx_path = os.path.join(tmp, "cue.xlsx")
            with open(xlsx_path, "wb") as f: f.write(xlsx_bytes)
            
            subprocess.run([soffice, "--headless", "--nologo", "--convert-to", "pdf", "--outdir", tmp, xlsx_path], capture_output=True, timeout=60)
            
            pdf_path = os.path.join(tmp, "cue.pdf")
            if not os.path.exists(pdf_path):
                for fn in os.listdir(tmp):
                    if fn.endswith(".pdf"): pdf_path = os.path.join(tmp, fn); break
            
            if os.path.exists(pdf_path):
                with open(pdf_path, "rb") as f: return f.read(), "LibreOffice", ""
            return None, "Fail", "LibreOffice è½‰æª”ç„¡è¼¸å‡º"
    except Exception as e: return None, "Fail", str(e)

def html_to_pdf_weasyprint(html_str):
    try:
        from weasyprint import HTML, CSS
        from weasyprint.text.fonts import FontConfiguration
        font_config = FontConfiguration()
        css = CSS(string="@page { size: A4 landscape; margin: 1cm; } body { font-family: sans-serif; }")
        pdf_bytes = HTML(string=html_str).write_pdf(stylesheets=[css], font_config=font_config)
        return pdf_bytes, ""
    except Exception as e: return None, str(e)

# =========================================================
# 3. æ ¸å¿ƒè³‡æ–™è¨­å®š (2026)
# =========================================================
STORE_COUNTS = {
    "å…¨çœ": "4,437åº—", "åŒ—å€": "1,649åº—", "æ¡ƒç«¹è‹—": "779åº—", "ä¸­å€": "839åº—", 
    "é›²å˜‰å—": "499åº—", "é«˜å±": "490åº—", "æ±å€": "181åº—",
    "æ–°é®®è¦–_å…¨çœ": "3,124é¢", "æ–°é®®è¦–_åŒ—å€": "1,127é¢", "æ–°é®®è¦–_æ¡ƒç«¹è‹—": "616é¢", 
    "æ–°é®®è¦–_ä¸­å€": "528é¢", "æ–°é®®è¦–_é›²å˜‰å—": "365é¢", "æ–°é®®è¦–_é«˜å±": "405é¢", "æ–°é®®è¦–_æ±å€": "83é¢",
    "å®¶æ¨‚ç¦_é‡è²©": "68åº—", "å®¶æ¨‚ç¦_è¶…å¸‚": "249åº—"
}
STORE_COUNTS_NUM = {k: parse_count_to_int(v) for k, v in STORE_COUNTS.items()}

PRICING_DB = {
    "å…¨å®¶å»£æ’­": { "Std_Spots": 480, "Day_Part": "00:00-24:00", "å…¨çœ": [400000, 320000], "åŒ—å€": [250000, 200000], "æ¡ƒç«¹è‹—": [150000, 120000], "ä¸­å€": [150000, 120000], "é›²å˜‰å—": [100000, 80000], "é«˜å±": [100000, 80000], "æ±å€": [62500, 50000] },
    "æ–°é®®è¦–": { "Std_Spots": 504, "Day_Part": "07:00-22:00", "å…¨çœ": [150000, 120000], "åŒ—å€": [150000, 120000], "æ¡ƒç«¹è‹—": [120000, 96000], "ä¸­å€": [90000, 72000], "é›²å˜‰å—": [75000, 60000], "é«˜å±": [75000, 60000], "æ±å€": [45000, 36000] },
    "å®¶æ¨‚ç¦": { "é‡è²©_å…¨çœ": {"List": 300000, "Net": 250000, "Std_Spots": 420, "Day_Part": "09:00-23:00"}, "è¶…å¸‚_å…¨çœ": {"List": 100000, "Net": 80000, "Std_Spots": 720, "Day_Part": "00:00-24:00"} }
}
SEC_FACTORS = {
    "å…¨å®¶å»£æ’­": {30: 1.0, 20: 0.85, 15: 0.65, 10: 0.5, 5: 0.25},
    "æ–°é®®è¦–": {30: 3.0, 20: 2.0, 15: 1.5, 10: 1.0, 5: 0.5},
    "å®¶æ¨‚ç¦": {30: 1.5, 20: 1.0, 15: 0.85, 10: 0.65, 5: 0.35}
}
REGIONS_ORDER = ["åŒ—å€", "æ¡ƒç«¹è‹—", "ä¸­å€", "é›²å˜‰å—", "é«˜å±", "æ±å€"]

REGION_DISPLAY_MAP = {
    "åŒ—å€": "åŒ—å€-åŒ—åŒ—åŸº", "æ¡ƒç«¹è‹—": "æ¡ƒå€-æ¡ƒç«¹è‹—", "ä¸­å€": "ä¸­å€-ä¸­å½°æŠ•",
    "é›²å˜‰å—": "é›²å˜‰å—å€-é›²å˜‰å—", "é«˜å±": "é«˜å±å€-é«˜å±", "æ±å€": "æ±å€-å®œèŠ±æ±",
    "å…¨çœé‡è²©": "å…¨çœé‡è²©", "å…¨çœè¶…å¸‚": "å…¨çœè¶…å¸‚"
}
def region_display(region): return REGION_DISPLAY_MAP.get(region, region)

def get_sec_factor(media_type, seconds): return SEC_FACTORS.get(media_type, {}).get(seconds, 1.0)

def calculate_schedule(total_spots, days):
    if days <= 0: return []
    if total_spots % 2 != 0: total_spots += 1
    half_spots = total_spots // 2
    base, rem = divmod(half_spots, days)
    sch = [base + (1 if i < rem else 0) for i in range(days)]
    return [x * 2 for x in sch]

def get_remarks_text(sign_deadline, billing_month, payment_date):
    d_str = sign_deadline.strftime("%Y/%m/%d (%a) %H:%M") if sign_deadline else "____/__/__ (__) 12:00"
    p_str = payment_date.strftime("%Y/%m/%d") if payment_date else "____/__/__"
    return [
        f"1.è«‹æ–¼ {d_str}å‰ å›ç°½åŠé€²å–®ï¼Œæ–¹å¯é †åˆ©ä¸Šæª”ã€‚",
        "2.ä»¥ä¸Šç¯€ç›®åç¨±å¦‚æœ‰ç•°å‹•ï¼Œä»¥ä¸Šæª”æ™‚ç¯€ç›®åç¨±ç‚ºä¸»ï¼Œå¦‚é‡æ™‚æ®µæ»¿æª”ï¼Œä¸Šæª”æ™‚é–“æŒªå¾Œæˆ–æ›´æ›è‡³åŒç´šæ™‚æ®µã€‚",
        "3.é€šè·¯åº—é‹ªæ•¸èˆ‡é–‹æ©Ÿç‡è‡³å°‘ä¸ƒæˆ(ä»¥ä¸Š)ã€‚æ¯æ—¥å› åŠ ç›Ÿæ•¸èª¿æ•´ï¼Œæˆ–é‡åº—èˆ–å¹´åº¦å­£åº¦æ”¹è£ã€è¨­å‚™ç¶­è­·å‡ç´šåŠä¿ä¿®ç­‰ç‹€æ³ï¼Œæœƒæœ‰ä¸€å®šå¹…åº¦å¢æ¸›ã€‚",
        "4.è¨—æ’­æ–¹éœ€æ–¼ä¸Šæª”å‰ 5 å€‹å·¥ä½œå¤©ï¼Œæä¾›å»£å‘Šå¸¶(mp3)ã€å½±ç‰‡/å½±åƒ 1920x1080 (mp4)ã€‚",
        f"5.é›™æ–¹åŒæ„è²»ç”¨è«‹æ¬¾æœˆä»½ : {billing_month}ï¼Œå¦‚æœ‰ä¿®æ­£å¿…è¦ï¼Œå°‡å¦è¡ŒE-Mailå‘ŠçŸ¥ï¼Œä¸¦è¦–ç‚ºæ­£å¼åˆç´„ä¹‹ä¸€éƒ¨åˆ†ã€‚",
        f"6.ä»˜æ¬¾å…Œç¾æ—¥æœŸï¼š{p_str}"
    ]

# =========================================================
# 4. æ ¸å¿ƒè¨ˆç®—å‡½å¼ (Logic v4.1 - Detailed Debug)
# =========================================================
def calculate_plan_data(config, total_budget, days_count):
    rows = []
    total_list_accum = 0
    debug_logs = []

    for m, cfg in config.items():
        m_budget_total = total_budget * (cfg["share"] / 100.0)
        
        # [NEW] ä¾ç…§ç§’æ•¸ä½”æ¯”å†æ¬¡åˆ†é…é ç®—
        for sec, sec_pct in cfg["sec_shares"].items():
            s_budget = m_budget_total * (sec_pct / 100.0)
            if s_budget <= 0: continue
            
            factor = get_sec_factor(m, sec)
            log_details = {}
            
            if m in ["å…¨å®¶å»£æ’­", "æ–°é®®è¦–"]:
                db = PRICING_DB[m]
                calc_regs = ["å…¨çœ"] if cfg["is_national"] else cfg["regions"]
                display_regs = REGIONS_ORDER if cfg["is_national"] else cfg["regions"]
                
                # --- Step 1: Net ç®—æª”æ¬¡ ---
                unit_net_sum = 0
                for r in calc_regs:
                    unit_net_sum += (db[r][1] / db["Std_Spots"]) * factor
                if unit_net_sum == 0: continue
                
                spots_init = math.ceil(s_budget / unit_net_sum)
                std_spots = db["Std_Spots"]
                is_under_target = spots_init < std_spots
                
                calc_penalty = 1.1 if is_under_target else 1.0 
                
                if cfg["is_national"]:
                    row_display_penalty = 1.0 
                    total_display_penalty = 1.1 if is_under_target else 1.0
                    status_msg = "å…¨çœ(åˆ†å€è±å…/ç¸½åƒ¹æ‡²ç½°)" if is_under_target else "é”æ¨™"
                else:
                    row_display_penalty = 1.1 if is_under_target else 1.0
                    total_display_penalty = 1.0 
                    status_msg = "æœªé”æ¨™ x1.1" if is_under_target else "é”æ¨™"

                spots_final = math.ceil(s_budget / (unit_net_sum * calc_penalty))
                if spots_final % 2 != 0: spots_final += 1
                if spots_final == 0: spots_final = 2
                
                # [NEW] è©³ç´° Log
                log_details = {
                    "Media": f"{m} ({sec}s)",
                    "Budget": f"${s_budget:,.0f}",
                    "Formula": f"Netç¸½å’Œ(${sum([db[r][1] for r in calc_regs]):,}) / {std_spots} * {factor}",
                    "Net_Unit": f"${unit_net_sum:.2f}",
                    "Init_Spots": f"{spots_init} (Std: {std_spots})",
                    "Penalty": f"x{calc_penalty} ({status_msg})",
                    "Final_Cost": f"${unit_net_sum * calc_penalty:.2f}",
                    "Final_Spots": spots_final
                }
                debug_logs.append(log_details)

                sch = calculate_schedule(spots_final, days_count)

                # --- Step 2: List å¡«è¡¨æ ¼ ---
                for i, r in enumerate(display_regs):
                    list_price_region = db[r][0]
                    # [é—œéµä¿®æ­£] Rate é¡¯ç¤ºåˆ†å€ã€Œç¸½åƒ¹ã€
                    unit_rate_display = int((list_price_region / db["Std_Spots"]) * factor * row_display_penalty)
                    total_rate_display = unit_rate_display * spots_final 
                    pkg_display = total_rate_display
                    
                    if cfg["is_national"]:
                        # å…¨çœ Total è¨ˆç®—
                        if i == 0:
                            nat_list = db["å…¨çœ"][0]
                            nat_unit = int((nat_list / db["Std_Spots"]) * factor * total_display_penalty)
                            total_list_accum += nat_unit * spots_final
                    else:
                        total_list_accum += pkg_display

                    rows.append({
                        "media": m, "region": r,
                        "program_num": STORE_COUNTS_NUM.get(f"æ–°é®®è¦–_{r}" if m=="æ–°é®®è¦–" else r, 0),
                        "daypart": db["Day_Part"], "seconds": sec,
                        "spots": spots_final, "schedule": sch,
                        "rate_display": total_rate_display, 
                        "pkg_display": pkg_display,
                        "is_pkg_member": cfg["is_national"]
                    })

            elif m == "å®¶æ¨‚ç¦":
                db = PRICING_DB["å®¶æ¨‚ç¦"]
                base_std = db["é‡è²©_å…¨çœ"]["Std_Spots"]
                unit_net = (db["é‡è²©_å…¨çœ"]["Net"] / base_std) * factor
                
                spots_init = math.ceil(s_budget / unit_net)
                penalty = 1.1 if spots_init < base_std else 1.0
                
                spots_final = math.ceil(s_budget / (unit_net * penalty))
                if spots_final % 2 != 0: spots_final += 1
                sch_h = calculate_schedule(spots_final, days_count)
                
                # [NEW] è©³ç´° Log
                log_details = {
                    "Media": f"å®¶æ¨‚ç¦ ({sec}s)",
                    "Budget": f"${s_budget:,.0f}",
                    "Formula": f"Net(${db['é‡è²©_å…¨çœ']['Net']:,}) / {base_std} * {factor}",
                    "Net_Unit": f"${unit_net:.2f}",
                    "Init_Spots": f"{spots_init} (Std: {base_std})",
                    "Penalty": f"x{penalty}",
                    "Final_Cost": f"${unit_net * penalty:.2f}",
                    "Final_Spots": spots_final
                }
                debug_logs.append(log_details)
                
                base_list = db["é‡è²©_å…¨çœ"]["List"]
                unit_rate_h = int((base_list / base_std) * factor * penalty)
                total_rate_h = unit_rate_h * spots_final
                
                total_list_accum += total_rate_h
                rows.append({"media": m, "region": "å…¨çœé‡è²©", "program_num": STORE_COUNTS_NUM["å®¶æ¨‚ç¦_é‡è²©"], "daypart": db["é‡è²©_å…¨çœ"]["Day_Part"], "seconds": sec, "spots": spots_final, "schedule": sch_h, "rate_display": total_rate_h, "pkg_display": total_rate_h})
                
                spots_s = int(spots_final * (db["è¶…å¸‚_å…¨çœ"]["Std_Spots"] / base_std))
                sch_s = calculate_schedule(spots_s, days_count)
                rows.append({"media": m, "region": "å…¨çœè¶…å¸‚", "program_num": STORE_COUNTS_NUM["å®¶æ¨‚ç¦_è¶…å¸‚"], "daypart": db["è¶…å¸‚_å…¨çœ"]["Day_Part"], "seconds": sec, "spots": spots_s, "schedule": sch_s, "rate_display": "è¨ˆé‡è²©", "pkg_display": "è¨ˆé‡è²©"})

    return rows, total_list_accum, debug_logs

# =========================================================
# 5. OpenPyXL æ¸²æŸ“å¼•æ“
# =========================================================
SHEET_META = {
    "Dongwu": {
        "sheet_name": "æ±å³-æ ¼å¼", "date_start_cell": "I7", "schedule_start_col": "I", "max_days": 31, "total_col": "AN",
        "anchors": {"å…¨å®¶å»£æ’­": "é€šè·¯å»£æ’­å»£å‘Š", "æ–°é®®è¦–": "æ–°é®®è¦–å»£å‘Š", "å®¶æ¨‚ç¦": "å®¶æ¨‚ç¦"},
        "cols": {"station": "B", "location": "C", "program": "D", "daypart": "E", "seconds": "F", "rate": "G", "pkg": "H"},
        "header_override": {"G7": "rate\n(Net)", "H7": "Package-cost\n(Net)"},
        "station_merge": True, "total_label": "Total",
        "footer_labels": {"make": "è£½ä½œ", "vat": "5% VAT", "grand": "Grand Total"},
        "force_center_cols": ["E", "F", "G", "H"], 
    },
    "Shenghuo": {
        "sheet_name": "è²æ´»-æ ¼å¼", "date_start_cell": "G7", "schedule_start_col": "G", "max_days": 23, "total_col": "AD",
        "anchors": {"å…¨å®¶å»£æ’­": "å»£æ’­é€šè·¯å»£å‘Š", "æ–°é®®è¦–": "æ–°é®®è¦–å»£å‘Š", "å®¶æ¨‚ç¦": "å®¶æ¨‚ç¦"},
        "cols": {"station": "B", "location": "C", "program": "D", "daypart": "E", "seconds": "F", "pkg": "AF"},
        "header_cells": {"client": "C5", "product": "C6", "month": "G6"},
        "station_merge": False, "total_label": "Total",
        "footer_labels": {"make": "è£½ä½œ", "vat": "5% VAT", "grand": "Grand Total"},
        "force_center_cols": [],
    }
}

def find_row_by_content(ws, col_letter, keyword):
    col_idx = column_index_from_string(col_letter)
    for r in range(1, ws.max_row + 1):
        v = ws.cell(r, col_idx).value
        if isinstance(v, str) and keyword in v: return r
    return None

def copy_style(source_cell, target_cell):
    if source_cell.has_style:
        target_cell.font = copy(source_cell.font)
        target_cell.border = copy(source_cell.border)
        target_cell.fill = copy(source_cell.fill)
        target_cell.number_format = source_cell.number_format
        target_cell.alignment = copy(source_cell.alignment)
        target_cell.protection = copy(source_cell.protection)

def safe_write(ws, row, col_letter, value, center=False):
    col_idx = column_index_from_string(col_letter)
    cell = ws.cell(row, col_idx)
    if isinstance(cell, MergedCell):
        for mr in ws.merged_cells.ranges:
            if mr.min_row <= row <= mr.max_row and mr.min_col <= col_idx <= mr.max_col:
                cell = ws.cell(mr.min_row, mr.min_col)
                break
    cell.value = value
    if center:
        cell.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)

def copy_row_with_style_fix(ws, src_row, dst_row, max_col):
    ws.row_dimensions[dst_row].height = ws.row_dimensions[src_row].height
    for c in range(1, max_col + 1):
        sc = ws.cell(src_row, c)
        dc = ws.cell(dst_row, c)
        if sc.has_style:
            dc.font = copy(sc.font)
            dc.border = copy(sc.border)
            dc.fill = copy(sc.fill)
            dc.number_format = sc.number_format
            dc.alignment = copy(sc.alignment)
        v = sc.value
        if isinstance(v, str) and v.startswith("="):
            try: dc.value = Translator(v, origin=sc.coordinate).translate_formula(row_shift=(dst_row - src_row), col_shift=0)
            except: dc.value = v
        else: dc.value = v

def unmerge_col_overlap(ws, col_letter, start_row, end_row):
    st_col = column_index_from_string(col_letter)
    to_unmerge = []
    for mr in list(ws.merged_cells.ranges):
        if mr.min_col == st_col and mr.max_col == st_col:
            if not (mr.max_row < start_row or mr.min_row > end_row):
                to_unmerge.append(str(mr))
    for s in set(to_unmerge):
        try: ws.unmerge_cells(s)
        except: pass

def set_schedule(ws, row, start_col_letter, max_days, schedule_list):
    start_col = column_index_from_string(start_col_letter)
    for i in range(max_days):
        v = schedule_list[i] if (schedule_list and i < len(schedule_list)) else None
        safe_write_rc(ws, row, start_col + i, v)

def safe_write_rc(ws, row, col, value):
    cell = ws.cell(row=row, column=col)
    if isinstance(cell, MergedCell):
        master = _get_master_cell(ws, cell)
        if master: master.value = value
    else: cell.value = value

def _get_master_cell(ws, cell):
    if not isinstance(cell, MergedCell): return cell
    for mr in ws.merged_cells.ranges:
        if mr.min_row <= cell.row <= mr.max_row and mr.min_col <= cell.column <= mr.max_col:
            return ws.cell(row=mr.min_row, column=mr.min_col)
    return None

def find_first_row_contains(ws, col_letter, keyword):
    col_idx = column_index_from_string(col_letter)
    for r in range(1, ws.max_row + 1):
        v = ws.cell(r, col_idx).value
        if isinstance(v, str) and keyword in v: return r
    return None

def force_center_columns_range(ws, col_letters, start_row, end_row):
    if start_row is None or end_row is None: return
    for r in range(start_row, end_row + 1):
        for col in col_letters:
            addr = f"{col}{r}"
            cell = ws[addr]
            if isinstance(cell, MergedCell):
                master = _get_master_cell(ws, cell)
                if master: cell = master
                else: continue
            apply_center_style(cell)

def generate_excel_from_template(format_type, start_dt, end_dt, client_name, product_display_str, rows, remarks_list, template_bytes, total_list_accum):
    meta = SHEET_META[format_type]
    wb = openpyxl.load_workbook(io.BytesIO(template_bytes))
    target_sheet = meta["sheet_name"]
    if target_sheet not in wb.sheetnames: return None
    
    for s in list(wb.sheetnames):
        if s != target_sheet: del wb[s]
    ws = wb[target_sheet]

    hc = meta["header_cells"]
    if "client" in hc: safe_write(ws, hc["client"], client_name)
    if "product" in hc: safe_write(ws, hc["product"], product_display_str)
    if "period" in hc: safe_write(ws, hc["period"], f"{start_dt.strftime('%Y. %m. %d')} - {end_dt.strftime('%Y.%m. %d')}")
    if "medium" in hc: safe_write(ws, hc["medium"], " ".join(sorted(set([r["media"] for r in rows]))))
    if "month" in hc: safe_write(ws, hc["month"], f" {start_dt.month}æœˆ")
    safe_write(ws, meta["date_start_cell"], datetime(start_dt.year, start_dt.month, start_dt.day))
    for addr, text in meta.get("header_override", {}).items(): safe_write(ws, addr, text)

    total_cell = find_row_by_content(ws, meta["cols"]["station"], meta["total_label"])
    if not total_cell: return None
    total_row_orig = total_cell
    cols = meta["cols"]
    
    sec_start = {}
    for m_key, kw in meta["anchors"].items():
        r0 = find_first_row_contains(ws, cols["station"], kw)
        if r0: sec_start[m_key] = r0
    
    sec_order = sorted(sec_start.items(), key=lambda x: x[1], reverse=True)
    reg_map = {r: i for i, r in enumerate(REGIONS_ORDER + ["å…¨çœé‡è²©", "å…¨çœè¶…å¸‚"])}
    def sort_key(x): return (x["seconds"], reg_map.get(x["region"], 999))
    
    grouped_data = {
        "å…¨å®¶å»£æ’­": sorted([r for r in rows if r["media"] == "å…¨å®¶å»£æ’­"], key=sort_key),
        "æ–°é®®è¦–": sorted([r for r in rows if r["media"] == "æ–°é®®è¦–"], key=sort_key),
        "å®¶æ¨‚ç¦": sorted([r for r in rows if r["media"] == "å®¶æ¨‚ç¦"], key=sort_key),
    }
    
    current_end_marker = total_row_orig - 1
    
    def station_title(m):
        prefix = "å…¨å®¶ä¾¿åˆ©å•†åº—\n" if m != "å®¶æ¨‚ç¦" else ""
        name = "é€šè·¯å»£æ’­å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
        if format_type == "Shenghuo" and m == "å…¨å®¶å»£æ’­": name = "å»£æ’­é€šè·¯å»£å‘Š"
        return prefix + name

    for i, (m_key, start_row_orig) in enumerate(sec_order):
        style_source_row = start_row_orig + 1
        rows_to_delete = max(0, current_end_marker - style_source_row)
        
        data = grouped_data.get(m_key, [])
        needed = len(data)
        
        if needed == 0:
            if rows_to_delete > 0: ws.delete_rows(style_source_row + 1, amount=rows_to_delete)
            for c in range(1, ws.max_column+1): safe_write_rc(ws, style_source_row, c, None)
            current_end_marker = start_row_orig - 1
            continue

        if rows_to_delete > 0: ws.delete_rows(style_source_row + 1, amount=rows_to_delete)
        if needed > 1:
            ws.insert_rows(style_source_row + 1, amount=needed - 1)
            for r_idx in range(style_source_row + 1, style_source_row + 1 + needed - 1):
                copy_row_with_style_fix(ws, style_source_row, r_idx, ws.max_column)
        
        curr_row = style_source_row
        
        if meta["station_merge"] and needed > 0:
            unmerge_col_overlap(ws, cols["station"], curr_row, curr_row + needed - 1)
            merge_rng = f"{cols['station']}{curr_row}:{cols['station']}{curr_row + needed - 1}"
            ws.merge_cells(merge_rng)
            top_cell = ws[f"{cols['station']}{curr_row}"]
            top_cell.value = station_title(m_key)
            apply_center_style(top_cell)

        for idx, r_data in enumerate(data):
            if not meta["station_merge"]:
                cell = ws[f"{cols['station']}{curr_row}"]
                cell.value = station_title(m_key)
                apply_center_style(cell)
            
            safe_write(ws, curr_row, cols["location"], region_display(r_data["region"]))
            prog_val = r_data.get("program_num", 0)
            safe_write(ws, curr_row, cols["program"], int(prog_val))

            if format_type == "Dongwu":
                safe_write(ws, curr_row, cols["daypart"], r_data["daypart"])
                if m_key == "å®¶æ¨‚ç¦": safe_write(ws, curr_row, cols["seconds"], f"{r_data['seconds']}ç§’")
                else: safe_write(ws, curr_row, cols["seconds"], int(r_data["seconds"]))
                
                safe_write(ws, curr_row, cols["rate"], r_data["rate_display"])
                safe_write(ws, curr_row, cols["pkg"], r_data["pkg_display"])
            else:
                safe_write(ws, curr_row, cols["daypart"], r_data["daypart"])
                safe_write(ws, curr_row, cols["seconds"], f"{r_data['seconds']}ç§’å»£å‘Š")
                if "pkg" in cols: safe_write(ws, curr_row, cols["pkg"], r_data["pkg_display"])

            set_schedule(ws, curr_row, meta["schedule_start_col"], meta["max_days"], r_data["schedule"])
            spot_sum = sum(r_data["schedule"][:meta["max_days"]])
            safe_write(ws, curr_row, meta["total_col"], spot_sum)
            curr_row += 1
            
        current_end_marker = start_row_orig - 1

    total_row = find_row_by_content(ws, meta["cols"]["station"], meta["total_label"])
    if total_row:
        eff_days = min((end_dt - start_dt).days + 1, meta["max_days"])
        daily_sums = [sum([x["schedule"][d] for x in rows if d < len(x["schedule"])]) for d in range(eff_days)]
        set_schedule(ws, total_row, meta["schedule_start_col"], meta["max_days"], daily_sums)
        safe_write(ws, total_row, meta["total_col"], sum(daily_sums))
        
        pkg_col = cols.get("pkg") or cols.get("proj_price")
        safe_write(ws, total_row, pkg_col, total_list_accum)

        lbl = meta["footer_labels"]
        make_fee = 10000 
        pos_make = find_row_by_content(ws, "B", lbl["make"])
        if pos_make:
            safe_write(ws, pos_make, pkg_col, make_fee)
        
        vat = int(round((total_list_accum + make_fee) * 0.05))
        pos_vat = find_row_by_content(ws, "B", lbl["vat"])
        if pos_vat: safe_write(ws, pos_vat, pkg_col, vat)
        
        pos_grand = find_row_by_content(ws, "B", lbl["grand"])
        if pos_grand: safe_write(ws, pos_grand, pkg_col, total_list_accum + make_fee + vat)

    rem_pos = find_row_by_content(ws, "B", "Remarksï¼š")
    if rem_pos:
        for i, rm in enumerate(remarks_list):
            ws.cell(rem_pos + 1 + i, 2).value = rm

    if format_type == "Dongwu":
        force_center_columns_range(ws, meta["force_center_cols"], 9, total_row)

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()

# =========================================================
# 6. HTML Preview
# =========================================================
def load_font_base64():
    font_path = "NotoSansTC-Regular.ttf"
    if os.path.exists(font_path):
        with open(font_path, "rb") as f: return base64.b64encode(f.read()).decode("utf-8")
    url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/TTF/TraditionalChinese/NotoSansTC-Regular.ttf"
    try:
        r = requests.get(url, timeout=15)
        if r.status_code == 200:
            with open(font_path, "wb") as f: f.write(r.content)
            return base64.b64encode(r.content).decode("utf-8")
    except: pass
    return None

def generate_html_preview(rows, days_cnt, start_dt, end_dt, c_name, p_display, format_type, remarks, total_list, grand_total, budget, prod):
    header_cls = "bg-dw-head" if format_type == "Dongwu" else "bg-sh-head"
    media_order = {"å…¨å®¶å»£æ’­": 1, "æ–°é®®è¦–": 2, "å®¶æ¨‚ç¦": 3}
    eff_days = min(days_cnt, 31)
    
    font_b64 = load_font_base64()
    font_face = f"@font-face {{ font-family: 'NotoSansTC'; src: url(data:font/ttf;base64,{font_b64}) format('truetype'); }}" if font_b64 else ""

    date_th1, date_th2 = "", ""
    curr = start_dt
    weekdays = ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "æ—¥"]
    for i in range(eff_days):
        wd = curr.weekday()
        bg = "bg-weekend" if (format_type == "Dongwu" and wd >= 5) else header_cls
        if format_type == "Shenghuo": bg = header_cls 
        date_th1 += f"<th class='{bg} col_day'>{curr.day}</th>"
        date_th2 += f"<th class='{bg} col_day'>{weekdays[wd]}</th>"
        curr += timedelta(days=1)

    if format_type == "Dongwu":
        cols_def = ["Station", "Location", "Program", "Day-part", "Size", "rate<br>(Net)", "Package-cost<br>(Net)"]
    else:
        cols_def = ["é »é“", "æ’­å‡ºåœ°å€", "æ’­å‡ºåº—æ•¸", "æ’­å‡ºæ™‚é–“", "ç§’æ•¸<br>è¦æ ¼", "å°ˆæ¡ˆåƒ¹<br>(Net)"]
    th_fixed = "".join([f"<th rowspan='2' class='{header_cls}'>{c}</th>" for c in cols_def])
    
    rows_sorted = sorted(rows, key=lambda x: (media_order.get(x["media"], 99), x["seconds"], REGIONS_ORDER.index(x["region"]) if x["region"] in REGIONS_ORDER else 99))
    tbody = ""
    media_counts = {}
    for r in rows_sorted: media_counts[r["media"]] = media_counts.get(r["media"], 0) + 1
    media_printed = {m: False for m in media_counts}

    for idx, r in enumerate(rows_sorted):
        m = r["media"]
        tbody += "<tr>"
        if not media_printed[m]:
            rowspan = media_counts[m]
            display_name = "å…¨å®¶ä¾¿åˆ©å•†åº—<br>é€šè·¯å»£æ’­å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "å…¨å®¶ä¾¿åˆ©å•†åº—<br>æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
            if format_type == "Shenghuo" and m == "å…¨å®¶å»£æ’­": display_name = "å…¨å®¶ä¾¿åˆ©å•†åº—<br>å»£æ’­é€šè·¯å»£å‘Š"
            if format_type == "Shenghuo": tbody += f"<td class='left'>{display_name}</td>"
            else: tbody += f"<td class='left' rowspan='{rowspan}'>{display_name}</td>"; media_printed[m] = True
        elif format_type == "Shenghuo":
             display_name = "å…¨å®¶ä¾¿åˆ©å•†åº—<br>å»£æ’­é€šè·¯å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "å…¨å®¶ä¾¿åˆ©å•†åº—<br>æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
             tbody += f"<td class='left'>{display_name}</td>"

        loc_txt = region_display(r['region'])
        if "åŒ—åŒ—åŸº" in loc_txt and "å»£æ’­" in r['media']: loc_txt = "åŒ—å€-åŒ—åŒ—åŸº+æ±"
        tbody += f"<td>{loc_txt}</td><td class='right'>{r.get('program_num','')}</td><td>{r['daypart']}</td>"
        sec_txt = f"{r['seconds']}ç§’" if format_type=="Dongwu" and m=="å®¶æ¨‚ç¦" else f"{r['seconds']}" if format_type=="Dongwu" else f"{r['seconds']}ç§’å»£å‘Š"
        tbody += f"<td>{sec_txt}</td>"
        
        rate = f"{r['rate_display']:,}" if isinstance(r['rate_display'], int) else r['rate_display']
        pkg = f"{r['pkg_display']:,}" if isinstance(r['pkg_display'], int) else r['pkg_display']
        
        if format_type == "Dongwu": tbody += f"<td class='right'>{rate}</td><td class='right'>{pkg}</td>"
        else: tbody += f"<td class='right'>{pkg}</td>"
        
        for d in r['schedule'][:eff_days]: tbody += f"<td>{d}</td>"
        tbody += f"<td class='bg-total'>{r['spots']}</td></tr>"

    totals = [sum([r["schedule"][d] for r in rows if d < len(r["schedule"])]) for d in range(eff_days)]
    colspan = 5
    empty_td = "<td></td>" if format_type == "Dongwu" else ""
    tfoot = f"<tr class='bg-total'><td colspan='{colspan}' class='right'>Total (List Price)</td>{empty_td}<td class='right'>{total_list:,}</td>"
    for t in totals: tfoot += f"<td>{t}</td>"
    tfoot += f"<td>{sum(totals)}</td></tr>"

    vat = int(round((budget + prod) * 0.05))
    footer_rows = f"<tr><td colspan='6' class='right'>è£½ä½œ</td><td class='right'>{prod:,}</td><td colspan='{eff_days+1}'></td></tr>"
    footer_rows += f"<tr><td colspan='6' class='right'>å°ˆæ¡ˆå„ªæƒ åƒ¹ (Budget)</td><td class='right' style='color:red; font-weight:bold;'>{budget:,}</td><td colspan='{eff_days+1}'></td></tr>"
    footer_rows += f"<tr><td colspan='6' class='right'>5% VAT</td><td class='right'>{vat:,}</td><td colspan='{eff_days+1}'></td></tr>"
    footer_rows += f"<tr class='bg-grand'><td colspan='6' class='right'>Grand Total</td><td class='right'>{grand_total:,}</td><td colspan='{eff_days+1}'></td></tr>"

    html_content = f"""
    <html><head><style>
    {font_face}
    body {{ font-family: 'NotoSansTC', sans-serif !important; font-size: 10px; }}
    table {{ width: 100%; border-collapse: collapse; }}
    th, td {{ border: 0.5pt solid #000; padding: 2px; text-align: center; white-space: nowrap; }}
    .bg-dw-head {{ background-color: #4472C4; color: white; -webkit-print-color-adjust: exact; }}
    .bg-sh-head {{ background-color: #BDD7EE; color: black; -webkit-print-color-adjust: exact; }}
    .bg-weekend {{ background-color: #FFD966; -webkit-print-color-adjust: exact; }}
    .bg-total   {{ background-color: #E2EFDA; -webkit-print-color-adjust: exact; }}
    .bg-grand   {{ background-color: #FFC107; -webkit-print-color-adjust: exact; }}
    .left {{ text-align: left; }}
    .right {{ text-align: right; }}
    .remarks {{ margin-top: 10px; font-size: 9px; text-align: left; white-space: pre-wrap; }}
    </style></head><body>
    <div style="margin-bottom:10px;">
        <div style="font-size:16px; font-weight:bold; text-align:center;">Media Schedule</div>
        <b>å®¢æˆ¶åç¨±ï¼š</b>{html_escape(c_name)} &nbsp; <b>Productï¼š</b>{html_escape(p_display)}<br>
        <b>Periodï¼š</b>{start_dt.strftime('%Y. %m. %d')} - {end_dt.strftime('%Y. %m. %d')} &nbsp; <b>Mediumï¼š</b>å…¨å®¶å»£æ’­/æ–°é®®è¦–/å®¶æ¨‚ç¦
    </div>
    <table>
        <thead><tr>{th_fixed}{date_th1}<th class='{header_cls}' rowspan='2'>æª”æ¬¡</th></tr><tr>{date_th2}</tr></thead>
        <tbody>{tbody}{tfoot}{footer_rows}</tbody>
    </table>
    <div class="remarks"><b>Remarksï¼š</b><br>{"<br>".join([html_escape(x) for x in remarks])}</div>
    </body></html>
    """
    return html_content

# =========================================================
# 7. UI Main
# =========================================================
st.title("ğŸ“º åª’é«” Cue è¡¨ç”Ÿæˆå™¨ (v74.1)")

auto_tpl, source, msgs = load_default_template()
template_bytes = auto_tpl

if auto_tpl:
    st.success(f"âœ… å·²è¼‰å…¥ç³»çµ±å…¬ç‰ˆ ({source})")
else:
    st.warning("âš ï¸ ç„¡æ³•è¼‰å…¥å…¬ç‰ˆï¼Œè«‹æ‰‹å‹•ä¸Šå‚³")
    tpl = st.file_uploader("ä¸Šå‚³ Excel æ¨¡æ¿", type=["xlsx"])
    if tpl: template_bytes = tpl.read()

st.markdown("### 1. é¸æ“‡æ ¼å¼")
format_type = st.radio("", ["Dongwu", "Shenghuo"], horizontal=True, label_visibility="collapsed")

st.markdown("### 2. åŸºæœ¬è³‡æ–™è¨­å®š")
c1, c2, c3 = st.columns(3)
with c1: client_name = st.text_input("å®¢æˆ¶åç¨±", "è¬åœ‹é€šè·¯")
with c2: product_name = st.text_input("ç”¢å“åç¨±", "çµ±ä¸€å¸ƒä¸")
with c3: total_budget_input = st.number_input("ç¸½é ç®— (æœªç¨… Net)", value=1000000, step=10000)

c4, c5 = st.columns(2)
with c4: start_date = st.date_input("é–‹å§‹æ—¥", datetime(2026, 1, 1))
with c5: end_date = st.date_input("çµæŸæ—¥", datetime(2026, 1, 31))
days_count = (end_date - start_date).days + 1
st.info(f"ğŸ“… èµ°æœŸå…± **{days_count}** å¤©")

with st.expander("ğŸ“ å‚™è¨»æ¬„ä½è¨­å®š (Remarks)", expanded=False):
    rc1, rc2, rc3 = st.columns(3)
    sign_deadline = rc1.date_input("å›ç°½æˆªæ­¢æ—¥", datetime.now() + timedelta(days=3))
    billing_month = rc2.text_input("è«‹æ¬¾æœˆä»½", "2026å¹´2æœˆ")
    payment_date = rc3.date_input("ä»˜æ¬¾å…Œç¾æ—¥", datetime(2026, 3, 31))

st.markdown("### 3. åª’é«”æŠ•æ”¾è¨­å®š")

if "rad_share" not in st.session_state: st.session_state.rad_share = 100
if "fv_share" not in st.session_state: st.session_state.fv_share = 0
if "cf_share" not in st.session_state: st.session_state.cf_share = 0

def on_media_change():
    active = []
    if st.session_state.get("cb_rad"): active.append("rad_share")
    if st.session_state.get("cb_fv"): active.append("fv_share")
    if st.session_state.get("cb_cf"): active.append("cf_share")
    if not active: return
    share = 100 // len(active)
    for key in active: st.session_state[key] = share
    rem = 100 - sum([st.session_state[k] for k in active])
    st.session_state[active[0]] += rem

def on_slider_change(changed_key):
    active = []
    if st.session_state.get("cb_rad"): active.append("rad_share")
    if st.session_state.get("cb_fv"): active.append("fv_share")
    if st.session_state.get("cb_cf"): active.append("cf_share")
    others = [k for k in active if k != changed_key]
    if not others: st.session_state[changed_key] = 100
    elif len(others) == 1:
        val = st.session_state[changed_key]
        st.session_state[others[0]] = max(0, 100 - val)
    elif len(others) == 2:
        val = st.session_state[changed_key]
        rem = max(0, 100 - val)
        k1, k2 = others[0], others[1]
        sum_others = st.session_state[k1] + st.session_state[k2]
        if sum_others == 0: st.session_state[k1] = rem // 2; st.session_state[k2] = rem - st.session_state[k1]
        else:
            ratio = st.session_state[k1] / sum_others
            st.session_state[k1] = int(rem * ratio)
            st.session_state[k2] = rem - st.session_state[k1]

st.write("è«‹å‹¾é¸è¦æŠ•æ”¾çš„åª’é«”ï¼š")
col_cb1, col_cb2, col_cb3 = st.columns(3)
with col_cb1: is_rad = st.checkbox("å…¨å®¶å»£æ’­", value=True, key="cb_rad", on_change=on_media_change)
with col_cb2: is_fv = st.checkbox("æ–°é®®è¦–", value=False, key="cb_fv", on_change=on_media_change)
with col_cb3: is_cf = st.checkbox("å®¶æ¨‚ç¦", value=False, key="cb_cf", on_change=on_media_change)

m1, m2, m3 = st.columns(3)
config = {}

if is_rad:
    with m1:
        st.markdown("#### ğŸ“» å…¨å®¶å»£æ’­")
        is_nat = st.checkbox("å…¨çœè¯æ’­", True, key="rad_nat")
        regs = ["å…¨çœ"] if is_nat else st.multiselect("å€åŸŸ", REGIONS_ORDER, default=REGIONS_ORDER, key="rad_reg")
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [20], key="rad_sec")
        st.slider("é ç®— %", 0, 100, key="rad_share", on_change=on_slider_change, args=("rad_share",))
        
        # [NEW] ç§’æ•¸ä½”æ¯”åˆ†é…
        sec_shares = {}
        if len(secs) > 1:
            st.caption("åˆ†é…ç§’æ•¸ä½”æ¯”")
            rem = 100
            for s in sorted(secs)[:-1]:
                v = st.slider(f"{s}ç§’ %", 0, rem, int(rem/2), key=f"rs_{s}")
                sec_shares[s] = v; rem -= v
            sec_shares[sorted(secs)[-1]] = rem
        elif secs: sec_shares[secs[0]] = 100
        
        config["å…¨å®¶å»£æ’­"] = {"is_national": is_nat, "regions": regs, "sec_shares": sec_shares, "share": st.session_state.rad_share}

if is_fv:
    with m2:
        st.markdown("#### ğŸ“º æ–°é®®è¦–")
        is_nat = st.checkbox("å…¨çœè¯æ’­", False, key="fv_nat")
        regs = ["å…¨çœ"] if is_nat else st.multiselect("å€åŸŸ", REGIONS_ORDER, default=["åŒ—å€"], key="fv_reg")
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [10], key="fv_sec")
        st.slider("é ç®— %", 0, 100, key="fv_share", on_change=on_slider_change, args=("fv_share",))
        
        # [NEW] ç§’æ•¸ä½”æ¯”åˆ†é…
        sec_shares = {}
        if len(secs) > 1:
            st.caption("åˆ†é…ç§’æ•¸ä½”æ¯”")
            rem = 100
            for s in sorted(secs)[:-1]:
                v = st.slider(f"{s}ç§’ %", 0, rem, int(rem/2), key=f"fs_{s}")
                sec_shares[s] = v; rem -= v
            sec_shares[sorted(secs)[-1]] = rem
        elif secs: sec_shares[secs[0]] = 100
        
        config["æ–°é®®è¦–"] = {"is_national": is_nat, "regions": regs, "sec_shares": sec_shares, "share": st.session_state.fv_share}

if is_cf:
    with m3:
        st.markdown("#### ğŸ›’ å®¶æ¨‚ç¦")
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [20], key="cf_sec")
        st.slider("é ç®— %", 0, 100, key="cf_share", on_change=on_slider_change, args=("cf_share",))
        
        # [NEW] ç§’æ•¸ä½”æ¯”åˆ†é…
        sec_shares = {}
        if len(secs) > 1:
            st.caption("åˆ†é…ç§’æ•¸ä½”æ¯”")
            rem = 100
            for s in sorted(secs)[:-1]:
                v = st.slider(f"{s}ç§’ %", 0, rem, int(rem/2), key=f"cs_{s}")
                sec_shares[s] = v; rem -= v
            sec_shares[sorted(secs)[-1]] = rem
        elif secs: sec_shares[secs[0]] = 100
        
        config["å®¶æ¨‚ç¦"] = {"regions": ["å…¨çœ"], "sec_shares": sec_shares, "share": st.session_state.cf_share}

if config:
    rows, total_list_accum, logs = calculate_plan_data(config, total_budget_input, days_count)
    
    prod_cost = 10000
    vat = int(round((total_budget_input + prod_cost) * 0.05))
    grand_total = total_budget_input + prod_cost + vat
    p_str = f"{'ã€'.join([f'{s}ç§’' for s in sorted(list(set(r['seconds'] for r in rows)))])} {product_name}"
    rem = get_remarks_text(sign_deadline, billing_month, payment_date)

    # 1. ç”¢ç”Ÿ HTML (ä¹Ÿæ˜¯ PDF çš„ä¾†æº)
    html_preview = generate_html_preview(rows, days_count, start_date, end_date, client_name, p_str, format_type, rem, total_list_accum, grand_total, total_budget_input, prod_cost)
    st.components.v1.html(html_preview, height=700, scrolling=True)

    with st.expander("ğŸ’¡ ç³»çµ±é‹ç®—é‚è¼¯èªªæ˜ (Debug Panel)", expanded=False):
        st.markdown("#### 1. æœ¬æ¬¡é ç®—åˆ†é…è©³ç´°é‹ç®—")
        for log in logs:
            st.markdown(f"**{log['Media']}**")
            st.markdown(f"- é ç®—: {log['Budget']}")
            st.markdown(f"- å…¬å¼: {log['Formula']}")
            st.markdown(f"- åŸå§‹å–®åƒ¹: {log['Net_Unit']} | æ‡²ç½°: {log['Penalty']}")
            st.markdown(f"- æœ€çµ‚å–®åƒ¹: {log['Final_Cost']} | åŸ·è¡Œæª”æ¬¡: **{log['Final_Spots']}**")
            st.divider()

    # 2. ç”¢ç”Ÿæª”æ¡ˆ
    if template_bytes and rows:
        try:
            # Excel (ä½¿ç”¨ OpenPyXL å¡«å¯«æ¨¡æ¿)
            xlsx = generate_excel_from_template(format_type, start_date, end_date, client_name, p_str, rows, rem, template_bytes, total_list_accum)
            if xlsx:
                st.download_button("ä¸‹è¼‰ Excel", xlsx, f"Cue_{safe_filename(client_name)}.xlsx")
                
                # PDF (å„ªå…ˆä½¿ç”¨ LibreOfficeï¼Œå¤±æ•—æ‰é¡¯ç¤ºè­¦å‘Š)
                pdf_bytes, method, err = xlsx_bytes_to_pdf_bytes(xlsx)
                if pdf_bytes:
                    st.download_button(f"ä¸‹è¼‰ PDF ({method})", pdf_bytes, f"Cue_{safe_filename(client_name)}.pdf")
                else:
                    st.warning(f"æœ¬åœ°è½‰æª”å¤±æ•—ï¼Œåˆ‡æ›è‡³ WeasyPrint: {err}")
                    pdf_bytes, err = html_to_pdf_weasyprint(html_preview)
                    if pdf_bytes:
                        st.download_button("ä¸‹è¼‰ PDF (HTML Render)", pdf_bytes, f"Cue_{safe_filename(client_name)}.pdf")
                    else:
                        st.error(f"PDF ç”¢å‡ºå¤±æ•—: {err}")
        except Exception as e: st.error(f"Excel ç”¢å‡ºéŒ¯èª¤: {e}")
