import streamlit as st
import math
import io
import os
import shutil
import tempfile
import subprocess
import re
import base64
from datetime import timedelta, datetime, date
from copy import copy

import requests
import openpyxl
from openpyxl.utils import column_index_from_string
from openpyxl.cell.cell import MergedCell
from openpyxl.formula.translate import Translator
from openpyxl.styles import Alignment, Font, Border, Side, PatternFill

# =========================================================
# 0. åŸºç¤å·¥å…·
# =========================================================
def parse_count_to_int(x):
    if x is None: return 0
    if isinstance(x, (int, float)): return int(x)
    s = str(x)
    m = re.findall(r"[\d,]+", s)
    if not m: return 0
    return int(m[0].replace(",", ""))

def safe_filename(name: str) -> str:
    return re.sub(r'[\\/*?:"<>|]', "_", name).strip()

def html_escape(s):
    if s is None: return ""
    return str(s).replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;").replace("'", "&#39;")

# =========================================================
# 1. é é¢è¨­å®š & è‡ªå‹•è¼‰å…¥
# =========================================================
st.set_page_config(layout="wide", page_title="Cue Sheet Pro v63.6 (Clean PDF)")

GOOGLE_DRIVE_FILE_ID = "11R1SA_hpFD5O_MGmYeh4BdtcUhK2bPta"
DEFAULT_FILENAME = "1209-Cueè¡¨ç›¸é—œè³‡æ–™.xlsx"

@st.cache_resource(ttl=600)
def load_default_template():
    status_msg = []
    if GOOGLE_DRIVE_FILE_ID:
        url = f"https://drive.google.com/uc?export=download&id={GOOGLE_DRIVE_FILE_ID}"
        try:
            r = requests.get(url, timeout=20, allow_redirects=True)
            if r.status_code == 200:
                if b"<!DOCTYPE html>" in r.content[:500]:
                    status_msg.append("âš ï¸ Drive ä¸‹è¼‰æ¬Šé™å—é™")
                else:
                    return r.content, "é›²ç«¯ç¡¬ç¢Ÿ (Google Drive)", status_msg
        except Exception as e:
            status_msg.append(f"âŒ é€£ç·šéŒ¯èª¤: {e}")

    if os.path.exists(DEFAULT_FILENAME):
        try:
            with open(DEFAULT_FILENAME, "rb") as f:
                return f.read(), "ç³»çµ±ä¸»æ©Ÿ (Local)", status_msg
        except: pass
    
    return None, None, status_msg

# =========================================================
# 2. GPT æ ¸å¿ƒå¼•æ“ï¼šExcel è½‰ PDF (æœ€æ“¬çœŸæ–¹æ¡ˆ)
# =========================================================
def find_soffice_path():
    """å°‹æ‰¾ LibreOffice åŸ·è¡Œæª”"""
    soffice = shutil.which("soffice") or shutil.which("libreoffice")
    if soffice: return soffice
    
    # Windows å¸¸è¦‹è·¯å¾‘
    if os.name == "nt":
        candidates = [
            r"C:\Program Files\LibreOffice\program\soffice.exe",
            r"C:\Program Files (x86)\LibreOffice\program\soffice.exe",
        ]
        for p in candidates:
            if os.path.exists(p): return p
    return None

def xlsx_bytes_to_pdf_bytes(xlsx_bytes: bytes):
    """
    GPT çš„å¼·åŠ›é‚è¼¯ï¼šç›´æ¥å°‡ Excel è½‰ç‚º PDFï¼Œç¢ºä¿ 100% æ“¬çœŸã€‚
    """
    # 1. Windows Local: å˜—è©¦ä½¿ç”¨å·²å®‰è£çš„ Excel
    if os.name == "nt":
        try:
            import win32com.client
            with tempfile.TemporaryDirectory() as tmp:
                xlsx_path = os.path.join(tmp, "cue.xlsx")
                pdf_path = os.path.join(tmp, "cue.pdf")
                with open(xlsx_path, "wb") as f: f.write(xlsx_bytes)

                excel = win32com.client.DispatchEx("Excel.Application")
                excel.Visible = False
                excel.DisplayAlerts = False
                wb = None
                try:
                    wb = excel.Workbooks.Open(xlsx_path)
                    # 0 = xlTypePDF
                    wb.ExportAsFixedFormat(0, pdf_path)
                except: pass
                finally:
                    if wb: 
                        try: wb.Close(False)
                        except: pass
                    try: excel.Quit()
                    except: pass

                if os.path.exists(pdf_path):
                    with open(pdf_path, "rb") as f: return f.read(), "Excel App (Local)", ""
        except: pass 

    # 2. LibreOffice (é©ç”¨æ–¼ Streamlit Cloud æˆ–æœ‰è£ LibreOffice çš„é›»è…¦)
    soffice = find_soffice_path()
    if soffice:
        try:
            with tempfile.TemporaryDirectory() as tmp:
                xlsx_path = os.path.join(tmp, "cue.xlsx")
                with open(xlsx_path, "wb") as f: f.write(xlsx_bytes)

                # åŸ·è¡Œè½‰æª”æŒ‡ä»¤
                subprocess.run(
                    [soffice, "--headless", "--nologo", "--convert-to", "pdf", "--outdir", tmp, xlsx_path],
                    capture_output=True, timeout=60
                )
                
                # å°‹æ‰¾ç”¢å‡ºçš„ PDF
                pdf_path = os.path.join(tmp, "cue.pdf")
                if not os.path.exists(pdf_path):
                    for fn in os.listdir(tmp):
                        if fn.endswith(".pdf"): pdf_path = os.path.join(tmp, fn); break
                
                if os.path.exists(pdf_path):
                    with open(pdf_path, "rb") as f: return f.read(), "LibreOffice", ""
                
                return None, "Fail", "LibreOffice è½‰æª”ç„¡è¼¸å‡º"
        except Exception as e:
            return None, "Fail", str(e)

    return None, "Fail", "ç„¡å¯ç”¨çš„ Excel è½‰æª”å¼•æ“ (éœ€å®‰è£ LibreOffice)"

# =========================================================
# 3. WeasyPrint Fallback
# =========================================================
def html_to_pdf_fallback(html_str, font_b64):
    try: 
        from weasyprint import HTML, CSS
        from weasyprint.text.fonts import FontConfiguration
        
        font_config = FontConfiguration()
        css_str = """
        @page { size: A4 landscape; margin: 0.5cm; }
        body { font-family: 'NotoSansTC', sans-serif !important; font-size: 8pt; }
        table { width: 100%; border-collapse: collapse; }
        th, td { border: 0.5pt solid #555; padding: 2px; text-align: center; white-space: nowrap; }
        .bg-dw-head { background-color: #4472C4; color: white; }
        .bg-sh-head { background-color: #BDD7EE; color: black; }
        .bg-weekend { background-color: #FFD966; }
        .bg-total   { background-color: #FFF2CC; }
        tr { page-break-inside: avoid; }
        """
        if font_b64:
            css_str = f"@font-face {{ font-family: 'NotoSansTC'; src: url(data:font/ttf;base64,{font_b64}) format('truetype'); }} " + css_str
            
        pdf_bytes = HTML(string=html_str).write_pdf(stylesheets=[CSS(string=css_str)], font_config=font_config)
        return pdf_bytes, ""
    except Exception as e:
        return None, str(e)

# =========================================================
# 4. è³‡æ–™åº«
# =========================================================
STORE_COUNTS_RAW = {
    "å…¨çœ": "4,437åº—", "åŒ—å€": "1,649åº—", "æ¡ƒç«¹è‹—": "779åº—", "ä¸­å€": "839åº—", "é›²å˜‰å—": "499åº—", "é«˜å±": "490åº—", "æ±å€": "181åº—",
    "æ–°é®®è¦–_å…¨çœ": "3,124é¢", "æ–°é®®è¦–_åŒ—å€": "1,127é¢", "æ–°é®®è¦–_æ¡ƒç«¹è‹—": "616é¢", "æ–°é®®è¦–_ä¸­å€": "528é¢",
    "æ–°é®®è¦–_é›²å˜‰å—": "365é¢", "æ–°é®®è¦–_é«˜å±": "405é¢", "æ–°é®®è¦–_æ±å€": "83é¢",
    "å®¶æ¨‚ç¦_é‡è²©": "67åº—", "å®¶æ¨‚ç¦_è¶…å¸‚": "250åº—"
}
STORE_COUNTS_NUM = {k: parse_count_to_int(v) for k, v in STORE_COUNTS_RAW.items()}
REGIONS_ORDER = ["åŒ—å€", "æ¡ƒç«¹è‹—", "ä¸­å€", "é›²å˜‰å—", "é«˜å±", "æ±å€"]
DURATIONS = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]

PRICING_DB = {
    "å…¨å®¶å»£æ’­": { "Std_Spots": 480, "Day_Part": "00:00-24:00", 
        "å…¨çœ": [400000, 320000], "åŒ—å€": [250000, 200000], "æ¡ƒç«¹è‹—": [150000, 120000], "ä¸­å€": [150000, 120000],
        "é›²å˜‰å—": [100000, 80000], "é«˜å±": [100000, 80000], "æ±å€": [62500, 50000] },
    "æ–°é®®è¦–": { "Std_Spots": 504, "Day_Part": "07:00-22:00", 
        "å…¨çœ": [150000, 120000], "åŒ—å€": [150000, 120000], "æ¡ƒç«¹è‹—": [120000, 96000], "ä¸­å€": [90000, 72000],
        "é›²å˜‰å—": [75000, 60000], "é«˜å±": [75000, 60000], "æ±å€": [45000, 36000] },
    "å®¶æ¨‚ç¦": {
        "é‡è²©_å…¨çœ": {"List": 300000, "Net": 250000, "Std_Spots": 420, "Day_Part": "09:00-23:00"},
        "è¶…å¸‚_å…¨çœ": {"List": 100000, "Net": 80000, "Std_Spots": 720, "Day_Part": "00:00-24:00"} }
}

SEC_FACTORS = {
    "å…¨å®¶å»£æ’­": {30: 1.0, 20: 0.85, 15: 0.65, 10: 0.5, 5: 0.25},
    "æ–°é®®è¦–": {30: 3.0, 20: 2.0, 15: 1.5, 10: 1.0, 5: 0.5},
    "å®¶æ¨‚ç¦": {30: 1.5, 20: 1.0, 15: 0.85, 10: 0.65, 5: 0.35}
}

def get_sec_factor(media_type, seconds): return SEC_FACTORS.get(media_type, {}).get(seconds, 1.0)

def calculate_schedule(total_spots, days):
    if days <= 0: return []
    if total_spots % 2 != 0: total_spots += 1
    half_spots = total_spots // 2
    base, rem = divmod(half_spots, days)
    half_schedule = [base + (1 if i < rem else 0) for i in range(days)]
    return [x * 2 for x in half_schedule]

def get_remarks_text(sign_deadline, billing_month, payment_date):
    d_str = sign_deadline.strftime("%Y/%m/%d (%a) %H:%M") if sign_deadline else "____/__/__ (__) 12:00"
    p_str = payment_date.strftime("%Y/%m/%d") if payment_date else "____/__/__"
    return [
        f"1.è«‹æ–¼ {d_str}å‰ å›ç°½åŠé€²å–®ï¼Œæ–¹å¯é †åˆ©ä¸Šæª”ã€‚",
        "2.ä»¥ä¸Šç¯€ç›®åç¨±å¦‚æœ‰ç•°å‹•ï¼Œä»¥ä¸Šæª”æ™‚ç¯€ç›®åç¨±ç‚ºä¸»ï¼Œå¦‚é‡æ™‚æ®µæ»¿æª”ï¼Œä¸Šæª”æ™‚é–“æŒªå¾Œæˆ–æ›´æ›è‡³åŒç´šæ™‚æ®µã€‚",
        "3.é€šè·¯åº—é‹ªæ•¸èˆ‡é–‹æ©Ÿç‡é–‹æ©Ÿç‡è‡³å°‘ä¸ƒæˆ(ä»¥ä¸Š)ã€‚æ¯æ—¥å› åŠ ç›Ÿæ•¸èª¿æ•´ï¼Œæˆ–é‡åº—èˆ–å¹´åº¦å­£åº¦æ”¹è£ã€è¨­å‚™ç¶­è­·å‡ç´šåŠä¿ä¿®ç­‰ç‹€æ³ï¼Œæœƒæœ‰ä¸€å®šå¹…åº¦å¢æ¸›ã€‚",
        "4.è¨—æ’­æ–¹éœ€æ–¼ä¸Šæª”å‰ 5 å€‹å·¥ä½œå¤©ï¼Œæä¾›å»£å‘Šå¸¶(mp3)ã€å½±ç‰‡/å½±åƒ 1920x1080 (mp4)ã€‚",
        f"5.é›™æ–¹åŒæ„è²»ç”¨è«‹æ¬¾æœˆä»½ : {billing_month}ï¼Œå¦‚æœ‰ä¿®æ­£å¿…è¦ï¼Œå°‡å¦è¡ŒE-Mailå‘ŠçŸ¥ï¼Œä¸¦è¦–ç‚ºæ­£å¼åˆç´„ä¹‹ä¸€éƒ¨åˆ†ã€‚",
        f"6.ä»˜æ¬¾å…Œç¾æ—¥æœŸï¼š{p_str}"
    ]

REGION_DISPLAY_6 = {
    "åŒ—å€": "åŒ—å€-åŒ—åŒ—åŸº", "æ¡ƒç«¹è‹—": "æ¡ƒå€-æ¡ƒç«¹è‹—", "ä¸­å€": "ä¸­å€-ä¸­å½°æŠ•",
    "é›²å˜‰å—": "é›²å˜‰å—å€-é›²å˜‰å—", "é«˜å±": "é«˜å±å€-é«˜å±", "æ±å€": "æ±å€-å®œèŠ±æ±",
    "å…¨çœé‡è²©": "å…¨çœé‡è²©", "å…¨çœè¶…å¸‚": "å…¨çœè¶…å¸‚",
}
def region_display(region: str) -> str: return REGION_DISPLAY_6.get(region, region)

# =========================================================
# 5. Excel ç”Ÿæˆæ¨¡çµ„
# =========================================================
def _get_master_cell(ws, cell):
    if not isinstance(cell, MergedCell): return cell
    for mr in ws.merged_cells.ranges:
        if mr.min_row <= cell.row <= mr.max_row and mr.min_col <= cell.column <= mr.max_col:
            return ws.cell(row=mr.min_row, column=mr.min_col)
    return None

def safe_write_rc(ws, row, col, value):
    cell = ws.cell(row=row, column=col)
    if isinstance(cell, MergedCell):
        master = _get_master_cell(ws, cell)
        if master: master.value = value
    else: cell.value = value

def safe_write(ws, addr, value):
    cell = ws[addr]
    if isinstance(cell, MergedCell):
        master = _get_master_cell(ws, cell)
        if master: master.value = value
    else: cell.value = value

def apply_center_style(cell):
    al = cell.alignment or Alignment()
    cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True, indent=al.indent)

def copy_row_with_style_fix(ws, src_row, dst_row, max_col):
    ws.row_dimensions[dst_row].height = ws.row_dimensions[src_row].height
    row_shift = dst_row - src_row
    for c in range(1, max_col + 1):
        sc = ws.cell(src_row, c)
        dc = ws.cell(dst_row, c)
        if sc.has_style:
            dc.font = copy(sc.font)
            dc.border = copy(sc.border)
            dc.fill = copy(sc.fill)
            dc.number_format = sc.number_format
            dc.protection = copy(sc.protection)
            dc.alignment = copy(sc.alignment)
        v = sc.value
        if isinstance(v, str) and v.startswith("="):
            try: dc.value = Translator(v, origin=sc.coordinate).translate_formula(row_shift=row_shift, col_shift=0)
            except: dc.value = v
        else: dc.value = v

def force_center_columns_range(ws, col_letters, start_row, end_row):
    if start_row is None or end_row is None: return
    for r in range(start_row, end_row + 1):
        for col in col_letters:
            addr = f"{col}{r}"
            cell = ws[addr]
            if isinstance(cell, MergedCell):
                master = _get_master_cell(ws, cell)
                if master: cell = master
                else: continue
            apply_center_style(cell)

def unmerge_col_overlap(ws, col_letter, start_row, end_row):
    st_col = column_index_from_string(col_letter)
    to_unmerge = []
    for mr in list(ws.merged_cells.ranges):
        if mr.min_col == st_col and mr.max_col == st_col:
            if not (mr.max_row < start_row or mr.min_row > end_row):
                to_unmerge.append(str(mr))
    for s in set(to_unmerge):
        try: ws.unmerge_cells(s)
        except: pass

def set_schedule(ws, row, start_col_letter, max_days, schedule_list):
    start_col = column_index_from_string(start_col_letter)
    for i in range(max_days):
        v = schedule_list[i] if (schedule_list and i < len(schedule_list)) else None
        safe_write_rc(ws, row, start_col + i, v)

def find_cell_exact(ws, text):
    for row in ws.iter_rows():
        for cell in row:
            if cell.value == text: return cell.row, cell.column
    return None

def find_first_row_contains(ws, col_letter, keyword):
    col_idx = column_index_from_string(col_letter)
    for r in range(1, ws.max_row + 1):
        v = ws.cell(r, col_idx).value
        if isinstance(v, str) and keyword in v: return r
    return None

SHEET_META = {
    "Dongwu": {
        "sheet_name": "æ±å³-æ ¼å¼", "date_start_cell": "I7", "schedule_start_col": "I",
        "max_days": 31, "total_col": "AN",
        "anchors": {"å…¨å®¶å»£æ’­": "é€šè·¯å»£æ’­å»£å‘Š", "æ–°é®®è¦–": "æ–°é®®è¦–å»£å‘Š", "å®¶æ¨‚ç¦": "å®¶æ¨‚ç¦"},
        "header_cells": {"client": "C3", "product": "C4", "period": "C5", "medium": "C6", "month": "I6"},
        "cols": {"station": "B", "location": "C", "program": "D", "daypart": "E", "seconds": "F", "rate": "G", "pkg": "H"},
        "header_override": {"G7": "rate\n(List)", "H7": "Package-cost\n(List)"},
        "station_merge": True, "total_label": "Total",
        "footer_labels": {"make": "è£½ä½œ", "vat": "5% VAT", "grand": "Grand Total"},
        "force_center_cols": ["E", "F", "G", "H"], 
    },
    "Shenghuo": {
        "sheet_name": "è²æ´»-æ ¼å¼", "date_start_cell": "G7", "schedule_start_col": "G",
        "max_days": 23, "total_col": "AD",
        "anchors": {"å…¨å®¶å»£æ’­": "å»£æ’­é€šè·¯å»£å‘Š", "æ–°é®®è¦–": "æ–°é®®è¦–å»£å‘Š", "å®¶æ¨‚ç¦": "å®¶æ¨‚ç¦"},
        "header_cells": {"client": "C5", "product": "C6", "month": "G6"},
        "cols": {"station": "B", "location": "C", "program": "D", "daypart": "E", "seconds": "F", "proj_price": "AF"},
        "header_override": {"AF7": "å°ˆæ¡ˆåƒ¹\n(List)"}, 
        "station_merge": False, "total_label": "Total",
        "footer_labels": {"make": "è£½ä½œ", "vat": "5% VAT", "grand": "Grand Total"},
        "force_center_cols": [],
    }
}

def generate_excel_from_template(format_type, start_dt, end_dt, client_name, product_display_str, rows, remarks_list, template_bytes):
    meta = SHEET_META[format_type]
    wb = openpyxl.load_workbook(io.BytesIO(template_bytes))
    if meta["sheet_name"] not in wb.sheetnames: raise ValueError(f"ç¼ºå°‘åˆ†é ï¼š{meta['sheet_name']}")
    
    # ğŸŒŸ é—œéµä¿®æ­£ï¼šä¿ç•™ç›®æ¨™å·¥ä½œè¡¨ï¼Œåˆªé™¤å…¶ä»–æ‰€æœ‰åˆ†é  (é˜²æ­¢è½‰ PDF æ™‚å°å‡ºä¸ç›¸é—œçš„é é¢)
    target_sheet = meta["sheet_name"]
    for s in list(wb.sheetnames):
        if s != target_sheet:
            del wb[s]
            
    ws = wb[target_sheet]

    hc = meta["header_cells"]
    if "client" in hc: safe_write(ws, hc["client"], client_name)
    if "product" in hc: safe_write(ws, hc["product"], product_display_str)
    if "period" in hc: safe_write(ws, hc["period"], f"{start_dt.strftime('%Y. %m. %d')} - {end_dt.strftime('%Y.%m. %d')}")
    if "medium" in hc: safe_write(ws, hc["medium"], " ".join(sorted(set([r["media_type"] for r in rows]))))
    if "month" in hc: safe_write(ws, hc["month"], f" {start_dt.month}æœˆ")
    safe_write(ws, meta["date_start_cell"], datetime(start_dt.year, start_dt.month, start_dt.day))

    for addr, text in meta.get("header_override", {}).items():
        safe_write(ws, addr, text)

    total_cell = find_cell_exact(ws, meta["total_label"])
    if not total_cell: raise ValueError("æ‰¾ä¸åˆ° Total")
    total_row = total_cell[0]

    cols = meta["cols"]
    sec_start = {}
    for m_key, kw in meta["anchors"].items():
        r0 = find_first_row_contains(ws, cols["station"], kw)
        if r0: sec_start[m_key] = r0
    
    sec_order = sorted(sec_start.items(), key=lambda x: x[1])
    sec_ranges = []
    for i, (k, sr) in enumerate(sec_order):
        next_start = sec_order[i + 1][1] if i + 1 < len(sec_order) else total_row
        sec_ranges.append((k, sr, next_start - 1))

    reg_map = {r: i for i, r in enumerate(REGIONS_ORDER + ["å…¨çœé‡è²©", "å…¨çœè¶…å¸‚"])}
    def sort_key(x): return (x["seconds"], reg_map.get(x["region"], 999))
    grouped = {
        "å…¨å®¶å»£æ’­": sorted([r for r in rows if r["media_type"] == "å…¨å®¶å»£æ’­"], key=sort_key),
        "æ–°é®®è¦–": sorted([r for r in rows if r["media_type"] == "æ–°é®®è¦–"], key=sort_key),
        "å®¶æ¨‚ç¦": sorted([r for r in rows if r["media_type"] == "å®¶æ¨‚ç¦"], key=sort_key),
    }

    for k, sr, er in sorted(sec_ranges, key=lambda x: x[1], reverse=True):
        data = grouped.get(k, [])
        needed = len(data)
        if needed <= 0: continue
        existing = er - sr + 1
        if needed > existing:
            ws.insert_rows(er + 1, amount=needed - existing)
            for rr in range(er + 1, er + 1 + needed - existing):
                copy_row_with_style_fix(ws, sr, rr, ws.max_column)

    total_row = find_cell_exact(ws, meta["total_label"])[0]
    sec_start = {}
    for m_key, kw in meta["anchors"].items():
        r0 = find_first_row_contains(ws, cols["station"], kw)
        if r0: sec_start[m_key] = r0
    sec_order = sorted(sec_start.items(), key=lambda x: x[1])
    sec_ranges = []
    for i, (k, sr) in enumerate(sec_order):
        next_start = sec_order[i + 1][1] if i + 1 < len(sec_order) else total_row
        sec_ranges.append((k, sr, next_start - 1))

    def station_title(m):
        prefix = "å…¨å®¶ä¾¿åˆ©å•†åº—\n" if m != "å®¶æ¨‚ç¦" else ""
        name = "é€šè·¯å»£æ’­å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
        if format_type == "Shenghuo" and m == "å…¨å®¶å»£æ’­": name = "å»£æ’­é€šè·¯å»£å‘Š"
        return prefix + name

    written_rows = []
    for m, sr, er in sec_ranges:
        data = grouped.get(m, [])
        if not data: continue
        
        if meta["station_merge"]:
            unmerge_col_overlap(ws, cols["station"], sr, er)
            merge_rng = f"{cols['station']}{sr}:{cols['station']}{sr + len(data) - 1}"
            ws.merge_cells(merge_rng)
            top_cell = ws[f"{cols['station']}{sr}"]
            top_cell.value = station_title(m)
            apply_center_style(top_cell)

        row_ptr = sr
        for r in data:
            if not meta["station_merge"]: 
                cell = ws[f"{cols['station']}{row_ptr}"]
                cell.value = station_title(m)
                apply_center_style(cell)

            safe_write(ws, f"{cols['location']}{row_ptr}", region_display(r["region"]))
            prog_val = r.get("program_num", parse_count_to_int(r.get("program", 0)))
            safe_write(ws, f"{cols['program']}{row_ptr}", int(prog_val))

            if format_type == "Dongwu":
                safe_write(ws, f"{cols['daypart']}{row_ptr}", r["daypart"])
                if m == "å®¶æ¨‚ç¦": safe_write(ws, f"{cols['seconds']}{row_ptr}", f"{r['seconds']}ç§’")
                else: safe_write(ws, f"{cols['seconds']}{row_ptr}", int(r["seconds"]))
                safe_write(ws, f"{cols['rate']}{row_ptr}", r["rate_list"])
                safe_write(ws, f"{cols['pkg']}{row_ptr}", r["pkg_display_val"])
            else:
                safe_write(ws, f"{cols['daypart']}{row_ptr}", r["daypart"])
                safe_write(ws, f"{cols['seconds']}{row_ptr}", f"{r['seconds']}ç§’å»£å‘Š")
                safe_write(ws, f"{cols['proj_price']}{row_ptr}", r["pkg_display_val"] if isinstance(r["pkg_display_val"], int) else 0)

            set_schedule(ws, row_ptr, meta["schedule_start_col"], meta["max_days"], r["schedule"])
            spot_sum = sum(r["schedule"][:meta["max_days"]])
            safe_write(ws, f"{meta['total_col']}{row_ptr}", spot_sum)
            written_rows.append(row_ptr)
            row_ptr += 1

    eff_days = min((end_dt - start_dt).days + 1, meta["max_days"])
    daily_sums = [sum([x["schedule"][d] for x in rows if d < len(x["schedule"])]) for d in range(eff_days)]
    set_schedule(ws, total_row, meta["schedule_start_col"], meta["max_days"], daily_sums)
    safe_write(ws, f"{meta['total_col']}{total_row}", sum(daily_sums))
    total_pkg = sum([x["pkg_display_val"] for x in rows if isinstance(x["pkg_display_val"], int)])
    pkg_col = cols.get("pkg") or cols.get("proj_price")
    safe_write(ws, f"{pkg_col}{total_row}", total_pkg)

    lbl = meta["footer_labels"]
    def write_footer(key, val):
        pos = find_cell_exact(ws, lbl.get(key, ""))
        if pos: safe_write_rc(ws, pos[0], pos[1]+1, int(val))

    make_fee = 10000 
    pos_make = find_cell_exact(ws, lbl["make"])
    if pos_make:
        v = ws.cell(pos_make[0], pos_make[1]+1).value
        if isinstance(v, (int, float)) and v > 0: make_fee = int(v)
        else: safe_write_rc(ws, pos_make[0], pos_make[1]+1, make_fee)
    
    vat = int(round((total_pkg + make_fee) * 0.05))
    write_footer("vat", vat)
    write_footer("grand", total_pkg + make_fee + vat)

    rem_pos = find_cell_exact(ws, "Remarksï¼š")
    if rem_pos:
        for i, rm in enumerate(remarks_list):
            safe_write_rc(ws, rem_pos[0] + 1 + i, rem_pos[1], rm)

    if format_type == "Dongwu" and written_rows:
        min_r, max_r = min(written_rows), total_row
        force_center_columns_range(ws, meta["force_center_cols"], min_r, max_r)

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()

# =========================================================
# 6. HTML Preview
# =========================================================
def load_font_base64():
    font_path = "NotoSansTC-Regular.ttf"
    if os.path.exists(font_path):
        with open(font_path, "rb") as f: return base64.b64encode(f.read()).decode("utf-8")
    
    url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/TTF/TraditionalChinese/NotoSansTC-Regular.ttf"
    try:
        r = requests.get(url, timeout=15)
        if r.status_code == 200:
            with open(font_path, "wb") as f: f.write(r.content)
            return base64.b64encode(r.content).decode("utf-8")
    except: pass
    return None

def generate_html_preview(rows, days_cnt, start_dt, end_dt, c_name, p_display, format_type, remarks):
    header_cls = "bg-dw-head" if format_type == "Dongwu" else "bg-sh-head"
    media_order = {"å…¨å®¶å»£æ’­": 1, "æ–°é®®è¦–": 2, "å®¶æ¨‚ç¦": 3}
    eff_days = min(days_cnt, 31)
    
    # CSS Injection for Preview
    st.markdown(f"""<style>
    .bg-dw-head {{ background-color: #4472C4; color: white; font-weight: bold; }}
    .bg-sh-head {{ background-color: #BDD7EE; color: black; font-weight: bold; }}
    .bg-weekend {{ background-color: #FFD966; color: black; }}
    .bg-total   {{ background-color: #FFF2CC; font-weight: bold; }}
    .col_day {{ min-width: 25px; }}
    </style>""", unsafe_allow_html=True)

    date_th1, date_th2 = "", ""
    curr = start_dt
    weekdays = ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "æ—¥"]
    for i in range(eff_days):
        wd = curr.weekday()
        bg = "bg-weekend" if (format_type == "Dongwu" and wd >= 5) else header_cls
        if format_type == "Shenghuo": bg = header_cls 
        date_th1 += f"<th class='{bg} col_day'>{curr.day}</th>"
        date_th2 += f"<th class='{bg} col_day'>{weekdays[wd]}</th>"
        curr += timedelta(days=1)

    if format_type == "Dongwu":
        cols_def = ["Station", "Location", "Program", "Day-part", "Size", "rate<br>(List)", "Package<br>(List)"]
    else:
        cols_def = ["é »é“", "æ’­å‡ºåœ°å€", "æ’­å‡ºåº—æ•¸", "æ’­å‡ºæ™‚é–“", "ç§’æ•¸<br>è¦æ ¼", "å°ˆæ¡ˆåƒ¹"]
    th_fixed = "".join([f"<th rowspan='2'>{c}</th>" for c in cols_def])
    
    rows_sorted = sorted(rows, key=lambda x: (media_order.get(x["media_type"], 99), x["seconds"], REGIONS_ORDER.index(x["region"]) if x["region"] in REGIONS_ORDER else 99))
    tbody = ""
    media_counts = {}
    for r in rows_sorted: media_counts[r["media_type"]] = media_counts.get(r["media_type"], 0) + 1
    media_printed = {m: False for m in media_counts}

    for r in rows_sorted:
        m = r["media_type"]
        tbody += "<tr>"
        if not media_printed[m]:
            rowspan = media_counts[m]
            display_name = "å…¨å®¶ä¾¿åˆ©å•†åº—<br>é€šè·¯å»£æ’­å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "å…¨å®¶ä¾¿åˆ©å•†åº—<br>æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
            if format_type == "Shenghuo" and m == "å…¨å®¶å»£æ’­": display_name = "å…¨å®¶ä¾¿åˆ©å•†åº—<br>å»£æ’­é€šè·¯å»£å‘Š"
            if format_type == "Shenghuo": tbody += f"<td class='left'>{display_name}</td>"
            else: tbody += f"<td class='left' rowspan='{rowspan}'>{display_name}</td>"; media_printed[m] = True
        elif format_type == "Shenghuo":
             display_name = "å…¨å®¶ä¾¿åˆ©å•†åº—<br>å»£æ’­é€šè·¯å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "å…¨å®¶ä¾¿åˆ©å•†åº—<br>æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
             tbody += f"<td class='left'>{display_name}</td>"

        tbody += f"<td>{region_display(r['region'])}</td><td class='right'>{r.get('program_num','')}</td><td>{r['daypart']}</td>"
        sec_txt = f"{r['seconds']}ç§’" if format_type=="Dongwu" and m=="å®¶æ¨‚ç¦" else f"{r['seconds']}" if format_type=="Dongwu" else f"{r['seconds']}ç§’å»£å‘Š"
        tbody += f"<td>{sec_txt}</td>"
        rate = f"{r['rate_list']:,}" if isinstance(r['rate_list'], int) else r['rate_list']
        pkg = f"{r['pkg_display_val']:,}" if isinstance(r['pkg_display_val'], int) else r['pkg_display_val']
        if format_type == "Dongwu": tbody += f"<td class='right'>{rate}</td><td class='right'>{pkg}</td>"
        else: tbody += f"<td class='right'>{pkg}</td>"
        
        for d in r['schedule'][:eff_days]: tbody += f"<td>{d}</td>"
        tbody += f"<td class='bg-total'>{sum(r['schedule'])}</td></tr>"

    totals = [sum([r["schedule"][d] for r in rows if d < len(r["schedule"])]) for d in range(eff_days)]
    total_pkg = sum([r["pkg_display_val"] for r in rows if isinstance(r["pkg_display_val"], int)])
    colspan = 5; empty_td = "<td></td>" if format_type == "Dongwu" else ""
    tfoot = f"<tr class='bg-total'><td colspan='{colspan}' class='left'>Total</td>{empty_td}<td class='right'>{total_pkg:,}</td>"
    for t in totals: tfoot += f"<td>{t}</td>"
    tfoot += f"<td>{sum(totals)}</td></tr>"

    return f"""<div class="excel-container"><div style="margin-bottom:10px;"><b>å®¢æˆ¶ï¼š</b>{c_name} &nbsp; <b>ç”¢å“ï¼š</b>{p_display}<br><span style="color:#666;">èµ°æœŸï¼š{start_dt} ~ {end_dt}</span></div><table class="excel-table"><thead><tr>{th_fixed}{date_th1}<th class='{header_cls}' rowspan='2'>æª”æ¬¡</th></tr><tr>{date_th2}</tr></thead><tbody>{tbody}{tfoot}</tbody></table><div class="remarks"><b>Remarksï¼š</b><br>{"<br>".join(remarks)}</div></div>"""

def build_colgroup(format_type, days):
    cols = ["col_station", "col_loc", "col_prog", "col_daypart", "col_size", "col_rate", "col_pkg"] if format_type=="Dongwu" else ["col_station", "col_loc", "col_prog", "col_daypart", "col_size", "col_pkg"]
    html = "<colgroup>"
    for c in cols: html += f"<col class='{c}'>"
    for _ in range(days): html += "<col class='col_day'>"
    html += "<col class='col_total'></colgroup>"
    return html

# =========================================================
# 7. UI Main
# =========================================================
st.title("ğŸ“º åª’é«” Cue è¡¨ç”Ÿæˆå™¨ (v63.6: Clean PDF)")

auto_tpl, source, msgs = load_default_template()
template_bytes = auto_tpl

if auto_tpl:
    st.success(f"âœ… å·²è¼‰å…¥ç³»çµ±å…¬ç‰ˆ ({source})")
else:
    st.warning("âš ï¸ ç„¡æ³•è¼‰å…¥å…¬ç‰ˆï¼Œè«‹æ‰‹å‹•ä¸Šå‚³")
    tpl = st.file_uploader("ä¸Šå‚³ Excel æ¨¡æ¿", type=["xlsx"])
    if tpl: template_bytes = tpl.read()

st.markdown("### 1. é¸æ“‡æ ¼å¼")
format_type = st.radio("", ["Dongwu", "Shenghuo"], horizontal=True, label_visibility="collapsed")

st.markdown("### 2. åŸºæœ¬è³‡æ–™è¨­å®š")
c1, c2, c3 = st.columns(3)
with c1: client_name = st.text_input("å®¢æˆ¶åç¨±", "è¬åœ‹é€šè·¯")
with c2: product_name = st.text_input("ç”¢å“åç¨±", "çµ±ä¸€å¸ƒä¸")
with c3: total_budget_input = st.number_input("ç¸½é ç®— (æœªç¨… Net)", value=1000000, step=10000)

c4, c5 = st.columns(2)
with c4: start_date = st.date_input("é–‹å§‹æ—¥", datetime(2026, 1, 1))
with c5: end_date = st.date_input("çµæŸæ—¥", datetime(2026, 1, 31))
days_count = (end_date - start_date).days + 1
st.info(f"ğŸ“… èµ°æœŸå…± **{days_count}** å¤©")

with st.expander("ğŸ“ å‚™è¨»æ¬„ä½è¨­å®š (Remarks)", expanded=False):
    rc1, rc2, rc3 = st.columns(3)
    sign_deadline = rc1.date_input("å›ç°½æˆªæ­¢æ—¥", datetime.now() + timedelta(days=3))
    billing_month = rc2.text_input("è«‹æ¬¾æœˆä»½", "2026å¹´2æœˆ")
    payment_date = rc3.date_input("ä»˜æ¬¾å…Œç¾æ—¥", datetime(2026, 3, 31))

st.markdown("### 3. åª’é«”æŠ•æ”¾è¨­å®š")

# 1. ç‹€æ…‹åˆå§‹åŒ–
if "rad_share" not in st.session_state: st.session_state.rad_share = 100
if "fv_share" not in st.session_state: st.session_state.fv_share = 0
if "cf_share" not in st.session_state: st.session_state.cf_share = 0

# 2. è‡ªå‹•å¹³è¡¡ Callback
def on_media_change():
    active = []
    if st.session_state.get("cb_rad"): active.append("rad_share")
    if st.session_state.get("cb_fv"): active.append("fv_share")
    if st.session_state.get("cb_cf"): active.append("cf_share")
    
    if not active: return
    share = 100 // len(active)
    for key in active: st.session_state[key] = share
    rem = 100 - sum([st.session_state[k] for k in active])
    st.session_state[active[0]] += rem

def on_slider_change(changed_key):
    active = []
    if st.session_state.get("cb_rad"): active.append("rad_share")
    if st.session_state.get("cb_fv"): active.append("fv_share")
    if st.session_state.get("cb_cf"): active.append("cf_share")
    
    others = [k for k in active if k != changed_key]
    if not others:
        st.session_state[changed_key] = 100
    elif len(others) == 1:
        val = st.session_state[changed_key]
        st.session_state[others[0]] = max(0, 100 - val)
    elif len(others) == 2:
        val = st.session_state[changed_key]
        rem = max(0, 100 - val)
        k1, k2 = others[0], others[1]
        sum_others = st.session_state[k1] + st.session_state[k2]
        if sum_others == 0:
            st.session_state[k1] = rem // 2
            st.session_state[k2] = rem - st.session_state[k1]
        else:
            ratio = st.session_state[k1] / sum_others
            st.session_state[k1] = int(rem * ratio)
            st.session_state[k2] = rem - st.session_state[k1]

# 3. åª’é«”å‹¾é¸å€
st.write("è«‹å‹¾é¸è¦æŠ•æ”¾çš„åª’é«”ï¼š")
col_cb1, col_cb2, col_cb3 = st.columns(3)
with col_cb1: is_rad = st.checkbox("å…¨å®¶å»£æ’­", value=True, key="cb_rad", on_change=on_media_change)
with col_cb2: is_fv = st.checkbox("æ–°é®®è¦–", value=False, key="cb_fv", on_change=on_media_change)
with col_cb3: is_cf = st.checkbox("å®¶æ¨‚ç¦", value=False, key="cb_cf", on_change=on_media_change)

# 4. ç´°éƒ¨è¨­å®šå€
m1, m2, m3 = st.columns(3)
config = {}

if is_rad:
    with m1:
        st.markdown("#### ğŸ“» å…¨å®¶å»£æ’­")
        is_nat = st.checkbox("å…¨çœè¯æ’­", True, key="rad_nat")
        regs = ["å…¨çœ"] if is_nat else st.multiselect("å€åŸŸ", REGIONS_ORDER, default=REGIONS_ORDER, key="rad_reg")
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [20], key="rad_sec")
        st.slider("é ç®— %", 0, 100, key="rad_share", on_change=on_slider_change, args=("rad_share",))
        sec_shares = {}
        if len(secs) > 1:
            ls = 100
            for s in sorted(secs)[:-1]:
                v = st.slider(f"{s}ç§’ %", 0, ls, int(ls/2), key=f"rs_{s}")
                sec_shares[s] = v; ls -= v
            sec_shares[sorted(secs)[-1]] = ls
        elif secs: sec_shares[secs[0]] = 100
        config["å…¨å®¶å»£æ’­"] = {"is_national": is_nat, "regions": regs, "seconds": sorted(secs), "share": st.session_state.rad_share, "sec_shares": sec_shares}

if is_fv:
    with m2:
        st.markdown("#### ğŸ“º æ–°é®®è¦–")
        is_nat = st.checkbox("å…¨çœè¯æ’­", False, key="fv_nat")
        regs = ["å…¨çœ"] if is_nat else st.multiselect("å€åŸŸ", REGIONS_ORDER, default=["åŒ—å€"], key="fv_reg")
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [10], key="fv_sec")
        st.slider("é ç®— %", 0, 100, key="fv_share", on_change=on_slider_change, args=("fv_share",))
        sec_shares = {}
        if len(secs) > 1:
            ls = 100
            for s in sorted(secs)[:-1]:
                v = st.slider(f"{s}ç§’ %", 0, ls, int(ls/2), key=f"fs_{s}")
                sec_shares[s] = v; ls -= v
            sec_shares[sorted(secs)[-1]] = ls
        elif secs: sec_shares[secs[0]] = 100
        config["æ–°é®®è¦–"] = {"is_national": is_nat, "regions": regs, "seconds": sorted(secs), "share": st.session_state.fv_share, "sec_shares": sec_shares}

if is_cf:
    with m3:
        st.markdown("#### ğŸ›’ å®¶æ¨‚ç¦")
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [20], key="cf_sec")
        st.slider("é ç®— %", 0, 100, key="cf_share", on_change=on_slider_change, args=("cf_share",))
        sec_shares = {}
        if len(secs) > 1:
            ls = 100
            for s in sorted(secs)[:-1]:
                v = st.slider(f"{s}ç§’ %", 0, ls, int(ls/2), key=f"cs_{s}")
                sec_shares[s] = v; ls -= v
            sec_shares[sorted(secs)[-1]] = ls
        elif secs: sec_shares[secs[0]] = 100
        config["å®¶æ¨‚ç¦"] = {"regions": ["å…¨çœ"], "seconds": sorted(secs), "share": st.session_state.cf_share, "sec_shares": sec_shares}

# ---------------------------------------------------------
# è¨ˆç®—å¼•æ“
# ---------------------------------------------------------
rows = []
debug_logs = []

if config:
    for m, cfg in config.items():
        m_budget = total_budget_input * (cfg["share"] / 100.0)
        for sec, sec_pct in cfg["sec_shares"].items():
            s_budget = m_budget * (sec_pct / 100.0)
            if s_budget <= 0: continue
            factor = get_sec_factor(m, sec)
            
            if m in ["å…¨å®¶å»£æ’­", "æ–°é®®è¦–"]:
                db = PRICING_DB[m]
                calc_regs = REGIONS_ORDER if cfg["is_national"] else cfg["regions"]
                display_regs = REGIONS_ORDER if cfg["is_national"] else cfg["regions"]
                
                unit_net_sum = 0
                for r in calc_regs: unit_net_sum += (db[r][1] / db["Std_Spots"]) * factor
                
                if unit_net_sum == 0: continue
                
                spots_init = math.ceil(s_budget / unit_net_sum)
                penalty = 1.1 if spots_init < db["Std_Spots"] else 1.0
                spots_final = math.ceil(s_budget / (unit_net_sum * penalty))
                if spots_final % 2 != 0: spots_final += 1
                if spots_final == 0: spots_final = 2
                
                sch = calculate_schedule(spots_final, days_count)
                
                debug_logs.append({
                    "media": m, "sec": sec, "budget": s_budget, 
                    "unit_cost": unit_net_sum * penalty, "spots": spots_final, 
                    "std": db["Std_Spots"], "factor": factor, 
                    "status": "æœªé”æ¨™" if penalty > 1 else "é”æ¨™",
                    "reason": f"æ‡²ç½° x1.1" if penalty > 1 else "è²»ç‡æ­£å¸¸"
                })
                
                for r in display_regs:
                    rate_list = int((db[r][0] / db["Std_Spots"]) * factor)
                    pkg_list = rate_list * spots_final
                    is_start = (cfg["is_national"] and r == "åŒ—å€")
                    rows.append({"media_type": m, "region": r, "program_num": STORE_COUNTS_NUM.get(f"æ–°é®®è¦–_{r}" if m=="æ–°é®®è¦–" else r, 0), "daypart": db["Day_Part"], "seconds": sec, "spots": spots_final, "schedule": sch, "rate_list": rate_list, "pkg_display_val": pkg_list, "is_pkg_start": is_start, "is_pkg_member": cfg["is_national"]})

            elif m == "å®¶æ¨‚ç¦":
                db = PRICING_DB["å®¶æ¨‚ç¦"]
                base_std = db["é‡è²©_å…¨çœ"]["Std_Spots"]
                unit_net = (db["é‡è²©_å…¨çœ"]["Net"] / base_std) * factor
                
                spots_init = math.ceil(s_budget / unit_net)
                penalty = 1.1 if spots_init < base_std else 1.0
                spots_final = math.ceil(s_budget / (unit_net * penalty))
                if spots_final % 2 != 0: spots_final += 1
                
                sch_h = calculate_schedule(spots_final, days_count)
                
                debug_logs.append({
                    "media": m, "sec": sec, "budget": s_budget, 
                    "unit_cost": unit_net * penalty, "spots": spots_final, 
                    "std": base_std, "factor": factor,
                    "status": "æœªé”æ¨™" if penalty > 1 else "é”æ¨™",
                    "reason": f"æ‡²ç½° x1.1" if penalty > 1 else "è²»ç‡æ­£å¸¸"
                })
                
                rate_h = int((db["é‡è²©_å…¨çœ"]["List"] / base_std) * factor)
                rows.append({"media_type": m, "region": "å…¨çœé‡è²©", "program_num": STORE_COUNTS_NUM["å®¶æ¨‚ç¦_é‡è²©"], "daypart": db["é‡è²©_å…¨çœ"]["Day_Part"], "seconds": sec, "spots": spots_final, "schedule": sch_h, "rate_list": rate_h, "pkg_display_val": rate_h * spots_final, "is_pkg_start": False, "is_pkg_member": False})
                spots_s = int(spots_final * (db["è¶…å¸‚_å…¨çœ"]["Std_Spots"] / base_std))
                sch_s = calculate_schedule(spots_s, days_count)
                rows.append({"media_type": m, "region": "å…¨çœè¶…å¸‚", "program_num": STORE_COUNTS_NUM["å®¶æ¨‚ç¦_è¶…å¸‚"], "daypart": db["è¶…å¸‚_å…¨çœ"]["Day_Part"], "seconds": sec, "spots": spots_s, "schedule": sch_s, "rate_list": "è¨ˆé‡è²©", "pkg_display_val": "è¨ˆé‡è²©", "is_pkg_start": False, "is_pkg_member": False})

p_str = f"{'ã€'.join([f'{s}ç§’' for s in sorted(list(set(r['seconds'] for r in rows)))])} {product_name}" if rows else ""
rem = get_remarks_text(sign_deadline, billing_month, payment_date)

with st.expander("ğŸ’¡ ç³»çµ±é‹ç®—é‚è¼¯èªªæ˜ (Debug Panel)", expanded=False):
    st.markdown("#### 1. æœ¬æ¬¡é ç®—åˆ†é… (Waterfall)")
    for log in debug_logs:
        color = "green" if log["status"] == "é”æ¨™" else "red"
        st.markdown(f"**{log['media']} ({log['sec']}ç§’)**: é ç®—${log['budget']:,.0f} | åŸ·è¡Œ{log['spots']}æª” -> <span style='color:{color}'><b>{log['status']}</b></span>", unsafe_allow_html=True)

if rows:
    html = generate_html_preview(rows, days_count, start_date, end_date, client_name, p_str, format_type, rem)
    st.components.v1.html(html, height=700, scrolling=True)
    
    if template_bytes:
        try:
            xlsx = generate_excel_from_template(format_type, start_date, end_date, client_name, p_str, rows, rem, template_bytes)
            st.download_button("ä¸‹è¼‰ Excel", xlsx, f"Cue_{client_name}.xlsx")
            
            # PDF Generation Strategy
            # Priority 1: Direct Excel/LibreOffice Conversion (Most accurate)
            # Priority 2: WeasyPrint (Fallback)
            pdf_bytes, method, err = xlsx_bytes_to_pdf_bytes(xlsx)
            
            if pdf_bytes:
                st.download_button(f"ä¸‹è¼‰ PDF ({method})", pdf_bytes, f"Cue_{client_name}.pdf")
            else:
                st.warning(f"Excel è½‰ PDF å¤±æ•— ({err})ï¼Œåˆ‡æ›è‡³å‚™ç”¨æ¸²æŸ“å¼•æ“ (HTML)...")
                font_b64 = load_font_base64()
                pdf_bytes, err = html_to_pdf_fallback(html, font_b64)
                if pdf_bytes: st.download_button("ä¸‹è¼‰ PDF (Fallback)", pdf_bytes, f"Cue_{client_name}.pdf")
                else: st.error(f"PDF ç”¢å‡ºå¤±æ•—: {err}")
                
        except Exception as e: st.error(f"Excel ç”¢å‡ºéŒ¯èª¤: {e}")
    else: st.warning("è«‹ä¸Šå‚³æ¨¡æ¿ä»¥å•Ÿç”¨ä¸‹è¼‰ã€‚")
