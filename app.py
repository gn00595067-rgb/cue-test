import streamlit as st
import math
import io
import os
import shutil
import tempfile
import subprocess
import re
from datetime import timedelta, datetime
from copy import copy

import requests
import openpyxl
from openpyxl.utils import column_index_from_string
from openpyxl.cell.cell import MergedCell
from openpyxl.formula.translate import Translator
from openpyxl.styles import Alignment

# =========================================================
# 0) åŸºç¤å·¥å…·å‡½å¼ï¼ˆå¿…é ˆæ”¾æœ€å‰é¢ï¼‰
# =========================================================
def parse_count_to_int(x):
    """å°‡å«æœ‰é€—è™Ÿçš„å­—ä¸²æˆ–æ•¸å­—è½‰ç‚ºæ•´æ•¸"""
    if x is None:
        return 0
    if isinstance(x, (int, float)):
        return int(x)
    s = str(x)
    m = re.findall(r"[\d,]+", s)
    if not m:
        return 0
    return int(m[0].replace(",", ""))

def sanitize_text(s):
    """æ¸…ç†ä¸å¯è¦‹æ§åˆ¶å­—å…ƒ/æ›¿ä»£å­—å…ƒï¼Œé¿å… PDF äº‚ç¢¼ã€æ€ªç¬¦è™Ÿ"""
    if s is None:
        return s
    s = str(s)
    s = s.replace("\uFFFD", "").replace("\uFFFE", "").replace("\ufeff", "")
    s = re.sub(r"[\x00-\x08\x0b-\x1f\x7f]", "", s)  # ä¿ç•™ \t \n
    s = re.sub(r"[ ]{2,}", " ", s).strip()
    return s

def find_soffice_path():
    """æ‰¾ LibreOffice/sofficeï¼ˆé›²ç«¯é€šå¸¸åœ¨ /usr/bin/sofficeï¼‰"""
    soffice = shutil.which("soffice") or shutil.which("libreoffice")
    if soffice:
        return soffice
    if os.name == "nt":
        candidates = [
            r"C:\Program Files\LibreOffice\program\soffice.exe",
            r"C:\Program Files (x86)\LibreOffice\program\soffice.exe",
        ]
        for p in candidates:
            if os.path.exists(p):
                return p
    return None

def xlsx_bytes_to_pdf_bytes(xlsx_bytes: bytes):
    """
    PDF æœ€é«˜æ“¬çœŸç­–ç•¥ï¼š
    1) Windows æœ¬æ©Ÿï¼šExcel COM ExportAsFixedFormatï¼ˆæœ€åƒï¼‰
    2) Linux / Streamlit Cloudï¼šLibreOffice headless convertï¼ˆå¾ˆåƒï¼‰
    3) éƒ½æ²’æœ‰ â†’ å›å‚³ Noneï¼ˆè®“ UI fallbackï¼‰
    """
    # 1) Windowsï¼šExcel COMï¼ˆæœ€åƒï¼‰
    if os.name == "nt":
        try:
            import win32com.client  # pip install pywin32
            with tempfile.TemporaryDirectory() as tmp:
                xlsx_path = os.path.join(tmp, "cue.xlsx")
                pdf_path = os.path.join(tmp, "cue.pdf")
                with open(xlsx_path, "wb") as f:
                    f.write(xlsx_bytes)

                excel = win32com.client.DispatchEx("Excel.Application")
                excel.Visible = False
                excel.DisplayAlerts = False
                wb = None
                try:
                    wb = excel.Workbooks.Open(xlsx_path)
                    wb.ExportAsFixedFormat(0, pdf_path)
                finally:
                    try:
                        if wb is not None:
                            wb.Close(False)
                    except:
                        pass
                    excel.Quit()

                if os.path.exists(pdf_path):
                    return open(pdf_path, "rb").read(), "excel_com", ""
                return None, "excel_com_fail", "excel export no output"
        except Exception as e:
            return None, "excel_com_fail", str(e)

    # 2) LibreOffice headless
    soffice = find_soffice_path()
    if soffice:
        try:
            with tempfile.TemporaryDirectory() as tmp:
                xlsx_path = os.path.join(tmp, "cue.xlsx")
                with open(xlsx_path, "wb") as f:
                    f.write(xlsx_bytes)

                # âœ…é›²ç«¯ç©©å®šæ€§é—œéµï¼šå›ºå®š UserInstallation profileï¼ˆé¿å… lock / first-run wizardï¼‰
                lo_profile = os.path.join(tmp, "lo_profile")
                os.makedirs(lo_profile, exist_ok=True)

                # file URIï¼ˆWindows/Linux éƒ½å®‰å…¨ï¼‰
                lo_uri = "file:///" + lo_profile.replace("\\", "/")

                cmd = [
                    soffice,
                    "--headless", "--invisible", "--nologo", "--nofirststartwizard",
                    "--norestore", "--nolockcheck",
                    f"-env:UserInstallation={lo_uri}",
                    "--convert-to", "pdf:calc_pdf_Export",
                    "--outdir", tmp,
                    xlsx_path
                ]
                p = subprocess.run(cmd, capture_output=True, text=True)

                if p.returncode != 0:
                    return None, "libreoffice_fail", (p.stderr or p.stdout or "LibreOffice convert failed")

                # æœŸå¾…è¼¸å‡º cue.pdfï¼Œä½† LO æœ‰æ™‚æœƒè¼¸å‡ºä¸åŒæª”å
                pdf_path = os.path.join(tmp, "cue.pdf")
                if not os.path.exists(pdf_path):
                    for fn in os.listdir(tmp):
                        if fn.lower().endswith(".pdf"):
                            pdf_path = os.path.join(tmp, fn)
                            break

                if os.path.exists(pdf_path):
                    return open(pdf_path, "rb").read(), "libreoffice", ""
                return None, "libreoffice_fail", "libreoffice export no output"
        except Exception as e:
            return None, "libreoffice_fail", str(e)

    return None, "none", "no_excel_com_and_no_soffice"

def ensure_noto_tc_ttf():
    """WeasyPrint fallback ç”¨ï¼šç¢ºä¿ä¸­æ–‡å­—é«”åœ¨æœ¬æ©Ÿå¯ç”¨ï¼ˆé¿å…äº‚ç¢¼ï¼‰"""
    font_path = "NotoSansTC-Regular.ttf"
    if os.path.exists(font_path) and os.path.getsize(font_path) > 100000:
        return font_path
    url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/TTF/TraditionalChinese/NotoSansTC-Regular.ttf"
    try:
        r = requests.get(url, timeout=20)
        if r.status_code == 200 and len(r.content) > 100000:
            with open(font_path, "wb") as f:
                f.write(r.content)
            return font_path
    except:
        pass
    return font_path if os.path.exists(font_path) else None

def html_to_pdf_weasyprint(html_str: str):
    """
    âš ï¸æ“¬çœŸåº¦ä¸€å®šä½æ–¼ xlsxâ†’pdfï¼ˆé€™æ˜¯æœ€å¾Œ fallbackï¼‰
    """
    try:
        from weasyprint import HTML, CSS
        from weasyprint.text.fonts import FontConfiguration
    except Exception as e:
        return None, f"WeasyPrint not installed: {e}"

    font_path = ensure_noto_tc_ttf()
    font_abs = os.path.abspath(font_path) if font_path else ""

    font_config = FontConfiguration()
    css_str = f"""
    @page {{
        size: A4 landscape;
        margin: 0.5cm;
    }}
    @font-face {{
        font-family: 'NotoSansTC';
        src: url('file://{font_abs}');
    }}
    body {{
        font-family: 'NotoSansTC', sans-serif !important;
        font-size: 8pt;
    }}
    table {{ width: 100%; border-collapse: collapse; }}
    th, td {{
        border: 0.5pt solid #555;
        padding: 2px 3px;
        text-align: center;
        vertical-align: middle;
        white-space: nowrap;
    }}
    tr {{ page-break-inside: avoid; }}
    """
    try:
        pdf_bytes = HTML(string=html_str).write_pdf(
            stylesheets=[CSS(string=css_str)],
            font_config=font_config
        )
        return pdf_bytes, ""
    except Exception as e:
        return None, f"PDF Render Error: {str(e)}"

# =========================================================
# 1) Streamlit é é¢è¨­å®š & è‡ªå‹•è¼‰å…¥æ¨¡æ¿
# =========================================================
st.set_page_config(layout="wide", page_title="Cue Sheet Pro v63.1 (Cloud PDF æ“¬çœŸæå‡)")

GOOGLE_DRIVE_FILE_ID = "11R1SA_hpFD5O_MGmYeh4BdtcUhK2bPta"
DEFAULT_FILENAME = "1209-Cueè¡¨ç›¸é—œè³‡æ–™.xlsx"

@st.cache_resource(ttl=600)
def load_default_template():
    status_msg = []
    # Google Driveï¼ˆè‹¥æ¬Šé™å¯ç›´é€£ï¼‰
    if GOOGLE_DRIVE_FILE_ID:
        url = f"https://drive.google.com/uc?export=download&id={GOOGLE_DRIVE_FILE_ID}"
        try:
            r = requests.get(url, timeout=20, allow_redirects=True)
            if r.status_code == 200:
                if b"<!DOCTYPE html>" in r.content[:500]:
                    status_msg.append("âš ï¸ Drive ä¸‹è¼‰æ¬Šé™å—é™ï¼ˆå¯èƒ½éœ€ç™»å…¥ / ä¸æ˜¯ç›´é€£ä¸‹è¼‰ï¼‰")
                else:
                    return r.content, "é›²ç«¯ç¡¬ç¢Ÿ (Google Drive)", status_msg
        except Exception as e:
            status_msg.append(f"âŒ Drive é€£ç·šéŒ¯èª¤: {e}")

    # æœ¬æ©Ÿæª”ï¼ˆä½ æœ¬æ©Ÿæ¸¬è©¦ç”¨ï¼›é›²ç«¯é€šå¸¸æ²’æœ‰ï¼‰
    if os.path.exists(DEFAULT_FILENAME):
        try:
            with open(DEFAULT_FILENAME, "rb") as f:
                return f.read(), "ç³»çµ±ä¸»æ©Ÿ (Local)", status_msg
        except Exception as e:
            status_msg.append(f"âŒ æœ¬åœ°è®€å–å¤±æ•—: {e}")

    return None, None, status_msg

# =========================================================
# 2) CSSï¼ˆé è¦½æ›´åƒ Excelï¼‰
# =========================================================
st.markdown("""
<style>
  @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+TC:wght@400;700&display=swap');
  .stApp { background-color: #f4f4f4; font-family: 'Noto Sans TC', sans-serif; }

  .preview-wrapper {
      background: #fff;
      padding: 12px;
      border: 1px solid #cfcfcf;
      box-shadow: 0 2px 8px rgba(0,0,0,0.08);
      margin-bottom: 16px;
      overflow: auto;
      white-space: nowrap;
  }

  table.excel-table {
      border-collapse: collapse;
      font-size: 11px;
      min-width: 1200px;
      color: #000;
      font-family: Arial, "Microsoft JhengHei", sans-serif;
  }

  .excel-table th, .excel-table td {
      border: 1px solid #000;
      padding: 3px 6px;
      text-align: center;
      vertical-align: middle;
      height: 20px;
      line-height: 1.2;
      white-space: nowrap;
  }

  .excel-table thead th {
      position: sticky; top: 0; z-index: 20;
      border-bottom: 2px solid #000;
  }
  .excel-table thead tr:nth-child(2) th { top: 24px; z-index: 19; }

  .bg-dw-head { background-color: #4472C4; color: white; font-weight: 700; }
  .bg-sh-head { background-color: #BDD7EE; color: black; font-weight: 700; }
  .bg-weekend { background-color: #FFD966; color: black; }
  .bg-total   { background-color: #FFF2CC; font-weight: 700; }

  .align-left  { text-align: left !important; padding-left: 6px !important; }
  .align-right { text-align: right !important; padding-right: 6px !important; font-family: Consolas, monospace; }
</style>
""", unsafe_allow_html=True)

# =========================================================
# 3) è³‡æ–™åº«
# =========================================================
STORE_COUNTS_RAW = {
    "å…¨çœ": "4,437åº—",
    "åŒ—å€": "1,649åº—", "æ¡ƒç«¹è‹—": "779åº—", "ä¸­å€": "839åº—", "é›²å˜‰å—": "499åº—", "é«˜å±": "490åº—", "æ±å€": "181åº—",
    "æ–°é®®è¦–_å…¨çœ": "3,124é¢",
    "æ–°é®®è¦–_åŒ—å€": "1,127é¢", "æ–°é®®è¦–_æ¡ƒç«¹è‹—": "616é¢", "æ–°é®®è¦–_ä¸­å€": "528é¢",
    "æ–°é®®è¦–_é›²å˜‰å—": "365é¢", "æ–°é®®è¦–_é«˜å±": "405é¢", "æ–°é®®è¦–_æ±å€": "83é¢",
    "å®¶æ¨‚ç¦_é‡è²©": "67åº—", "å®¶æ¨‚ç¦_è¶…å¸‚": "250åº—"
}
STORE_COUNTS_NUM = {k: parse_count_to_int(v) for k, v in STORE_COUNTS_RAW.items()}

# 2026ï¼šå…¨å®¶å»£æ’­ä»¥ 6 å€ï¼ˆä½ ç¢ºèªä¸æ˜¯ bugï¼‰
REGIONS_ORDER = ["åŒ—å€", "æ¡ƒç«¹è‹—", "ä¸­å€", "é›²å˜‰å—", "é«˜å±", "æ±å€"]
DURATIONS = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]

PRICING_DB = {
    "å…¨å®¶å»£æ’­": {
        "Std_Spots": 480, "Day_Part": "00:00-24:00",
        "å…¨çœ": [400000, 320000],
        "åŒ—å€": [250000, 200000], "æ¡ƒç«¹è‹—": [150000, 120000], "ä¸­å€": [150000, 120000],
        "é›²å˜‰å—": [100000, 80000], "é«˜å±": [100000, 80000], "æ±å€": [62500, 50000]
    },
    "æ–°é®®è¦–": {
        "Std_Spots": 504, "Day_Part": "07:00-22:00",
        "å…¨çœ": [150000, 120000],
        "åŒ—å€": [150000, 120000], "æ¡ƒç«¹è‹—": [120000, 96000], "ä¸­å€": [90000, 72000],
        "é›²å˜‰å—": [75000, 60000], "é«˜å±": [75000, 60000], "æ±å€": [45000, 36000]
    },
    "å®¶æ¨‚ç¦": {
        "é‡è²©_å…¨çœ": {"List": 300000, "Net": 250000, "Std_Spots": 420, "Day_Part": "09:00-23:00"},
        "è¶…å¸‚_å…¨çœ": {"List": 100000, "Net": 80000, "Std_Spots": 720, "Day_Part": "00:00-24:00"},
    }
}

SEC_FACTORS = {
    "å…¨å®¶å»£æ’­": {30: 1.0, 20: 0.85, 15: 0.65, 10: 0.5, 5: 0.25},
    "æ–°é®®è¦–": {30: 3.0, 20: 2.0, 15: 1.5, 10: 1.0, 5: 0.5},
    "å®¶æ¨‚ç¦": {30: 1.5, 20: 1.0, 15: 0.85, 10: 0.65, 5: 0.35}
}

def get_sec_factor(media_type, seconds):
    return SEC_FACTORS.get(media_type, {}).get(seconds, 1.0)

def calculate_schedule(total_spots, days):
    """å›ºå®šå¶æ•¸ã€å°åŠåˆ†é…å¾Œä¹˜å› 2 => æ¯å¤©éƒ½å¶æ•¸"""
    if days <= 0:
        return []
    if total_spots % 2 != 0:
        total_spots += 1
    half_spots = total_spots // 2
    base, rem = divmod(half_spots, days)
    half_schedule = [base + (1 if i < rem else 0) for i in range(days)]
    return [x * 2 for x in half_schedule]

def get_remarks_text(sign_deadline, billing_month, payment_date):
    d_str = sign_deadline.strftime("%Y/%m/%d (%a) %H:%M") if sign_deadline else "____/__/__ (__) 12:00"
    p_str = payment_date.strftime("%Y/%m/%d") if payment_date else "____/__/__"
    return [
        sanitize_text(f"1.è«‹æ–¼ {d_str}å‰ å›ç°½åŠé€²å–®ï¼Œæ–¹å¯é †åˆ©ä¸Šæª”ã€‚"),
        sanitize_text("2.ä»¥ä¸Šç¯€ç›®åç¨±å¦‚æœ‰ç•°å‹•ï¼Œä»¥ä¸Šæª”æ™‚ç¯€ç›®åç¨±ç‚ºä¸»ï¼Œå¦‚é‡æ™‚æ®µæ»¿æª”ï¼Œä¸Šæª”æ™‚é–“æŒªå¾Œæˆ–æ›´æ›è‡³åŒç´šæ™‚æ®µã€‚"),
        sanitize_text("3.é€šè·¯åº—é‹ªæ•¸èˆ‡é–‹æ©Ÿç‡é–‹æ©Ÿç‡è‡³å°‘ä¸ƒæˆ(ä»¥ä¸Š)ã€‚æ¯æ—¥å› åŠ ç›Ÿæ•¸èª¿æ•´ï¼Œæˆ–é‡åº—èˆ–å¹´åº¦å­£åº¦æ”¹è£ã€è¨­å‚™ç¶­è­·å‡ç´šåŠä¿ä¿®ç­‰ç‹€æ³ï¼Œæœƒæœ‰ä¸€å®šå¹…åº¦å¢æ¸›ã€‚"),
        sanitize_text("4.è¨—æ’­æ–¹éœ€æ–¼ä¸Šæª”å‰ 5 å€‹å·¥ä½œå¤©ï¼Œæä¾›å»£å‘Šå¸¶(mp3)ã€å½±ç‰‡/å½±åƒ 1920x1080 (mp4)ã€‚"),
        sanitize_text(f"5.é›™æ–¹åŒæ„è²»ç”¨è«‹æ¬¾æœˆä»½ : {billing_month}ï¼Œå¦‚æœ‰ä¿®æ­£å¿…è¦ï¼Œå°‡å¦è¡ŒE-Mailå‘ŠçŸ¥ï¼Œä¸¦è¦–ç‚ºæ­£å¼åˆç´„ä¹‹ä¸€éƒ¨åˆ†ã€‚"),
        sanitize_text(f"6.ä»˜æ¬¾å…Œç¾æ—¥æœŸï¼š{p_str}")
    ]

REGION_DISPLAY_6 = {
    "åŒ—å€": "åŒ—å€-åŒ—åŒ—åŸº", "æ¡ƒç«¹è‹—": "æ¡ƒå€-æ¡ƒç«¹è‹—", "ä¸­å€": "ä¸­å€-ä¸­å½°æŠ•",
    "é›²å˜‰å—": "é›²å˜‰å—å€-é›²å˜‰å—", "é«˜å±": "é«˜å±å€-é«˜å±", "æ±å€": "æ±å€-å®œèŠ±æ±",
    "å…¨çœé‡è²©": "å…¨çœé‡è²©", "å…¨çœè¶…å¸‚": "å…¨çœè¶…å¸‚",
}
def region_display(region: str) -> str:
    return sanitize_text(REGION_DISPLAY_6.get(region, region))

# =========================================================
# 4) Excel ç”Ÿæˆï¼ˆopenpyxlï¼šæ¨¡æ¿å¡«ç©ºï¼‰
# =========================================================
def _get_master_cell(ws, cell):
    if not isinstance(cell, MergedCell):
        return cell
    r, c = cell.row, cell.column
    for mr in ws.merged_cells.ranges:
        if mr.min_row <= r <= mr.max_row and mr.min_col <= c <= mr.max_col:
            return ws.cell(row=mr.min_row, column=mr.min_col)
    return None

def safe_write(ws, addr: str, value):
    cell = ws[addr]
    if isinstance(cell, MergedCell):
        master = _get_master_cell(ws, cell)
        if master:
            master.value = value
        return
    cell.value = value

def safe_write_rc(ws, row: int, col: int, value):
    cell = ws.cell(row=row, column=col)
    if isinstance(cell, MergedCell):
        master = _get_master_cell(ws, cell)
        if master:
            master.value = value
        return
    cell.value = value

def apply_center_style(cell):
    al = cell.alignment or Alignment()
    cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=al.wrap_text, indent=al.indent)

def copy_row_with_style_fix(ws, src_row, dst_row, max_col):
    """è¤‡è£½æ¨£å¼ + å…¬å¼å¹³ç§»ï¼ˆé¿å…æ’åˆ—å¾Œæ ¼å¼è·‘æ‰ï¼‰"""
    ws.row_dimensions[dst_row].height = ws.row_dimensions[src_row].height
    row_shift = dst_row - src_row
    for c in range(1, max_col + 1):
        sc = ws.cell(src_row, c)
        dc = ws.cell(dst_row, c)

        if isinstance(sc, MergedCell) or isinstance(dc, MergedCell):
            continue

        if sc.has_style:
            dc.font = copy(sc.font)
            dc.border = copy(sc.border)
            dc.fill = copy(sc.fill)
            dc.number_format = sc.number_format
            dc.protection = copy(sc.protection)
            dc.alignment = copy(sc.alignment)

        v = sc.value
        if isinstance(v, str) and v.startswith("="):
            try:
                dc.value = Translator(v, origin=sc.coordinate).translate_formula(row_shift=row_shift, col_shift=0)
            except:
                dc.value = v
        else:
            dc.value = v

def force_center_columns_range(ws, col_letters, start_row, end_row):
    """æœ€å¾Œè£œå¼·ï¼šç¢ºä¿æŸäº›æ¬„ä½å…¨éƒ¨ç½®ä¸­ï¼ˆå« merged master cellï¼‰"""
    if start_row is None or end_row is None:
        return
    for r in range(start_row, end_row + 1):
        for col in col_letters:
            addr = f"{col}{r}"
            cell = ws[addr]
            if isinstance(cell, MergedCell):
                master = _get_master_cell(ws, cell)
                if master:
                    cell = master
                else:
                    continue
            apply_center_style(cell)

def unmerge_col_overlap(ws, col_letter, start_row, end_row):
    st_col = column_index_from_string(col_letter)
    to_unmerge = []
    for mr in list(ws.merged_cells.ranges):
        if mr.min_col == st_col and mr.max_col == st_col:
            if not (mr.max_row < start_row or mr.min_row > end_row):
                to_unmerge.append(str(mr))
    for s in set(to_unmerge):
        try:
            ws.unmerge_cells(s)
        except:
            pass

def set_schedule(ws, row, start_col_letter, max_days, schedule_list):
    start_col = column_index_from_string(start_col_letter)
    for i in range(max_days):
        v = schedule_list[i] if (schedule_list and i < len(schedule_list)) else None
        safe_write_rc(ws, row, start_col + i, v)

def find_cell_exact(ws, text):
    for row in ws.iter_rows():
        for cell in row:
            if cell.value == text:
                return cell.row, cell.column
    return None

def find_first_row_contains(ws, col_letter, keyword):
    col_idx = column_index_from_string(col_letter)
    for r in range(1, ws.max_row + 1):
        v = ws.cell(r, col_idx).value
        if isinstance(v, str) and keyword in v:
            return r
    return None

def hide_unused_sheets(wb, keep_sheet_names, mode="veryHidden"):
    mode = mode if mode in ("hidden", "veryHidden") else "veryHidden"
    for sh in wb.worksheets:
        if sh.title not in keep_sheet_names:
            sh.sheet_state = mode

SHEET_META = {
    "Dongwu": {
        "sheet_name": "æ±å³-æ ¼å¼",
        "date_start_cell": "I7",
        "schedule_start_col": "I",
        "max_days": 31,
        "total_col": "AN",
        "anchors": {"å…¨å®¶å»£æ’­": "é€šè·¯å»£æ’­å»£å‘Š", "æ–°é®®è¦–": "æ–°é®®è¦–å»£å‘Š", "å®¶æ¨‚ç¦": "å®¶æ¨‚ç¦"},
        "header_cells": {"client": "C3", "product": "C4", "period": "C5", "medium": "C6", "month": "I6"},
        "cols": {"station": "B", "location": "C", "program": "D", "daypart": "E", "seconds": "F", "rate": "G", "pkg": "H"},
        "header_override": {"G7": "rate\n(List)", "H7": "Package-cost\n(List)"},
        "station_merge": True,
        "total_label": "Total",
        "footer_labels": {"make": "è£½ä½œ", "vat": "5% VAT", "grand": "Grand Total"},
        "force_center_cols": ["E", "F", "G", "H"],
    },
    "Shenghuo": {
        "sheet_name": "è²æ´»-æ ¼å¼",
        "date_start_cell": "G7",
        "schedule_start_col": "G",
        "max_days": 23,
        "total_col": "AD",
        "anchors": {"å…¨å®¶å»£æ’­": "å»£æ’­é€šè·¯å»£å‘Š", "æ–°é®®è¦–": "æ–°é®®è¦–å»£å‘Š", "å®¶æ¨‚ç¦": "å®¶æ¨‚ç¦"},
        "header_cells": {"client": "C5", "product": "C6", "month": "G6"},
        "cols": {"station": "B", "location": "C", "program": "D", "daypart": "E", "seconds": "F", "proj_price": "AF"},
        "header_override": {"AF7": "å°ˆæ¡ˆåƒ¹\n(List)"},
        "station_merge": False,
        "total_label": "Total",
        "footer_labels": {"make": "è£½ä½œ", "vat": "5% VAT", "grand": "Grand Total"},
        "force_center_cols": [],
    }
}

def generate_excel_from_template(format_type, start_dt, end_dt, client_name, product_display_str, rows, remarks_list, template_bytes):
    meta = SHEET_META[format_type]
    wb = openpyxl.load_workbook(io.BytesIO(template_bytes))

    if meta["sheet_name"] not in wb.sheetnames:
        raise ValueError(f"ç¼ºå°‘åˆ†é ï¼š{meta['sheet_name']}")

    ws = wb[meta["sheet_name"]]
    hide_unused_sheets(wb, [meta["sheet_name"]], mode="veryHidden")

    # Header
    hc = meta["header_cells"]
    if "client" in hc:
        safe_write(ws, hc["client"], sanitize_text(client_name))
    if "product" in hc:
        safe_write(ws, hc["product"], sanitize_text(product_display_str))
    if "period" in hc:
        safe_write(ws, hc["period"], f"{start_dt.strftime('%Y. %m. %d')} - {end_dt.strftime('%Y.%m. %d')}")
    if "medium" in hc:
        safe_write(ws, hc["medium"], sanitize_text(" ".join(sorted(set([r["media_type"] for r in rows])))))
    if "month" in hc:
        safe_write(ws, hc["month"], f" {start_dt.month}æœˆ")

    safe_write(ws, meta["date_start_cell"], datetime(start_dt.year, start_dt.month, start_dt.day))

    for addr, text in meta.get("header_override", {}).items():
        safe_write(ws, addr, sanitize_text(text))

    # æ‰¾ Total row
    total_cell = find_cell_exact(ws, meta["total_label"])
    if not total_cell:
        raise ValueError("æ‰¾ä¸åˆ° Totalï¼ˆæ¨¡æ¿å¯èƒ½è®Šæ›´ï¼‰")
    total_row = total_cell[0]

    cols = meta["cols"]

    # æ‰¾å„åª’é«”å€å¡Šèµ·é»ï¼ˆä»¥ Station æ¬„é—œéµå­—ï¼‰
    sec_start = {}
    for m_key, kw in meta["anchors"].items():
        r0 = find_first_row_contains(ws, cols["station"], kw)
        if r0:
            sec_start[m_key] = r0
    if not sec_start:
        raise ValueError("æ¨¡æ¿æ‰¾ä¸åˆ°ä»»ä½•å€å¡Š anchorï¼ˆè«‹ç¢ºèª Station æ¬„æ˜¯å¦æœ‰é—œéµå­—ï¼‰")

    # ç”¢ç”Ÿå€å¡Šç¯„åœ
    sec_order = sorted(sec_start.items(), key=lambda x: x[1])
    sec_ranges = []
    for i, (k, sr) in enumerate(sec_order):
        next_start = sec_order[i + 1][1] if i + 1 < len(sec_order) else total_row
        sec_ranges.append((k, sr, next_start - 1))

    # æ’åºï¼ˆåª’é«”å…§ï¼šç§’æ•¸â†’å€åŸŸï¼‰
    reg_map = {r: i for i, r in enumerate(REGIONS_ORDER + ["å…¨çœé‡è²©", "å…¨çœè¶…å¸‚"])}
    def sort_key(x):
        return (x.get("seconds", 0), reg_map.get(x.get("region", ""), 999))

    grouped = {
        "å…¨å®¶å»£æ’­": sorted([r for r in rows if r["media_type"] == "å…¨å®¶å»£æ’­"], key=sort_key),
        "æ–°é®®è¦–":   sorted([r for r in rows if r["media_type"] == "æ–°é®®è¦–"], key=sort_key),
        "å®¶æ¨‚ç¦":   sorted([r for r in rows if r["media_type"] == "å®¶æ¨‚ç¦"], key=sort_key),
    }

    # æ’åˆ—ï¼šç”¨å€å¡Šæœ€å¾Œä¸€åˆ—ç•¶ pattern rowï¼ˆæ›´æ¥è¿‘åŸæ¨£å¼ï¼‰
    for k, sr, er in sorted(sec_ranges, key=lambda x: x[1], reverse=True):
        data = grouped.get(k, [])
        needed = len(data)
        if needed <= 0:
            continue
        existing = er - sr + 1
        if needed > existing:
            insert_n = needed - existing
            insert_at = er + 1
            ws.insert_rows(insert_at, amount=insert_n)
            pattern_row = er
            max_col = ws.max_column
            for rr in range(insert_at, insert_at + insert_n):
                copy_row_with_style_fix(ws, pattern_row, rr, max_col)

    # æ’åˆ—å¾Œé‡æ–°æŠ“ Total / rangesï¼ˆrow æœƒè®Šï¼‰
    total_cell = find_cell_exact(ws, meta["total_label"])
    if not total_cell:
        raise ValueError("æ’åˆ—å¾Œæ‰¾ä¸åˆ° Totalï¼ˆæ¨¡æ¿å¯èƒ½ç•°å¸¸ï¼‰")
    total_row = total_cell[0]

    sec_start = {}
    for m_key, kw in meta["anchors"].items():
        r0 = find_first_row_contains(ws, cols["station"], kw)
        if r0:
            sec_start[m_key] = r0

    sec_order = sorted(sec_start.items(), key=lambda x: x[1])
    sec_ranges = []
    for i, (k, sr) in enumerate(sec_order):
        next_start = sec_order[i + 1][1] if i + 1 < len(sec_order) else total_row
        sec_ranges.append((k, sr, next_start - 1))

    def station_title(m):
        prefix = "å…¨å®¶ä¾¿åˆ©å•†åº—\n" if m != "å®¶æ¨‚ç¦" else ""
        name = "é€šè·¯å»£æ’­å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
        if format_type == "Shenghuo" and m == "å…¨å®¶å»£æ’­":
            name = "å»£æ’­é€šè·¯å»£å‘Š"
        return sanitize_text(prefix + name)

    # Dongwuï¼šæ¯å€‹ç§’æ•¸å€å¡Šåªåœ¨ç¬¬ä¸€åˆ—å¯« E/F/G/Hï¼ˆé¿å… merged-cell å­æ ¼è¦†å¯«ï¼‰
    def group_by_seconds(data_list):
        by_sec = {}
        for r in data_list:
            by_sec.setdefault(r["seconds"], []).append(r)
        out = []
        for s in sorted(by_sec.keys()):
            sec_rows = sorted(by_sec[s], key=lambda x: reg_map.get(x.get("region", ""), 999))
            out.append((s, sec_rows))
        return out

    written_rows = []

    for m, sr, er in sec_ranges:
        data = grouped.get(m, [])
        if not data:
            continue

        if meta["station_merge"]:
            unmerge_col_overlap(ws, cols["station"], sr, er)
            merge_rng = f"{cols['station']}{sr}:{cols['station']}{sr + len(data) - 1}"
            ws.merge_cells(merge_rng)
            top_cell = ws[f"{cols['station']}{sr}"]
            top_cell.value = station_title(m)
            apply_center_style(top_cell)

        row_ptr = sr

        if format_type == "Dongwu":
            for sec_val, sec_rows in group_by_seconds(data):
                for idx, r in enumerate(sec_rows):
                    if not meta["station_merge"]:
                        c_station = ws[f"{cols['station']}{row_ptr}"]
                        c_station.value = station_title(m)
                        apply_center_style(c_station)

                    safe_write(ws, f"{cols['location']}{row_ptr}", region_display(r["region"]))
                    safe_write(ws, f"{cols['program']}{row_ptr}", int(r.get("program_num", 0)))

                    if idx == 0:
                        safe_write(ws, f"{cols['daypart']}{row_ptr}", sanitize_text(r["daypart"]))
                        if m == "å®¶æ¨‚ç¦":
                            safe_write(ws, f"{cols['seconds']}{row_ptr}", sanitize_text(f"{r['seconds']}ç§’"))
                        else:
                            safe_write(ws, f"{cols['seconds']}{row_ptr}", int(r["seconds"]))

                        safe_write(ws, f"{cols['rate']}{row_ptr}", r.get("rate_list", ""))
                        safe_write(ws, f"{cols['pkg']}{row_ptr}", r.get("pkg_display_val", ""))

                        # ç½®ä¸­ä¿éšªï¼ˆmaster cellï¼‰
                        for kcol in (cols["daypart"], cols["seconds"], cols["rate"], cols["pkg"]):
                            cc = ws[f"{kcol}{row_ptr}"]
                            if isinstance(cc, MergedCell):
                                mc = _get_master_cell(ws, cc)
                                if mc:
                                    cc = mc
                            apply_center_style(cc)

                    set_schedule(ws, row_ptr, meta["schedule_start_col"], meta["max_days"], r["schedule"])
                    spot_sum = sum(r["schedule"][:meta["max_days"]])
                    safe_write(ws, f"{meta['total_col']}{row_ptr}", spot_sum)

                    written_rows.append(row_ptr)
                    row_ptr += 1

        else:
            for r in data:
                if not meta["station_merge"]:
                    c_station = ws[f"{cols['station']}{row_ptr}"]
                    c_station.value = station_title(m)
                    apply_center_style(c_station)

                safe_write(ws, f"{cols['location']}{row_ptr}", region_display(r["region"]))
                safe_write(ws, f"{cols['program']}{row_ptr}", int(r.get("program_num", 0)))
                safe_write(ws, f"{cols['daypart']}{row_ptr}", sanitize_text(r["daypart"]))
                safe_write(ws, f"{cols['seconds']}{row_ptr}", sanitize_text(f"{r['seconds']}ç§’å»£å‘Š"))
                safe_write(ws, f"{cols['proj_price']}{row_ptr}", r.get("pkg_display_val", 0) if isinstance(r.get("pkg_display_val", 0), int) else 0)

                set_schedule(ws, row_ptr, meta["schedule_start_col"], meta["max_days"], r["schedule"])
                spot_sum = sum(r["schedule"][:meta["max_days"]])
                safe_write(ws, f"{meta['total_col']}{row_ptr}", spot_sum)

                written_rows.append(row_ptr)
                row_ptr += 1

    # Total row
    eff_days = min((end_dt - start_dt).days + 1, meta["max_days"])
    daily_sums = [sum([x["schedule"][d] for x in rows if d < len(x["schedule"])]) for d in range(eff_days)]
    set_schedule(ws, total_row, meta["schedule_start_col"], meta["max_days"], daily_sums)
    safe_write(ws, f"{meta['total_col']}{total_row}", sum(daily_sums))

    total_pkg = sum([x.get("pkg_display_val", 0) for x in rows if isinstance(x.get("pkg_display_val", 0), int)])
    pkg_col = cols.get("pkg") or cols.get("proj_price")
    safe_write(ws, f"{pkg_col}{total_row}", total_pkg)

    # Footer
    lbl = meta["footer_labels"]
    def write_footer(key, val):
        pos = find_cell_exact(ws, lbl.get(key, ""))
        if pos:
            safe_write_rc(ws, pos[0], pos[1] + 1, int(val))

    make_fee = 10000
    pos_make = find_cell_exact(ws, lbl["make"])
    if pos_make:
        v = ws.cell(pos_make[0], pos_make[1] + 1).value
        if isinstance(v, (int, float)) and v > 0:
            make_fee = int(v)
        else:
            safe_write_rc(ws, pos_make[0], pos_make[1] + 1, make_fee)

    vat = int(round((total_pkg + make_fee) * 0.05))
    write_footer("vat", vat)
    write_footer("grand", total_pkg + make_fee + vat)

    # Remarks
    rem_pos = find_cell_exact(ws, "Remarksï¼š")
    if rem_pos:
        for i, rm in enumerate(remarks_list):
            safe_write_rc(ws, rem_pos[0] + 1 + i, rem_pos[1], sanitize_text(rm))

    # âœ…è£œå¼·ç½®ä¸­ï¼ˆé¿å… E/F/G/H ä¸ç½®ä¸­ï¼‰
    if format_type == "Dongwu" and written_rows:
        min_r, max_r = min(written_rows), total_row
        force_center_columns_range(ws, meta["force_center_cols"], min_r, max_r)

    # âœ…PDF æ“¬çœŸåº¦é—œéµï¼šå¼·åˆ¶åˆ—å°/ç¸®æ”¾/print areaï¼ˆæ±å³ + è²æ´» å…±ç”¨ï¼‰
    try:
        ws.page_setup.orientation = "landscape"
        ws.sheet_properties.pageSetUpPr.fitToPage = True
        ws.page_setup.fitToWidth = 1
        ws.page_setup.fitToHeight = 0

        ws.page_margins.left = 0.2
        ws.page_margins.right = 0.2
        ws.page_margins.top = 0.2
        ws.page_margins.bottom = 0.2
        ws.page_margins.header = 0.1
        ws.page_margins.footer = 0.1

        last_col = meta["total_col"]
        last_row = total_row + 20
        if rem_pos:
            last_row = max(last_row, rem_pos[0] + 10)
        ws.print_area = f"A1:{last_col}{last_row}"
    except:
        pass

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()

# =========================================================
# 5) HTML Previewï¼ˆåƒ…ä¾›ç¶²é é¡¯ç¤ºï¼›PDF ä»¥ xlsxâ†’pdf ç‚ºä¸»ï¼‰
# =========================================================
def generate_html_preview(rows, days_cnt, start_dt, end_dt, c_name, p_display, format_type, remarks):
    header_cls = "bg-dw-head" if format_type == "Dongwu" else "bg-sh-head"
    media_order = {"å…¨å®¶å»£æ’­": 1, "æ–°é®®è¦–": 2, "å®¶æ¨‚ç¦": 3}
    eff_days = min(days_cnt, 31 if format_type == "Dongwu" else 23)

    date_headers_1 = ""
    date_headers_2 = ""
    curr = start_dt
    weekdays = ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "æ—¥"]
    for _ in range(eff_days):
        wd = curr.weekday()
        bg = "bg-weekend" if (format_type == "Dongwu" and wd >= 5) else header_cls
        if format_type == "Shenghuo":
            bg = header_cls
        date_headers_1 += f"<th class='{bg}'>{curr.day}</th>"
        date_headers_2 += f"<th class='{bg}'>{weekdays[wd]}</th>"
        curr += timedelta(days=1)

    if format_type == "Dongwu":
        cols_def = ["Station", "Location", "Program", "Day-part", "Size", "rate<br>(List)", "Package<br>(List)"]
    else:
        cols_def = ["é »é“", "æ’­å‡ºåœ°å€", "æ’­å‡ºåº—æ•¸", "æ’­å‡ºæ™‚é–“", "ç§’æ•¸<br>è¦æ ¼", "å°ˆæ¡ˆåƒ¹"]
    th_fixed = "".join([f"<th class='{header_cls}' rowspan='2'>{c}</th>" for c in cols_def])

    def region_rank(r):
        if r in REGIONS_ORDER:
            return REGIONS_ORDER.index(r)
        return 99

    rows_sorted = sorted(
        rows,
        key=lambda x: (media_order.get(x["media_type"], 99), x.get("seconds", 0), region_rank(x.get("region", "")))
    )

    tbody = ""
    media_group_counts = {}
    for r in rows_sorted:
        media_group_counts[r["media_type"]] = media_group_counts.get(r["media_type"], 0) + 1
    media_printed = {m: False for m in media_group_counts}

    # Dongwuï¼šåœ¨é è¦½ä¹Ÿæ¨¡æ“¬ã€Œç§’æ•¸å€å¡Šã€åªé¡¯ç¤ºä¸€æ¬¡ daypart/size/rate/pkg
    last_key = None

    for r in rows_sorted:
        m = r["media_type"]
        sec = r.get("seconds", "")
        key = (m, sec)

        tbody += "<tr>"

        if format_type == "Dongwu":
            if not media_printed[m]:
                rowspan = media_group_counts[m]
                display_name = "å…¨å®¶ä¾¿åˆ©å•†åº—<br>é€šè·¯å»£æ’­å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "å…¨å®¶ä¾¿åˆ©å•†åº—<br>æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
                tbody += f"<td rowspan='{rowspan}' class='align-left'>{display_name}</td>"
                media_printed[m] = True

            tbody += f"<td>{region_display(r['region'])}</td>"
            tbody += f"<td class='align-right'>{int(r.get('program_num', 0)):,}</td>"

            if key != last_key:
                tbody += f"<td>{sanitize_text(r['daypart'])}</td>"
                sec_txt = f"{r['seconds']}ç§’" if m == "å®¶æ¨‚ç¦" else f"{int(r['seconds'])}"
                tbody += f"<td>{sanitize_text(sec_txt)}</td>"

                rate = r.get("rate_list", "")
                pkg = r.get("pkg_display_val", "")
                rate_disp = f"{rate:,}" if isinstance(rate, int) else sanitize_text(str(rate))
                pkg_disp = f"{pkg:,}" if isinstance(pkg, int) else sanitize_text(str(pkg))
                tbody += f"<td class='align-right'>{rate_disp}</td>"
                tbody += f"<td class='align-right'>{pkg_disp}</td>"
            else:
                tbody += "<td></td><td></td><td></td><td></td>"

            for d in r["schedule"][:eff_days]:
                tbody += f"<td>{d}</td>"
            tbody += f"<td class='bg-total'>{sum(r['schedule'][:eff_days])}</td></tr>"
            last_key = key

        else:
            display_name = "å…¨å®¶ä¾¿åˆ©å•†åº—<br>å»£æ’­é€šè·¯å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "å…¨å®¶ä¾¿åˆ©å•†åº—<br>æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
            tbody += f"<td class='align-left'>{display_name}</td>"
            tbody += f"<td>{region_display(r['region'])}</td>"
            tbody += f"<td class='align-right'>{int(r.get('program_num', 0)):,}</td>"
            tbody += f"<td>{sanitize_text(r['daypart'])}</td>"
            tbody += f"<td>{sanitize_text(str(r['seconds']) + 'ç§’å»£å‘Š')}</td>"
            pkg = r.get("pkg_display_val", 0)
            pkg_disp = f"{pkg:,}" if isinstance(pkg, int) else sanitize_text(str(pkg))
            tbody += f"<td class='align-right'>{pkg_disp}</td>"
            for d in r["schedule"][:eff_days]:
                tbody += f"<td>{d}</td>"
            tbody += f"<td class='bg-total'>{sum(r['schedule'][:eff_days])}</td></tr>"

    totals = [sum([r["schedule"][d] for r in rows if d < len(r["schedule"])]) for d in range(eff_days)]
    total_spots = sum(totals)
    total_pkg = sum([r.get("pkg_display_val", 0) for r in rows if isinstance(r.get("pkg_display_val", 0), int)])

    if format_type == "Dongwu":
        tfoot = f"<tr class='bg-total'><td colspan='5' class='align-left'>Total</td><td></td><td class='align-right'>{total_pkg:,}</td>"
    else:
        tfoot = f"<tr class='bg-total'><td colspan='5' class='align-left'>Total</td><td class='align-right'>{total_pkg:,}</td>"
    for t in totals:
        tfoot += f"<td>{t}</td>"
    tfoot += f"<td>{total_spots}</td></tr>"

    remarks_html = "<div style='margin-top:10px; font-size:12px; line-height:1.6; border-top:2px solid #000; padding-top:8px; text-align:left;'>" \
                   "<b style='text-decoration:underline;'>Remarksï¼š</b><br>" + "<br>".join([sanitize_text(x) for x in remarks]) + "</div>"

    return f"""
    <div class="preview-wrapper">
      <div style="margin-bottom:8px;">
        <b>å®¢æˆ¶ï¼š</b>{sanitize_text(c_name)} &nbsp; <b>ç”¢å“ï¼š</b>{sanitize_text(p_display)}<br>
        <span style="color:#666;">èµ°æœŸï¼š{start_dt} ~ {end_dt}</span>
      </div>
      <table class="excel-table">
        <thead>
          <tr>
            {th_fixed}{date_headers_1}
            <th class="{header_cls}" rowspan="2">æª”æ¬¡</th>
          </tr>
          <tr>{date_headers_2}</tr>
        </thead>
        <tbody>
          {tbody}
          {tfoot}
        </tbody>
      </table>
      {remarks_html}
    </div>
    """

# =========================================================
# 6) UI Main
# =========================================================
st.title("ğŸ“º åª’é«” Cue è¡¨ç”Ÿæˆå™¨ (v63.1ï¼šé›²ç«¯ PDF æ“¬çœŸæå‡)")

auto_tpl, source, msgs = load_default_template()
template_bytes = auto_tpl

if msgs:
    for m in msgs:
        st.caption(m)

if auto_tpl:
    st.success(f"âœ… å·²è¼‰å…¥ç³»çµ±å…¬ç‰ˆ ({source})")
else:
    st.warning("âš ï¸ ç„¡æ³•è¼‰å…¥å…¬ç‰ˆï¼Œè«‹æ‰‹å‹•ä¸Šå‚³æ¨¡æ¿")
    tpl = st.file_uploader("ä¸Šå‚³ Excel æ¨¡æ¿ï¼ˆ1209-Cueè¡¨ç›¸é—œè³‡æ–™.xlsxï¼‰", type=["xlsx"])
    if tpl:
        template_bytes = tpl.read()

st.markdown("### 1. é¸æ“‡æ ¼å¼")
format_type = st.radio("", ["Dongwu", "Shenghuo"], horizontal=True, label_visibility="collapsed")

with st.container():
    st.markdown("### 2. åŸºæœ¬è³‡æ–™è¨­å®š")
    with st.expander("ğŸ“ é»æ“Šå±•é–‹/æ”¶åˆåŸºæœ¬è³‡æ–™", expanded=True):
        c1, c2, c3 = st.columns(3)
        with c1:
            client_name = st.text_input("å®¢æˆ¶åç¨±", "è¬åœ‹é€šè·¯")
        with c2:
            product_name = st.text_input("ç”¢å“åç¨±", "çµ±ä¸€å¸ƒä¸")
        with c3:
            total_budget_input = st.number_input("ç¸½é ç®— (æœªç¨… Net)", value=1000000, step=10000)

        c4, c5 = st.columns(2)
        with c4:
            start_date = st.date_input("é–‹å§‹æ—¥", datetime(2026, 1, 1))
        with c5:
            end_date = st.date_input("çµæŸæ—¥", datetime(2026, 1, 31))

        days_count = (end_date - start_date).days + 1
        st.info(f"ğŸ“… èµ°æœŸå…± **{days_count}** å¤©")

with st.expander("ğŸ“ å‚™è¨»æ¬„ä½è¨­å®š (Remarks)", expanded=False):
    rc1, rc2, rc3 = st.columns(3)
    sign_deadline = rc1.date_input("å›ç°½æˆªæ­¢æ—¥", datetime.now() + timedelta(days=3))
    billing_month = rc2.text_input("è«‹æ¬¾æœˆä»½", "2026å¹´2æœˆ")
    payment_date = rc3.date_input("ä»˜æ¬¾å…Œç¾æ—¥", datetime(2026, 3, 31))

st.markdown("### 3. åª’é«”æŠ•æ”¾è¨­å®š")
m1, m2, m3 = st.columns(3)
config = {}
rem_budget = 100

with m1:
    if st.checkbox("å…¨å®¶å»£æ’­", True):
        is_nat = st.checkbox("å…¨çœè¯æ’­ï¼ˆä»¥6å€å‡ºè¡¨ï¼‰", True, key="rad_nat")
        regs = REGIONS_ORDER if is_nat else st.multiselect("å€åŸŸ", REGIONS_ORDER, default=REGIONS_ORDER, key="rad_reg")
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [20], key="rad_sec")
        share = st.slider("é ç®— %", 0, 100, 60, key="rad_share")
        rem_budget -= share

        sec_shares = {}
        if len(secs) > 1:
            ls = 100
            for s in sorted(secs)[:-1]:
                v = st.slider(f"{s}ç§’ %", 0, ls, int(ls / 2), key=f"rs_{s}")
                sec_shares[s] = v
                ls -= v
            sec_shares[sorted(secs)[-1]] = ls
        elif secs:
            sec_shares[secs[0]] = 100

        config["å…¨å®¶å»£æ’­"] = {"is_national": is_nat, "regions": regs, "seconds": sorted(secs), "share": share, "sec_shares": sec_shares}

with m2:
    if st.checkbox("æ–°é®®è¦–", True):
        is_nat = st.checkbox("å…¨çœè¯æ’­ï¼ˆä»¥6å€å‡ºè¡¨ï¼‰", False, key="fv_nat")
        regs = REGIONS_ORDER if is_nat else st.multiselect("å€åŸŸ", REGIONS_ORDER, default=["åŒ—å€"], key="fv_reg")
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [10], key="fv_sec")
        share = st.slider("é ç®— %", 0, rem_budget, min(20, rem_budget), key="fv_share")
        rem_budget -= share

        sec_shares = {}
        if len(secs) > 1:
            ls = 100
            for s in sorted(secs)[:-1]:
                v = st.slider(f"{s}ç§’ %", 0, ls, int(ls / 2), key=f"fs_{s}")
                sec_shares[s] = v
                ls -= v
            sec_shares[sorted(secs)[-1]] = ls
        elif secs:
            sec_shares[secs[0]] = 100

        config["æ–°é®®è¦–"] = {"is_national": is_nat, "regions": regs, "seconds": sorted(secs), "share": share, "sec_shares": sec_shares}

with m3:
    if st.checkbox("å®¶æ¨‚ç¦", True):
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [20], key="cf_sec")
        st.info(f"å‰©é¤˜é ç®—: {rem_budget}%")

        sec_shares = {}
        if len(secs) > 1:
            ls = 100
            for s in sorted(secs)[:-1]:
                v = st.slider(f"{s}ç§’ %", 0, ls, int(ls / 2), key=f"cs_{s}")
                sec_shares[s] = v
                ls -= v
            sec_shares[sorted(secs)[-1]] = ls
        elif secs:
            sec_shares[secs[0]] = 100

        config["å®¶æ¨‚ç¦"] = {"regions": ["å…¨çœ"], "seconds": sorted(secs), "share": rem_budget, "sec_shares": sec_shares}

rows = []
debug_logs = []

if config:
    for m, cfg in config.items():
        m_budget = total_budget_input * (cfg["share"] / 100.0)
        for sec, sec_pct in cfg["sec_shares"].items():
            s_budget = m_budget * (sec_pct / 100.0)
            if s_budget <= 0:
                continue

            factor = get_sec_factor(m, sec)

            if m in ["å…¨å®¶å»£æ’­", "æ–°é®®è¦–"]:
                db = PRICING_DB[m]
                calc_regs = REGIONS_ORDER if cfg["is_national"] else cfg["regions"]
                display_regs = REGIONS_ORDER if cfg["is_national"] else cfg["regions"]

                unit_net_sum = 0
                for r in calc_regs:
                    unit_net_sum += (db[r][1] / db["Std_Spots"]) * factor

                if unit_net_sum == 0:
                    continue

                spots_init = math.ceil(s_budget / unit_net_sum)
                penalty = 1.1 if spots_init < db["Std_Spots"] else 1.0
                spots_final = math.ceil(s_budget / (unit_net_sum * penalty))
                if spots_final % 2 != 0:
                    spots_final += 1
                if spots_final == 0:
                    spots_final = 2

                sch = calculate_schedule(spots_final, days_count)

                debug_logs.append({
                    "media": m, "sec": sec, "budget": s_budget,
                    "unit_cost": unit_net_sum * penalty, "spots": spots_final,
                    "std": db["Std_Spots"],
                    "status": "æœªé”æ¨™" if penalty > 1 else "é”æ¨™",
                    "reason": "æ‡²ç½° x1.1" if penalty > 1 else "è²»ç‡æ­£å¸¸"
                })

                for r in display_regs:
                    rate_list = int((db[r][0] / db["Std_Spots"]) * factor)
                    pkg_list = rate_list * spots_final
                    rows.append({
                        "media_type": m,
                        "region": r,
                        "program_num": STORE_COUNTS_NUM.get(f"æ–°é®®è¦–_{r}" if m == "æ–°é®®è¦–" else r, 0),
                        "daypart": db["Day_Part"],
                        "seconds": sec,
                        "spots": spots_final,
                        "schedule": sch,
                        "rate_list": rate_list,
                        "pkg_display_val": pkg_list
                    })

            elif m == "å®¶æ¨‚ç¦":
                db = PRICING_DB["å®¶æ¨‚ç¦"]
                base_std = db["é‡è²©_å…¨çœ"]["Std_Spots"]
                unit_net = (db["é‡è²©_å…¨çœ"]["Net"] / base_std) * factor

                spots_init = math.ceil(s_budget / unit_net)
                penalty = 1.1 if spots_init < base_std else 1.0
                spots_final = math.ceil(s_budget / (unit_net * penalty))
                if spots_final % 2 != 0:
                    spots_final += 1

                sch_h = calculate_schedule(spots_final, days_count)
                debug_logs.append({
                    "media": m, "sec": sec, "budget": s_budget,
                    "unit_cost": unit_net * penalty, "spots": spots_final,
                    "std": base_std,
                    "status": "æœªé”æ¨™" if penalty > 1 else "é”æ¨™",
                    "reason": "æ‡²ç½° x1.1" if penalty > 1 else "è²»ç‡æ­£å¸¸"
                })

                rate_h = int((db["é‡è²©_å…¨çœ"]["List"] / base_std) * factor)
                rows.append({
                    "media_type": m,
                    "region": "å…¨çœé‡è²©",
                    "program_num": STORE_COUNTS_NUM["å®¶æ¨‚ç¦_é‡è²©"],
                    "daypart": db["é‡è²©_å…¨çœ"]["Day_Part"],
                    "seconds": sec,
                    "spots": spots_final,
                    "schedule": sch_h,
                    "rate_list": rate_h,
                    "pkg_display_val": rate_h * spots_final
                })

                spots_s = int(spots_final * (db["è¶…å¸‚_å…¨çœ"]["Std_Spots"] / base_std))
                sch_s = calculate_schedule(spots_s, days_count)
                rows.append({
                    "media_type": m,
                    "region": "å…¨çœè¶…å¸‚",
                    "program_num": STORE_COUNTS_NUM["å®¶æ¨‚ç¦_è¶…å¸‚"],
                    "daypart": db["è¶…å¸‚_å…¨çœ"]["Day_Part"],
                    "seconds": sec,
                    "spots": spots_s,
                    "schedule": sch_s,
                    "rate_list": "è¨ˆé‡è²©",
                    "pkg_display_val": "è¨ˆé‡è²©"
                })

p_str = f"{'ã€'.join([f'{s}ç§’' for s in sorted(list(set(r['seconds'] for r in rows)))])} {product_name}" if rows else ""
rem = get_remarks_text(sign_deadline, billing_month, payment_date)

with st.expander("ğŸ’¡ ç³»çµ±é‹ç®—é‚è¼¯èªªæ˜ (Debug Panel)", expanded=False):
    for log in debug_logs:
        color = "green" if log["status"] == "é”æ¨™" else "red"
        st.markdown(
            f"**{log['media']} ({log['sec']}ç§’)**ï¼šé ç®— ${log['budget']:,.0f} | æª”æ¬¡ {log['spots']} "
            f"â†’ <span style='color:{color}'><b>{log['status']}</b></span>ï¼ˆ{log['reason']}ï¼‰",
            unsafe_allow_html=True
        )

if rows:
    html = generate_html_preview(rows, days_count, start_date, end_date, client_name, p_str, format_type, rem)
    st.components.v1.html(html, height=720, scrolling=True)

    if template_bytes:
        try:
            xlsx_bytes = generate_excel_from_template(format_type, start_date, end_date, client_name, p_str, rows, rem, template_bytes)

            st.download_button(
                "ğŸ“¥ ä¸‹è¼‰ Excelï¼ˆæ¨¡æ¿æ“¬çœŸç‰ˆï¼‰",
                xlsx_bytes,
                file_name=f"Cue_{sanitize_text(client_name)}_{format_type}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

            # âœ…PDFï¼šå„ªå…ˆ xlsxâ†’pdfï¼ˆæœ€åƒï¼‰ï¼Œå¤±æ•—æ‰ fallback WeasyPrint
            pdf_bytes, method, err = xlsx_bytes_to_pdf_bytes(xlsx_bytes)
            if pdf_bytes:
                st.download_button(
                    f"ğŸ“„ ä¸‹è¼‰ PDFï¼ˆ{method}ï¼šæ“¬çœŸåº¦é«˜ï¼‰",
                    pdf_bytes,
                    file_name=f"Cue_{sanitize_text(client_name)}_{format_type}.pdf",
                    mime="application/pdf"
                )
                st.caption(f"PDF ç”¢ç”Ÿæ–¹å¼ï¼š{method}")
            else:
                st.warning(f"âš ï¸ ç›®å‰ç’°å¢ƒç„¡æ³•ç”¨ Excel/LibreOffice ç”¢ PDFï¼ˆ{method}ï¼‰ã€‚æ”¹ç”¨ WeasyPrint fallbackï¼ˆæ“¬çœŸåº¦æœƒä¸‹é™ï¼‰ã€‚")
                pdf2, err2 = html_to_pdf_weasyprint(html)
                if pdf2:
                    st.download_button(
                        "ğŸ“„ ä¸‹è¼‰ PDFï¼ˆWeasyPrint fallbackï¼‰",
                        pdf2,
                        file_name=f"Cue_{sanitize_text(client_name)}_{format_type}.pdf",
                        mime="application/pdf"
                    )
                else:
                    st.error(f"PDF ç”¢å‡ºå¤±æ•—ï¼š{err} | fallbackï¼š{err2}")

            # å°æç¤ºï¼šé›²ç«¯æ˜¯å¦æœ‰ soffice
            soffice = find_soffice_path()
            if soffice:
                st.caption(f"âœ… é›²ç«¯åµæ¸¬åˆ° LibreOffice: {soffice}")
            else:
                st.caption("âš ï¸ é›²ç«¯æœªåµæ¸¬åˆ° LibreOffice/sofficeï¼ˆè‹¥ä½ æœ‰ packages.txt å®‰è£ï¼Œé‡æ–°éƒ¨ç½²å¾Œæœƒå‡ºç¾ï¼‰")

        except Exception as e:
            st.error(f"Excel ç”¢å‡ºéŒ¯èª¤: {e}")
    else:
        st.warning("è«‹ä¸Šå‚³æ¨¡æ¿ä»¥å•Ÿç”¨ä¸‹è¼‰ã€‚")
else:
    st.info("è«‹å…ˆè¨­å®šåª’é«”/ç§’æ•¸/é ç®—ï¼Œç³»çµ±æ‰æœƒç”¢ç”Ÿ Cue è¡¨ã€‚")
