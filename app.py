import streamlit as st
import math
import io
import os
import shutil
import tempfile
import subprocess
import re
import base64
from datetime import timedelta, datetime, date
from copy import copy

import requests
import openpyxl
from openpyxl.utils import column_index_from_string
from openpyxl.cell.cell import MergedCell
from openpyxl.formula.translate import Translator
from openpyxl.styles import Alignment, Font, Border, Side, PatternFill

# =========================================================
# 0. åŸºç¤å·¥å…·
# =========================================================
def parse_count_to_int(x):
    if x is None: return 0
    if isinstance(x, (int, float)): return int(x)
    s = str(x)
    m = re.findall(r"[\d,]+", s)
    if not m: return 0
    return int(m[0].replace(",", ""))

def safe_filename(name: str) -> str:
    return re.sub(r'[\\/*?:"<>|]', "_", name).strip()

def html_escape(s):
    if s is None: return ""
    return str(s).replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;").replace("'", "&#39;")

# =========================================================
# 1. é é¢è¨­å®š & è‡ªå‹•è¼‰å…¥
# =========================================================
st.set_page_config(layout="wide", page_title="Cue Sheet Pro v66.1 (Value Anchor)")

GOOGLE_DRIVE_FILE_ID = "11R1SA_hpFD5O_MGmYeh4BdtcUhK2bPta"
DEFAULT_FILENAME = "1209-Cueè¡¨ç›¸é—œè³‡æ–™.xlsx"

@st.cache_resource(ttl=600)
def load_default_template():
    status_msg = []
    if GOOGLE_DRIVE_FILE_ID:
        url = f"https://drive.google.com/uc?export=download&id={GOOGLE_DRIVE_FILE_ID}"
        try:
            r = requests.get(url, timeout=20, allow_redirects=True)
            if r.status_code == 200:
                if b"<!DOCTYPE html>" in r.content[:500]:
                    status_msg.append("âš ï¸ Drive ä¸‹è¼‰æ¬Šé™å—é™")
                else:
                    return r.content, "é›²ç«¯ç¡¬ç¢Ÿ (Google Drive)", status_msg
        except Exception as e:
            status_msg.append(f"âŒ é€£ç·šéŒ¯èª¤: {e}")

    if os.path.exists(DEFAULT_FILENAME):
        try:
            with open(DEFAULT_FILENAME, "rb") as f:
                return f.read(), "ç³»çµ±ä¸»æ©Ÿ (Local)", status_msg
        except: pass
    
    return None, None, status_msg

# =========================================================
# 2. GPT æ ¸å¿ƒå¼•æ“ï¼šExcel è½‰ PDF
# =========================================================
def find_soffice_path():
    soffice = shutil.which("soffice") or shutil.which("libreoffice")
    if soffice: return soffice
    if os.name == "nt":
        candidates = [
            r"C:\Program Files\LibreOffice\program\soffice.exe",
            r"C:\Program Files (x86)\LibreOffice\program\soffice.exe",
        ]
        for p in candidates:
            if os.path.exists(p): return p
    return None

def xlsx_bytes_to_pdf_bytes(xlsx_bytes: bytes):
    if os.name == "nt":
        try:
            import win32com.client
            with tempfile.TemporaryDirectory() as tmp:
                xlsx_path = os.path.join(tmp, "cue.xlsx")
                pdf_path = os.path.join(tmp, "cue.pdf")
                with open(xlsx_path, "wb") as f: f.write(xlsx_bytes)

                excel = win32com.client.DispatchEx("Excel.Application")
                excel.Visible = False
                excel.DisplayAlerts = False
                wb = None
                try:
                    wb = excel.Workbooks.Open(xlsx_path)
                    wb.ExportAsFixedFormat(0, pdf_path)
                except: pass
                finally:
                    if wb: 
                        try: wb.Close(False)
                        except: pass
                    try: excel.Quit()
                    except: pass

                if os.path.exists(pdf_path):
                    with open(pdf_path, "rb") as f: return f.read(), "Excel App (Local)", ""
        except: pass

    soffice = find_soffice_path()
    if soffice:
        try:
            with tempfile.TemporaryDirectory() as tmp:
                xlsx_path = os.path.join(tmp, "cue.xlsx")
                with open(xlsx_path, "wb") as f: f.write(xlsx_bytes)

                subprocess.run(
                    [soffice, "--headless", "--nologo", "--convert-to", "pdf", "--outdir", tmp, xlsx_path],
                    capture_output=True, timeout=60
                )
                
                pdf_path = os.path.join(tmp, "cue.pdf")
                if not os.path.exists(pdf_path):
                    for fn in os.listdir(tmp):
                        if fn.endswith(".pdf"): pdf_path = os.path.join(tmp, fn); break
                
                if os.path.exists(pdf_path):
                    with open(pdf_path, "rb") as f: return f.read(), "LibreOffice", ""
                
                return None, "Fail", "LibreOffice è½‰æª”ç„¡è¼¸å‡º"
        except Exception as e:
            return None, "Fail", str(e)

    return None, "Fail", "ç„¡å¯ç”¨çš„ Excel è½‰æª”å¼•æ“"

# =========================================================
# 3. WeasyPrint Fallback
# =========================================================
def html_to_pdf_fallback(html_str, font_b64):
    try: 
        from weasyprint import HTML, CSS
        from weasyprint.text.fonts import FontConfiguration
        font_config = FontConfiguration()
        css_str = """
        @page { size: A4 landscape; margin: 0.5cm; }
        body { font-family: 'NotoSansTC', sans-serif !important; font-size: 8pt; }
        table { width: 100%; border-collapse: collapse; table-layout: fixed; }
        th, td { border: 0.5pt solid #000; padding: 2px; text-align: center; white-space: nowrap; overflow: hidden; }
        .bg-dw-head { background-color: #4472C4; color: white; -webkit-print-color-adjust: exact; }
        .bg-sh-head { background-color: #BDD7EE; color: black; -webkit-print-color-adjust: exact; }
        .bg-weekend { background-color: #FFD966; -webkit-print-color-adjust: exact; }
        .bg-total   { background-color: #FFF2CC; -webkit-print-color-adjust: exact; }
        .left { text-align: left !important; }
        .right { text-align: right !important; }
        tr { page-break-inside: avoid; }
        """
        if font_b64:
            css_str = f"@font-face {{ font-family: 'NotoSansTC'; src: url(data:font/ttf;base64,{font_b64}) format('truetype'); }} " + css_str
        pdf_bytes = HTML(string=html_str).write_pdf(stylesheets=[CSS(string=css_str)], font_config=font_config)
        return pdf_bytes, ""
    except Exception as e:
        return None, str(e)

# =========================================================
# 4. è³‡æ–™åº« (2026 æ ¸å¿ƒ)
# =========================================================
STORE_COUNTS_RAW = {
    "å…¨çœ": "4,437åº—", "åŒ—å€": "1,649åº—", "æ¡ƒç«¹è‹—": "779åº—", "ä¸­å€": "839åº—", "é›²å˜‰å—": "499åº—", "é«˜å±": "490åº—", "æ±å€": "181åº—",
    "æ–°é®®è¦–_å…¨çœ": "3,124é¢", "æ–°é®®è¦–_åŒ—å€": "1,127é¢", "æ–°é®®è¦–_æ¡ƒç«¹è‹—": "616é¢", "æ–°é®®è¦–_ä¸­å€": "528é¢",
    "æ–°é®®è¦–_é›²å˜‰å—": "365é¢", "æ–°é®®è¦–_é«˜å±": "405é¢", "æ–°é®®è¦–_æ±å€": "83é¢",
    "å®¶æ¨‚ç¦_é‡è²©": "67åº—", "å®¶æ¨‚ç¦_è¶…å¸‚": "250åº—"
}
STORE_COUNTS_NUM = {k: parse_count_to_int(v) for k, v in STORE_COUNTS_RAW.items()}
REGIONS_ORDER = ["åŒ—å€", "æ¡ƒç«¹è‹—", "ä¸­å€", "é›²å˜‰å—", "é«˜å±", "æ±å€"]
DURATIONS = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]

PRICING_DB = {
    "å…¨å®¶å»£æ’­": { "Std_Spots": 480, "Day_Part": "00:00-24:00", 
        "å…¨çœ": [400000, 320000], 
        "åŒ—å€": [250000, 200000], "æ¡ƒç«¹è‹—": [150000, 120000], "ä¸­å€": [150000, 120000],
        "é›²å˜‰å—": [100000, 80000], "é«˜å±": [100000, 80000], "æ±å€": [62500, 50000] },
    "æ–°é®®è¦–": { "Std_Spots": 504, "Day_Part": "07:00-22:00", 
        "å…¨çœ": [150000, 120000], 
        "åŒ—å€": [150000, 120000], "æ¡ƒç«¹è‹—": [120000, 96000], "ä¸­å€": [90000, 72000],
        "é›²å˜‰å—": [75000, 60000], "é«˜å±": [75000, 60000], "æ±å€": [45000, 36000] },
    "å®¶æ¨‚ç¦": {
        "é‡è²©_å…¨çœ": {"List": 300000, "Net": 250000, "Std_Spots": 420, "Day_Part": "09:00-23:00"},
        "è¶…å¸‚_å…¨çœ": {"List": 100000, "Net": 80000, "Std_Spots": 720, "Day_Part": "00:00-24:00"} }
}

SEC_FACTORS = {
    "å…¨å®¶å»£æ’­": {30: 1.0, 20: 0.85, 15: 0.65, 10: 0.5, 5: 0.25},
    "æ–°é®®è¦–": {30: 3.0, 20: 2.0, 15: 1.5, 10: 1.0, 5: 0.5},
    "å®¶æ¨‚ç¦": {30: 1.5, 20: 1.0, 15: 0.85, 10: 0.65, 5: 0.35}
}

def get_sec_factor(media_type, seconds): return SEC_FACTORS.get(media_type, {}).get(seconds, 1.0)

def calculate_schedule(total_spots, days):
    if days <= 0: return []
    if total_spots % 2 != 0: total_spots += 1
    half_spots = total_spots // 2
    base, rem = divmod(half_spots, days)
    half_schedule = [base + (1 if i < rem else 0) for i in range(days)]
    return [x * 2 for x in half_schedule]

def get_remarks_text(sign_deadline, billing_month, payment_date):
    d_str = sign_deadline.strftime("%Y/%m/%d (%a) %H:%M") if sign_deadline else "____/__/__ (__) 12:00"
    p_str = payment_date.strftime("%Y/%m/%d") if payment_date else "____/__/__"
    return [
        f"1.è«‹æ–¼ {d_str}å‰ å›ç°½åŠé€²å–®ï¼Œæ–¹å¯é †åˆ©ä¸Šæª”ã€‚",
        "2.ä»¥ä¸Šç¯€ç›®åç¨±å¦‚æœ‰ç•°å‹•ï¼Œä»¥ä¸Šæª”æ™‚ç¯€ç›®åç¨±ç‚ºä¸»ï¼Œå¦‚é‡æ™‚æ®µæ»¿æª”ï¼Œä¸Šæª”æ™‚é–“æŒªå¾Œæˆ–æ›´æ›è‡³åŒç´šæ™‚æ®µã€‚",
        "3.é€šè·¯åº—é‹ªæ•¸èˆ‡é–‹æ©Ÿç‡é–‹æ©Ÿç‡è‡³å°‘ä¸ƒæˆ(ä»¥ä¸Š)ã€‚æ¯æ—¥å› åŠ ç›Ÿæ•¸èª¿æ•´ï¼Œæˆ–é‡åº—èˆ–å¹´åº¦å­£åº¦æ”¹è£ã€è¨­å‚™ç¶­è­·å‡ç´šåŠä¿ä¿®ç­‰ç‹€æ³ï¼Œæœƒæœ‰ä¸€å®šå¹…åº¦å¢æ¸›ã€‚",
        "4.è¨—æ’­æ–¹éœ€æ–¼ä¸Šæª”å‰ 5 å€‹å·¥ä½œå¤©ï¼Œæä¾›å»£å‘Šå¸¶(mp3)ã€å½±ç‰‡/å½±åƒ 1920x1080 (mp4)ã€‚",
        f"5.é›™æ–¹åŒæ„è²»ç”¨è«‹æ¬¾æœˆä»½ : {billing_month}ï¼Œå¦‚æœ‰ä¿®æ­£å¿…è¦ï¼Œå°‡å¦è¡ŒE-Mailå‘ŠçŸ¥ï¼Œä¸¦è¦–ç‚ºæ­£å¼åˆç´„ä¹‹ä¸€éƒ¨åˆ†ã€‚",
        f"6.ä»˜æ¬¾å…Œç¾æ—¥æœŸï¼š{p_str}"
    ]

REGION_DISPLAY_6 = {
    "åŒ—å€": "åŒ—å€-åŒ—åŒ—åŸº", "æ¡ƒç«¹è‹—": "æ¡ƒå€-æ¡ƒç«¹è‹—", "ä¸­å€": "ä¸­å€-ä¸­å½°æŠ•",
    "é›²å˜‰å—": "é›²å˜‰å—å€-é›²å˜‰å—", "é«˜å±": "é«˜å±å€-é«˜å±", "æ±å€": "æ±å€-å®œèŠ±æ±",
    "å…¨çœé‡è²©": "å…¨çœé‡è²©", "å…¨çœè¶…å¸‚": "å…¨çœè¶…å¸‚",
}
def region_display(region: str) -> str: return REGION_DISPLAY_6.get(region, region)

# =========================================================
# 5. Excel ç”Ÿæˆæ¨¡çµ„ (Dynamic Rebuild)
# =========================================================
def _get_master_cell(ws, cell):
    if not isinstance(cell, MergedCell): return cell
    for mr in ws.merged_cells.ranges:
        if mr.min_row <= cell.row <= mr.max_row and mr.min_col <= cell.column <= mr.max_col:
            return ws.cell(row=mr.min_row, column=mr.min_col)
    return None

def safe_write(ws, addr, value):
    cell = ws[addr]
    if isinstance(cell, MergedCell):
        master = _get_master_cell(ws, cell)
        if master: master.value = value
    else: cell.value = value

def safe_write_rc(ws, row, col, value):
    cell = ws.cell(row=row, column=col)
    if isinstance(cell, MergedCell):
        master = _get_master_cell(ws, cell)
        if master: master.value = value
    else: cell.value = value

def apply_center_style(cell):
    al = cell.alignment or Alignment()
    cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True, indent=al.indent)

def copy_row_with_style_fix(ws, src_row, dst_row, max_col):
    ws.row_dimensions[dst_row].height = ws.row_dimensions[src_row].height
    row_shift = dst_row - src_row
    for c in range(1, max_col + 1):
        sc = ws.cell(src_row, c)
        dc = ws.cell(dst_row, c)
        if sc.has_style:
            dc.font = copy(sc.font)
            dc.border = copy(sc.border)
            dc.fill = copy(sc.fill)
            dc.number_format = sc.number_format
            dc.protection = copy(sc.protection)
            dc.alignment = copy(sc.alignment)
        v = sc.value
        if isinstance(v, str) and v.startswith("="):
            try: dc.value = Translator(v, origin=sc.coordinate).translate_formula(row_shift=row_shift, col_shift=0)
            except: dc.value = v
        else: dc.value = v

def force_center_columns_range(ws, col_letters, start_row, end_row):
    if start_row is None or end_row is None: return
    for r in range(start_row, end_row + 1):
        for col in col_letters:
            addr = f"{col}{r}"
            cell = ws[addr]
            if isinstance(cell, MergedCell):
                master = _get_master_cell(ws, cell)
                if master: cell = master
                else: continue
            apply_center_style(cell)

def unmerge_col_overlap(ws, col_letter, start_row, end_row):
    st_col = column_index_from_string(col_letter)
    to_unmerge = []
    for mr in list(ws.merged_cells.ranges):
        if mr.min_col == st_col and mr.max_col == st_col:
            if not (mr.max_row < start_row or mr.min_row > end_row):
                to_unmerge.append(str(mr))
    for s in set(to_unmerge):
        try: ws.unmerge_cells(s)
        except: pass

def set_schedule(ws, row, start_col_letter, max_days, schedule_list):
    start_col = column_index_from_string(start_col_letter)
    for i in range(max_days):
        v = schedule_list[i] if (schedule_list and i < len(schedule_list)) else None
        safe_write_rc(ws, row, start_col + i, v)

def find_cell_exact(ws, text):
    for row in ws.iter_rows():
        for cell in row:
            if cell.value == text: return cell.row, cell.column
    return None

def find_first_row_contains(ws, col_letter, keyword):
    col_idx = column_index_from_string(col_letter)
    for r in range(1, ws.max_row + 1):
        v = ws.cell(r, col_idx).value
        if isinstance(v, str) and keyword in v: return r
    return None

SHEET_META = {
    "Dongwu": {
        "sheet_name": "æ±å³-æ ¼å¼", "date_start_cell": "I7", "schedule_start_col": "I",
        "max_days": 31, "total_col": "AN",
        "anchors": {"å…¨å®¶å»£æ’­": "é€šè·¯å»£æ’­å»£å‘Š", "æ–°é®®è¦–": "æ–°é®®è¦–å»£å‘Š", "å®¶æ¨‚ç¦": "å®¶æ¨‚ç¦"},
        "header_cells": {"client": "C3", "product": "C4", "period": "C5", "medium": "C6", "month": "I6"},
        "cols": {"station": "B", "location": "C", "program": "D", "daypart": "E", "seconds": "F", "rate": "G", "pkg": "H"},
        "header_override": {"G7": "rate\n(List)", "H7": "Package-cost\n(List)"},
        "station_merge": True, "total_label": "Total",
        "footer_labels": {"make": "è£½ä½œ", "vat": "5% VAT", "grand": "Grand Total"},
        "force_center_cols": ["E", "F", "G", "H"], 
    },
    "Shenghuo": {
        "sheet_name": "è²æ´»-æ ¼å¼", "date_start_cell": "G7", "schedule_start_col": "G",
        "max_days": 23, "total_col": "AD",
        "anchors": {"å…¨å®¶å»£æ’­": "å»£æ’­é€šè·¯å»£å‘Š", "æ–°é®®è¦–": "æ–°é®®è¦–å»£å‘Š", "å®¶æ¨‚ç¦": "å®¶æ¨‚ç¦"},
        "header_cells": {"client": "C5", "product": "C6", "month": "G6"},
        "cols": {"station": "B", "location": "C", "program": "D", "daypart": "E", "seconds": "F", "proj_price": "AF"},
        "header_override": {"AF7": "å°ˆæ¡ˆåƒ¹\n(List)"}, 
        "station_merge": False, "total_label": "Total",
        "footer_labels": {"make": "è£½ä½œ", "vat": "5% VAT", "grand": "Grand Total"},
        "force_center_cols": [],
    }
}

def generate_excel_from_template(format_type, start_dt, end_dt, client_name, product_display_str, rows, remarks_list, template_bytes):
    meta = SHEET_META[format_type]
    wb = openpyxl.load_workbook(io.BytesIO(template_bytes))
    target_sheet = meta["sheet_name"]
    if target_sheet not in wb.sheetnames: raise ValueError(f"ç¼ºå°‘åˆ†é ï¼š{target_sheet}")
    
    for s in list(wb.sheetnames):
        if s != target_sheet: del wb[s]
    ws = wb[target_sheet]

    hc = meta["header_cells"]
    if "client" in hc: safe_write(ws, hc["client"], client_name)
    if "product" in hc: safe_write(ws, hc["product"], product_display_str)
    if "period" in hc: safe_write(ws, hc["period"], f"{start_dt.strftime('%Y. %m. %d')} - {end_dt.strftime('%Y.%m. %d')}")
    if "medium" in hc: safe_write(ws, hc["medium"], " ".join(sorted(set([r["media_type"] for r in rows]))))
    if "month" in hc: safe_write(ws, hc["month"], f" {start_dt.month}æœˆ")
    safe_write(ws, meta["date_start_cell"], datetime(start_dt.year, start_dt.month, start_dt.day))
    for addr, text in meta.get("header_override", {}).items(): safe_write(ws, addr, text)

    total_cell = find_cell_exact(ws, meta["total_label"])
    if not total_cell: raise ValueError("æ‰¾ä¸åˆ° Total")
    total_row_orig = total_cell[0]
    cols = meta["cols"]
    
    sec_start = {}
    for m_key, kw in meta["anchors"].items():
        r0 = find_first_row_contains(ws, cols["station"], kw)
        if r0: sec_start[m_key] = r0
    
    sec_order = sorted(sec_start.items(), key=lambda x: x[1], reverse=True)
    written_ranges = [] 

    reg_map = {r: i for i, r in enumerate(REGIONS_ORDER + ["å…¨çœé‡è²©", "å…¨çœè¶…å¸‚"])}
    def sort_key(x): return (x["seconds"], reg_map.get(x["region"], 999))
    grouped_data = {
        "å…¨å®¶å»£æ’­": sorted([r for r in rows if r["media_type"] == "å…¨å®¶å»£æ’­"], key=sort_key),
        "æ–°é®®è¦–": sorted([r for r in rows if r["media_type"] == "æ–°é®®è¦–"], key=sort_key),
        "å®¶æ¨‚ç¦": sorted([r for r in rows if r["media_type"] == "å®¶æ¨‚ç¦"], key=sort_key),
    }
    
    current_end_marker = total_row_orig - 1
    
    def station_title(m):
        prefix = "å…¨å®¶ä¾¿åˆ©å•†åº—\n" if m != "å®¶æ¨‚ç¦" else ""
        name = "é€šè·¯å»£æ’­å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
        if format_type == "Shenghuo" and m == "å…¨å®¶å»£æ’­": name = "å»£æ’­é€šè·¯å»£å‘Š"
        return prefix + name

    for i, (m_key, start_row_orig) in enumerate(sec_order):
        style_source_row = start_row_orig + 1
        rows_to_delete = max(0, current_end_marker - style_source_row)
        
        data = grouped_data.get(m_key, [])
        needed = len(data)
        
        if needed == 0:
            if rows_to_delete > 0: ws.delete_rows(style_source_row + 1, amount=rows_to_delete)
            for c in range(1, ws.max_column+1): safe_write_rc(ws, style_source_row, c, None)
            current_end_marker = start_row_orig - 1
            continue

        if rows_to_delete > 0: ws.delete_rows(style_source_row + 1, amount=rows_to_delete)
        if needed > 1:
            ws.insert_rows(style_source_row + 1, amount=needed - 1)
            for r_idx in range(style_source_row + 1, style_source_row + 1 + needed - 1):
                copy_row_with_style_fix(ws, style_source_row, r_idx, ws.max_column)
        
        curr_row = style_source_row
        
        if meta["station_merge"] and needed > 0:
            unmerge_col_overlap(ws, cols["station"], curr_row, curr_row + needed - 1)
            merge_rng = f"{cols['station']}{curr_row}:{cols['station']}{curr_row + needed - 1}"
            ws.merge_cells(merge_rng)
            top_cell = ws[f"{cols['station']}{curr_row}"]
            top_cell.value = station_title(m_key)
            apply_center_style(top_cell)

        for idx, r_data in enumerate(data):
            if not meta["station_merge"]:
                cell = ws[f"{cols['station']}{curr_row}"]
                cell.value = station_title(m_key)
                apply_center_style(cell)
            
            safe_write(ws, f"{cols['location']}{curr_row}", region_display(r_data["region"]))
            prog_val = r_data.get("program_num", parse_count_to_int(r_data.get("program", 0)))
            safe_write(ws, f"{cols['program']}{curr_row}", int(prog_val))

            if format_type == "Dongwu":
                safe_write(ws, f"{cols['daypart']}{curr_row}", r_data["daypart"])
                if m_key == "å®¶æ¨‚ç¦": safe_write(ws, f"{cols['seconds']}{curr_row}", f"{r_data['seconds']}ç§’")
                else: safe_write(ws, f"{cols['seconds']}{curr_row}", int(r_data["seconds"]))
                
                # ğŸŒŸ [é—œéµä¿®æ­£]ï¼šæ¯ä¸€åˆ—éƒ½é¡¯ç¤ºåˆ†å€å®šåƒ¹ (Value Anchor)
                safe_write(ws, f"{cols['rate']}{curr_row}", r_data["rate_list"])
                safe_write(ws, f"{cols['pkg']}{curr_row}", r_data["pkg_display_val"])
            else:
                safe_write(ws, f"{cols['daypart']}{curr_row}", r_data["daypart"])
                safe_write(ws, f"{cols['seconds']}{curr_row}", f"{r_data['seconds']}ç§’å»£å‘Š")
                safe_write(ws, f"{cols['proj_price']}{curr_row}", r_data["pkg_display_val"] if isinstance(r_data["pkg_display_val"], int) else 0)

            set_schedule(ws, curr_row, meta["schedule_start_col"], meta["max_days"], r_data["schedule"])
            spot_sum = sum(r_data["schedule"][:meta["max_days"]])
            safe_write(ws, f"{meta['total_col']}{curr_row}", spot_sum)
            curr_row += 1
            
        written_ranges.append((curr_row - needed, curr_row - 1))
        current_end_marker = start_row_orig - 1

    total_cell = find_cell_exact(ws, meta["total_label"])
    if not total_cell: raise ValueError("æ‰¾ä¸åˆ° Total")
    total_row = total_cell[0]

    eff_days = min((end_dt - start_dt).days + 1, meta["max_days"])
    daily_sums = [sum([x["schedule"][d] for x in rows if d < len(x["schedule"])]) for d in range(eff_days)]
    set_schedule(ws, total_row, meta["schedule_start_col"], meta["max_days"], daily_sums)
    safe_write(ws, f"{meta['total_col']}{total_row}", sum(daily_sums))
    
    # ğŸŒŸ [ç¸½é‡‘é¡è¦†è“‹é‚è¼¯]ï¼šå…¨çœè¯æ’­æ™‚ï¼ŒTotal ç”¨ National Package Price
    total_pkg = 0
    # å…ˆè¨ˆç®—å®¶æ¨‚ç¦çš„éƒ¨åˆ† (å®ƒæ²’æœ‰å…¨çœ/åˆ†å€ä¹‹åˆ†ï¼Œç›´æ¥ç´¯åŠ )
    # ç„¶å¾Œè™•ç†å»£æ’­/æ–°é®®è¦–ï¼šå¦‚æœæ˜¯å…¨çœè¯æ’­ï¼Œç›´æ¥åŠ ä¸Šå…¨çœç¸½åƒ¹
    
    # ç‚ºäº†ç°¡åŒ–ï¼Œæˆ‘å€‘é‡æ–°æƒæ Rows ä¾†è¨ˆç®—
    # é€™è£¡éœ€è¦ä¸€å€‹ flag ä¾†é¿å…é‡è¤‡è¨ˆç®—å…¨çœçš„ç¸½åƒ¹
    processed_national_media = set()
    
    for r in rows:
        m = r["media_type"]
        val = r["pkg_display_val"] if isinstance(r["pkg_display_val"], int) else 0
        
        if r.get("is_national_display"):
            if m not in processed_national_media:
                # æ‰¾åˆ°å°æ‡‰çš„å…¨çœå®šåƒ¹ (List)
                # å¾ r è£¡é¢åæ¨æœ‰é»éº»ç…©ï¼Œç›´æ¥å¾ PRICING_DB æ‹¿æœ€æº–
                factor = SEC_FACTORS[m][r["seconds"]]
                std = PRICING_DB[m]["Std_Spots"]
                nat_list_price = PRICING_DB[m]["å…¨çœ"][0] # 400k or 150k
                
                # è¨ˆç®—å…¨çœç¸½åƒ¹ = å–®æª”å®šåƒ¹ * ç¸½æª”æ¬¡
                # é€™è£¡çš„ "ç¸½æª”æ¬¡" æ˜¯ "å…¨çœæª”æ¬¡" (1766)ï¼Œä¸æ˜¯ 6 å€åŠ ç¸½ (10596)
                # rows è£¡çš„ spots å·²ç¶“æ˜¯ 1766
                # Rate = 400k / 480 * Factor
                # Total = Rate * 1766
                nat_rate = int((nat_list_price / std) * factor)
                nat_total = nat_rate * r["spots"]
                
                total_pkg += nat_total
                processed_national_media.add(m)
        else:
            total_pkg += val

    pkg_col = cols.get("pkg") or cols.get("proj_price")
    safe_write(ws, f"{pkg_col}{total_row}", total_pkg)

    lbl = meta["footer_labels"]
    make_fee = 10000 
    pos_make = find_cell_exact(ws, lbl["make"])
    if pos_make:
        v = ws.cell(pos_make[0], pos_make[1]+1).value
        if isinstance(v, (int, float)) and v > 0: make_fee = int(v)
        else: safe_write_rc(ws, pos_make[0], pos_make[1]+1, make_fee)
    
    vat = int(round((total_pkg + make_fee) * 0.05))
    pos_vat = find_cell_exact(ws, lbl["vat"])
    if pos_vat: safe_write_rc(ws, pos_vat[0], pos_vat[1]+1, vat)
    
    pos_grand = find_cell_exact(ws, lbl["grand"])
    if pos_grand: safe_write_rc(ws, pos_grand[0], pos_grand[1]+1, total_pkg + make_fee + vat)

    rem_pos = find_cell_exact(ws, "Remarksï¼š")
    if rem_pos:
        for i, rm in enumerate(remarks_list):
            safe_write_rc(ws, rem_pos[0] + 1 + i, rem_pos[1], rm)

    if format_type == "Dongwu":
        force_center_columns_range(ws, meta["force_center_cols"], min(r[0] for r in written_ranges) if written_ranges else total_row, total_row)

    out = io.BytesIO()
    wb.save(out)
    return out.getvalue()

# =========================================================
# 6. HTML Preview
# =========================================================
def load_font_base64():
    font_path = "NotoSansTC-Regular.ttf"
    if os.path.exists(font_path):
        with open(font_path, "rb") as f: return base64.b64encode(f.read()).decode("utf-8")
    url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/TTF/TraditionalChinese/NotoSansTC-Regular.ttf"
    try:
        r = requests.get(url, timeout=15)
        if r.status_code == 200:
            with open(font_path, "wb") as f: f.write(r.content)
            return base64.b64encode(r.content).decode("utf-8")
    except: pass
    return None

def generate_html_preview(rows, days_cnt, start_dt, end_dt, c_name, p_display, format_type, remarks):
    header_cls = "bg-dw-head" if format_type == "Dongwu" else "bg-sh-head"
    media_order = {"å…¨å®¶å»£æ’­": 1, "æ–°é®®è¦–": 2, "å®¶æ¨‚ç¦": 3}
    eff_days = min(days_cnt, 31)
    
    st.markdown(f"""<style>
    .excel-container {{ overflow-x: auto; }}
    .excel-table {{ width: 100%; border-collapse: collapse; min-width: 1200px; font-family: Arial, sans-serif; font-size: 12px; }}
    .excel-table th, .excel-table td {{ border: 1px solid #999; padding: 4px; text-align: center; white-space: nowrap; height: 24px; }}
    .bg-dw-head {{ background-color: #4472C4; color: white; font-weight: bold; }}
    .bg-sh-head {{ background-color: #BDD7EE; color: black; font-weight: bold; }}
    .bg-weekend {{ background-color: #FFD966; color: black; }}
    .bg-total   {{ background-color: #FFF2CC; font-weight: bold; }}
    .left {{ text-align: left !important; padding-left: 5px; }}
    .right {{ text-align: right !important; padding-right: 5px; font-family: Consolas, monospace; }}
    .remarks {{ margin-top: 15px; font-size: 13px; text-align: left; line-height: 1.5; }}
    </style>""", unsafe_allow_html=True)

    date_th1, date_th2 = "", ""
    curr = start_dt
    weekdays = ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "æ—¥"]
    for i in range(eff_days):
        wd = curr.weekday()
        bg = "bg-weekend" if (format_type == "Dongwu" and wd >= 5) else header_cls
        if format_type == "Shenghuo": bg = header_cls 
        date_th1 += f"<th class='{bg} col_day'>{curr.day}</th>"
        date_th2 += f"<th class='{bg} col_day'>{weekdays[wd]}</th>"
        curr += timedelta(days=1)

    if format_type == "Dongwu":
        cols_def = ["Station", "Location", "Program", "Day-part", "Size", "rate<br>(List)", "Package<br>(List)"]
    else:
        cols_def = ["é »é“", "æ’­å‡ºåœ°å€", "æ’­å‡ºåº—æ•¸", "æ’­å‡ºæ™‚é–“", "ç§’æ•¸<br>è¦æ ¼", "å°ˆæ¡ˆåƒ¹"]
    th_fixed = "".join([f"<th rowspan='2'>{c}</th>" for c in cols_def])
    
    rows_sorted = sorted(rows, key=lambda x: (media_order.get(x["media_type"], 99), x["seconds"], REGIONS_ORDER.index(x["region"]) if x["region"] in REGIONS_ORDER else 99))
    tbody = ""
    media_counts = {}
    for r in rows_sorted: media_counts[r["media_type"]] = media_counts.get(r["media_type"], 0) + 1
    media_printed = {m: False for m in media_counts}

    for idx, r in enumerate(rows_sorted):
        m = r["media_type"]
        tbody += "<tr>"
        if not media_printed[m]:
            rowspan = media_counts[m]
            display_name = "å…¨å®¶ä¾¿åˆ©å•†åº—<br>é€šè·¯å»£æ’­å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "å…¨å®¶ä¾¿åˆ©å•†åº—<br>æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
            if format_type == "Shenghuo" and m == "å…¨å®¶å»£æ’­": display_name = "å…¨å®¶ä¾¿åˆ©å•†åº—<br>å»£æ’­é€šè·¯å»£å‘Š"
            if format_type == "Shenghuo": tbody += f"<td class='left'>{display_name}</td>"
            else: tbody += f"<td class='left' rowspan='{rowspan}'>{display_name}</td>"; media_printed[m] = True
        elif format_type == "Shenghuo":
             display_name = "å…¨å®¶ä¾¿åˆ©å•†åº—<br>å»£æ’­é€šè·¯å»£å‘Š" if m == "å…¨å®¶å»£æ’­" else "å…¨å®¶ä¾¿åˆ©å•†åº—<br>æ–°é®®è¦–å»£å‘Š" if m == "æ–°é®®è¦–" else "å®¶æ¨‚ç¦"
             tbody += f"<td class='left'>{display_name}</td>"

        tbody += f"<td>{region_display(r['region'])}</td><td class='right'>{r.get('program_num','')}</td><td>{r['daypart']}</td>"
        sec_txt = f"{r['seconds']}ç§’" if format_type=="Dongwu" and m=="å®¶æ¨‚ç¦" else f"{r['seconds']}" if format_type=="Dongwu" else f"{r['seconds']}ç§’å»£å‘Š"
        tbody += f"<td>{sec_txt}</td>"
        
        # é¡¯ç¤ºé‚è¼¯ï¼šå…¨éƒ¨é¡¯ç¤º (Value Anchor)
        rate = f"{r['rate_list']:,}" if isinstance(r['rate_list'], int) else r['rate_list']
        pkg = f"{r['pkg_display_val']:,}" if isinstance(r['pkg_display_val'], int) else r['pkg_display_val']
        
        if format_type == "Dongwu": tbody += f"<td class='right'>{rate}</td><td class='right'>{pkg}</td>"
        else: tbody += f"<td class='right'>{pkg}</td>"
        
        for d in r['schedule'][:eff_days]: tbody += f"<td>{d}</td>"
        tbody += f"<td class='bg-total'>{sum(r['schedule'])}</td></tr>"

    totals = [sum([r["schedule"][d] for r in rows if d < len(r["schedule"])]) for d in range(eff_days)]
    
    # ç¸½é‡‘é¡è¨ˆç®— (Total Override)
    total_pkg = 0
    processed_national = set()
    for r in rows:
        m = r["media_type"]
        val = r["pkg_display_val"] if isinstance(r["pkg_display_val"], int) else 0
        if r.get("is_national_display"):
            if m not in processed_national:
                factor = SEC_FACTORS[m][r["seconds"]]
                std = PRICING_DB[m]["Std_Spots"]
                nat_list = PRICING_DB[m]["å…¨çœ"][0]
                total_pkg += int((nat_list / std) * factor) * r["spots"]
                processed_national.add(m)
        else:
            total_pkg += val
            
    colspan = 5; empty_td = "<td></td>" if format_type == "Dongwu" else ""
    tfoot = f"<tr class='bg-total'><td colspan='{colspan}' class='left'>Total</td>{empty_td}<td class='right'>{total_pkg:,}</td>"
    for t in totals: tfoot += f"<td>{t}</td>"
    tfoot += f"<td>{sum(totals)}</td></tr>"

    return f"""<div class="excel-container"><div style="margin-bottom:10px;"><b>å®¢æˆ¶ï¼š</b>{c_name} &nbsp; <b>ç”¢å“ï¼š</b>{p_display}<br><span style="color:#666;">èµ°æœŸï¼š{start_dt} ~ {end_dt}</span></div><table class="excel-table"><thead><tr>{th_fixed}{date_th1}<th class='{header_cls}' rowspan='2'>æª”æ¬¡</th></tr><tr>{date_th2}</tr></thead><tbody>{tbody}{tfoot}</tbody></table><div class="remarks"><b>Remarksï¼š</b><br>{"<br>".join(remarks)}</div></div>"""

# =========================================================
# 7. UI Main
# =========================================================
st.title("ğŸ“º åª’é«” Cue è¡¨ç”Ÿæˆå™¨ (v66.1: Value Anchor)")

auto_tpl, source, msgs = load_default_template()
template_bytes = auto_tpl

if auto_tpl:
    st.success(f"âœ… å·²è¼‰å…¥ç³»çµ±å…¬ç‰ˆ ({source})")
else:
    st.warning("âš ï¸ ç„¡æ³•è¼‰å…¥å…¬ç‰ˆï¼Œè«‹æ‰‹å‹•ä¸Šå‚³")
    tpl = st.file_uploader("ä¸Šå‚³ Excel æ¨¡æ¿", type=["xlsx"])
    if tpl: template_bytes = tpl.read()

st.markdown("### 1. é¸æ“‡æ ¼å¼")
format_type = st.radio("", ["Dongwu", "Shenghuo"], horizontal=True, label_visibility="collapsed")

st.markdown("### 2. åŸºæœ¬è³‡æ–™è¨­å®š")
c1, c2, c3 = st.columns(3)
with c1: client_name = st.text_input("å®¢æˆ¶åç¨±", "è¬åœ‹é€šè·¯")
with c2: product_name = st.text_input("ç”¢å“åç¨±", "çµ±ä¸€å¸ƒä¸")
with c3: total_budget_input = st.number_input("ç¸½é ç®— (æœªç¨… Net)", value=1000000, step=10000)

c4, c5 = st.columns(2)
with c4: start_date = st.date_input("é–‹å§‹æ—¥", datetime(2026, 1, 1))
with c5: end_date = st.date_input("çµæŸæ—¥", datetime(2026, 1, 31))
days_count = (end_date - start_date).days + 1
st.info(f"ğŸ“… èµ°æœŸå…± **{days_count}** å¤©")

with st.expander("ğŸ“ å‚™è¨»æ¬„ä½è¨­å®š (Remarks)", expanded=False):
    rc1, rc2, rc3 = st.columns(3)
    sign_deadline = rc1.date_input("å›ç°½æˆªæ­¢æ—¥", datetime.now() + timedelta(days=3))
    billing_month = rc2.text_input("è«‹æ¬¾æœˆä»½", "2026å¹´2æœˆ")
    payment_date = rc3.date_input("ä»˜æ¬¾å…Œç¾æ—¥", datetime(2026, 3, 31))

st.markdown("### 3. åª’é«”æŠ•æ”¾è¨­å®š")

# 1. ç‹€æ…‹åˆå§‹åŒ–
if "rad_share" not in st.session_state: st.session_state.rad_share = 100
if "fv_share" not in st.session_state: st.session_state.fv_share = 0
if "cf_share" not in st.session_state: st.session_state.cf_share = 0

# 2. è‡ªå‹•å¹³è¡¡ Callback
def on_media_change():
    active = []
    if st.session_state.get("cb_rad"): active.append("rad_share")
    if st.session_state.get("cb_fv"): active.append("fv_share")
    if st.session_state.get("cb_cf"): active.append("cf_share")
    if not active: return
    share = 100 // len(active)
    for key in active: st.session_state[key] = share
    rem = 100 - sum([st.session_state[k] for k in active])
    st.session_state[active[0]] += rem

def on_slider_change(changed_key):
    active = []
    if st.session_state.get("cb_rad"): active.append("rad_share")
    if st.session_state.get("cb_fv"): active.append("fv_share")
    if st.session_state.get("cb_cf"): active.append("cf_share")
    others = [k for k in active if k != changed_key]
    if not others: st.session_state[changed_key] = 100
    elif len(others) == 1:
        val = st.session_state[changed_key]
        st.session_state[others[0]] = max(0, 100 - val)
    elif len(others) == 2:
        val = st.session_state[changed_key]
        rem = max(0, 100 - val)
        k1, k2 = others[0], others[1]
        sum_others = st.session_state[k1] + st.session_state[k2]
        if sum_others == 0: st.session_state[k1] = rem // 2; st.session_state[k2] = rem - st.session_state[k1]
        else:
            ratio = st.session_state[k1] / sum_others
            st.session_state[k1] = int(rem * ratio)
            st.session_state[k2] = rem - st.session_state[k1]

# 3. åª’é«”å‹¾é¸å€
st.write("è«‹å‹¾é¸è¦æŠ•æ”¾çš„åª’é«”ï¼š")
col_cb1, col_cb2, col_cb3 = st.columns(3)
with col_cb1: is_rad = st.checkbox("å…¨å®¶å»£æ’­", value=True, key="cb_rad", on_change=on_media_change)
with col_cb2: is_fv = st.checkbox("æ–°é®®è¦–", value=False, key="cb_fv", on_change=on_media_change)
with col_cb3: is_cf = st.checkbox("å®¶æ¨‚ç¦", value=False, key="cb_cf", on_change=on_media_change)

m1, m2, m3 = st.columns(3)
config = {}

if is_rad:
    with m1:
        st.markdown("#### ğŸ“» å…¨å®¶å»£æ’­")
        is_nat = st.checkbox("å…¨çœè¯æ’­", True, key="rad_nat")
        regs = ["å…¨çœ"] if is_nat else st.multiselect("å€åŸŸ", REGIONS_ORDER, default=REGIONS_ORDER, key="rad_reg")
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [20], key="rad_sec")
        st.slider("é ç®— %", 0, 100, key="rad_share", on_change=on_slider_change, args=("rad_share",))
        sec_shares = {}
        if len(secs) > 1:
            ls = 100
            for s in sorted(secs)[:-1]: v = st.slider(f"{s}ç§’ %", 0, ls, int(ls/2), key=f"rs_{s}"); sec_shares[s] = v; ls -= v
            sec_shares[sorted(secs)[-1]] = ls
        elif secs: sec_shares[secs[0]] = 100
        config["å…¨å®¶å»£æ’­"] = {"is_national": is_nat, "regions": regs, "seconds": sorted(secs), "share": st.session_state.rad_share, "sec_shares": sec_shares}

if is_fv:
    with m2:
        st.markdown("#### ğŸ“º æ–°é®®è¦–")
        is_nat = st.checkbox("å…¨çœè¯æ’­", False, key="fv_nat")
        regs = ["å…¨çœ"] if is_nat else st.multiselect("å€åŸŸ", REGIONS_ORDER, default=["åŒ—å€"], key="fv_reg")
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [10], key="fv_sec")
        st.slider("é ç®— %", 0, 100, key="fv_share", on_change=on_slider_change, args=("fv_share",))
        sec_shares = {}
        if len(secs) > 1:
            ls = 100
            for s in sorted(secs)[:-1]: v = st.slider(f"{s}ç§’ %", 0, ls, int(ls/2), key=f"fs_{s}"); sec_shares[s] = v; ls -= v
            sec_shares[sorted(secs)[-1]] = ls
        elif secs: sec_shares[secs[0]] = 100
        config["æ–°é®®è¦–"] = {"is_national": is_nat, "regions": regs, "seconds": sorted(secs), "share": st.session_state.fv_share, "sec_shares": sec_shares}

if is_cf:
    with m3:
        st.markdown("#### ğŸ›’ å®¶æ¨‚ç¦")
        secs = st.multiselect("ç§’æ•¸", DURATIONS, [20], key="cf_sec")
        st.slider("é ç®— %", 0, 100, key="cf_share", on_change=on_slider_change, args=("cf_share",))
        sec_shares = {}
        if len(secs) > 1:
            ls = 100
            for s in sorted(secs)[:-1]: v = st.slider(f"{s}ç§’ %", 0, ls, int(ls/2), key=f"cs_{s}"); sec_shares[s] = v; ls -= v
            sec_shares[sorted(secs)[-1]] = ls
        elif secs: sec_shares[secs[0]] = 100
        config["å®¶æ¨‚ç¦"] = {"regions": ["å…¨çœ"], "seconds": sorted(secs), "share": st.session_state.cf_share, "sec_shares": sec_shares}

# ---------------------------------------------------------
# è¨ˆç®—å¼•æ“
# ---------------------------------------------------------
rows = []
debug_logs = []

if config:
    for m, cfg in config.items():
        m_budget = total_budget_input * (cfg["share"] / 100.0)
        for sec, sec_pct in cfg["sec_shares"].items():
            s_budget = m_budget * (sec_pct / 100.0)
            if s_budget <= 0: continue
            factor = get_sec_factor(m, sec)
            
            if m in ["å…¨å®¶å»£æ’­", "æ–°é®®è¦–"]:
                db = PRICING_DB[m]
                
                if cfg["is_national"]:
                    calc_regs = ["å…¨çœ"]
                    display_regs = REGIONS_ORDER # å±•é–‹6å€
                else:
                    calc_regs = cfg["regions"]
                    display_regs = cfg["regions"]
                
                unit_net_sum = 0
                for r in calc_regs:
                    unit_net_sum += (db[r][1] / db["Std_Spots"]) * factor
                
                if unit_net_sum == 0: continue
                
                spots_init = math.ceil(s_budget / unit_net_sum)
                penalty = 1.1 if spots_init < db["Std_Spots"] else 1.0
                spots_final = math.ceil(s_budget / (unit_net_sum * penalty))
                if spots_final % 2 != 0: spots_final += 1
                if spots_final == 0: spots_final = 2
                
                sch = calculate_schedule(spots_final, days_count)
                
                debug_logs.append({
                    "media": m, "sec": sec, "budget": s_budget, 
                    "unit_cost": unit_net_sum * penalty, "spots": spots_final, 
                    "std": db["Std_Spots"], "factor": factor, 
                    "status": "æœªé”æ¨™" if penalty > 1 else "é”æ¨™",
                    "reason": f"æ‡²ç½° x1.1" if penalty > 1 else "è²»ç‡æ­£å¸¸"
                })
                
                for i, r in enumerate(display_regs):
                    is_national_display = cfg["is_national"]
                    is_primary_pricing_row = (i == 0)
                    
                    # é¡¯ç¤ºé‚è¼¯ï¼šæ¯åˆ—éƒ½é¡¯ç¤ºè©²å€çš„ List Rate (Anchor)
                    rate_list = int((db[r][0] / db["Std_Spots"]) * factor)
                    pkg_list = rate_list * spots_final
                    
                    rows.append({
                        "media_type": m, "region": r, 
                        "program_num": STORE_COUNTS_NUM.get(f"æ–°é®®è¦–_{r}" if m=="æ–°é®®è¦–" else r, 0),
                        "daypart": db["Day_Part"], "seconds": sec,
                        "spots": spots_final, "schedule": sch,
                        "rate_list": rate_list, "pkg_display_val": pkg_list,
                        "is_national_display": is_national_display,
                        "is_primary_pricing_row": is_primary_pricing_row
                    })

            elif m == "å®¶æ¨‚ç¦":
                db = PRICING_DB["å®¶æ¨‚ç¦"]
                base_std = db["é‡è²©_å…¨çœ"]["Std_Spots"]
                unit_net = (db["é‡è²©_å…¨çœ"]["Net"] / base_std) * factor
                
                spots_init = math.ceil(s_budget / unit_net)
                penalty = 1.1 if spots_init < base_std else 1.0
                spots_final = math.ceil(s_budget / (unit_net * penalty))
                if spots_final % 2 != 0: spots_final += 1
                
                sch_h = calculate_schedule(spots_final, days_count)
                
                debug_logs.append({
                    "media": m, "sec": sec, "budget": s_budget, 
                    "unit_cost": unit_net * penalty, "spots": spots_final, 
                    "std": base_std, "factor": factor,
                    "status": "æœªé”æ¨™" if penalty > 1 else "é”æ¨™",
                    "reason": f"æ‡²ç½° x1.1" if penalty > 1 else "è²»ç‡æ­£å¸¸"
                })
                
                rate_h = int((db["é‡è²©_å…¨çœ"]["List"] / base_std) * factor)
                rows.append({"media_type": m, "region": "å…¨çœé‡è²©", "program_num": STORE_COUNTS_NUM["å®¶æ¨‚ç¦_é‡è²©"], "daypart": db["é‡è²©_å…¨çœ"]["Day_Part"], "seconds": sec, "spots": spots_final, "schedule": sch_h, "rate_list": rate_h, "pkg_display_val": rate_h * spots_final})
                
                spots_s = int(spots_final * (db["è¶…å¸‚_å…¨çœ"]["Std_Spots"] / base_std))
                sch_s = calculate_schedule(spots_s, days_count)
                rows.append({"media_type": m, "region": "å…¨çœè¶…å¸‚", "program_num": STORE_COUNTS_NUM["å®¶æ¨‚ç¦_è¶…å¸‚"], "daypart": db["è¶…å¸‚_å…¨çœ"]["Day_Part"], "seconds": sec, "spots": spots_s, "schedule": sch_s, "rate_list": "è¨ˆé‡è²©", "pkg_display_val": "è¨ˆé‡è²©"})

p_str = f"{'ã€'.join([f'{s}ç§’' for s in sorted(list(set(r['seconds'] for r in rows)))])} {product_name}" if rows else ""
rem = get_remarks_text(sign_deadline, billing_month, payment_date)

with st.expander("ğŸ’¡ ç³»çµ±é‹ç®—é‚è¼¯èªªæ˜ (Debug Panel)", expanded=False):
    st.markdown("#### 1. æœ¬æ¬¡é ç®—åˆ†é… (Waterfall)")
    for log in debug_logs:
        color = "green" if log["status"] == "é”æ¨™" else "red"
        st.markdown(f"**{log['media']} ({log['sec']}ç§’)**: é ç®—${log['budget']:,.0f} | åŸ·è¡Œ{log['spots']}æª” -> <span style='color:{color}'><b>{log['status']}</b></span>", unsafe_allow_html=True)

if rows:
    font_b64 = load_font_base64()
    html = generate_html_preview(rows, days_count, start_date, end_date, client_name, p_str, format_type, rem)
    st.components.v1.html(html, height=700, scrolling=True)
    
    if template_bytes:
        try:
            xlsx = generate_excel_from_template(format_type, start_date, end_date, client_name, p_str, rows, rem, template_bytes)
            st.download_button("ä¸‹è¼‰ Excel", xlsx, f"Cue_{client_name}.xlsx")
            
            pdf_bytes, method, err = xlsx_bytes_to_pdf_bytes(xlsx)
            
            if pdf_bytes:
                st.download_button(f"ä¸‹è¼‰ PDF ({method})", pdf_bytes, f"Cue_{client_name}.pdf")
            else:
                st.warning(f"Excel è½‰ PDF å¤±æ•— ({method}: {err})ï¼Œåˆ‡æ›è‡³å‚™ç”¨æ¸²æŸ“å¼•æ“ (HTML)...")
                pdf_bytes, err = html_to_pdf_fallback(html, font_b64)
                if pdf_bytes: st.download_button("ä¸‹è¼‰ PDF (Fallback)", pdf_bytes, f"Cue_{client_name}.pdf")
                else: st.error(f"PDF ç”¢å‡ºå¤±æ•—: {err}")
                
        except Exception as e: st.error(f"Excel ç”¢å‡ºéŒ¯èª¤: {e}")
    else: st.warning("è«‹ä¸Šå‚³æ¨¡æ¿ä»¥å•Ÿç”¨ä¸‹è¼‰ã€‚")
